Okay, speak your pre-log. You're in serious. This is a recording for the competition AI, but the Magical Olympiad. Progress too. So like a pre-face, we tried the previous competition, but didn't go too well. We finally bailed the model, but nah nah. That didn't operate on the first competition. Against the rub and not. Let's go deeper then. What is this competition about? It's basically the same shit, right? They just want us... I'll show you. The previous start from the previous one, since I have it here. Let's go with this one. Hey, Barbie. The previous top solution, I think, was this one. Hopefully. No meaner. Yeah, this was the top in the previous one. And what they did was this. They did just a pre-face. They have a natural reasoning like data. So this was done, I think, with GPT-4O. Come up with an answer, sort of like pseudo code. Then code nested and tool interaction data. So this would be... So for example, if you have an agent, it will have some tools. So for this part, they created data to show how the tools would be used. And how it interacts with the pseudo answer. Then from there, now we give it the question. The question goes into a chain of thoughts. Then the code... So the process would be... From the chain of thoughts, we get code. From the code, outputs. From the outputs. If there's a narrow-witty bug, go back to the code and so on. If it's successful, that's our final answer. And that's basically it. Then that's more and more. Yeah. You can't see it. You have to speak. But the main thing they did was our let me go back. Self-consistency with tool integration reasoning. Then chain of thoughts as well. That was one thing. And if I'm not wrong, there must have been some sort of tree of thought. So those are tree of thought. Or actually just let's say, yeah. So we had... We had input, output prompting. Then chain of thoughts. That's what we've covered. Self-consistency. Chain of thought. Then tree of thought. So that was a few of the techniques covered. Then that's it. Then results. That was the top model. At least that won the previous one. And now the scores that it had were... I think 29 over 50. Maybe here. Now that's the demo. Go back to the communication. Oh yeah. Yeah, 29. So on the private set, the test... The private test that we don't see, they go 29 out of 50 questions. So they usually give human students 50 questions. Then I think humans have surpassed... Maybe I'm not sure about... About 30 plus. But for Numeena, the scores 29, which are the best. As we continue now, the competition we're trying out. The target is... I don't think there is a target. But let's see. Is it the highest or at least 47? Yep. So the target is 47. Out of 50. Out of 50, okay. Then... I'm going 5 million. No, no. I don't know. High score? I just saw it down there. That's total. Yes, the high score. Okay. Okay. Sorry? Yeah? The overall price, progress price, winner in this competition. The price will be at least billionth. Okay. If no team, blah blah blah. Just that. We'll try to hit there, but we'll likely land somewhere. I just want cargo for this operator. I don't want no gun. They know winning now. We'll end up somewhere hopefully. Somewhere... Yeah, I need to chill. We've got five months. Good boy. Seven days ago, that's when he started. But that's all the preface we need. So... So what I did is... The technique I have in mind... I'm not going to show you Agent Zero. But the technique I have in mind... It's not that we don't need to use it. It's just something I want to try out. Let me know such for it. Toby be good. Agent Zero. There we go. So Agent Zero is a framework that uses... It's an agent framework that uses an LLM as its core... Let's say core... Yeah, backbone, perfect. With the... It's sort of like a cursor composer how you can prompt it. Then it goes... And does or creates a file. Add the code in and so on and so forth. But it's more general purpose. So it can... If you use cases, if you give it GPU access, it can... If you prompt it to do something with GPU acceleration, then it can do that. It can retain thoughts or prompts or... Anything really. In its memory, but the memory is more efficient compared to what we have on GBT. The memory is more of a learning capability in that... In its process, we can tell it to learn by itself or keep store things in memory. Like best, let's say, best techniques or best results, something like that. Apart from that, it does have a doc container where that's where it does most of its code things. So that it's separate from your computer. So in case it does... Let's say, was case scenario, it deletes windows or deletes linux. Then it doesn't affect your system. It only happens on the doc container. Then it does... When we say it is a computer or computer as a tool, then with the doc container, it can't interact with your computer. Almost similar to the anthropic one, but not as such. The anthropic one is different because it's directly on your computer. Rather than this, it's through the doc container. Next, multi-agent cooperation. This is an interesting one. So with multi-agent, it means it can create different iterations of itself. So we could have... The reason it was called agent zero, agent zero, be at the top. Or let's say, no, I'm... I'm agent infinity before zero. Then agent zero is now the agent itself. Then it can delegate tasks to agent one. Agent one can give to two or agent zero can give to two and so on. And that basically helps. If I was to tell it, go create a website, for example, that uses Node.js as backend and maybe react as front and something like that. Then that would mean there's a react agent, there's a Node.js agent, then there's maybe... Now agent zero is there, overlooking person. Then as it overlooks, agent one repost to agent zero, agent zero can send agent one back, go redo this, and so on and so forth. You can always interrupt any of the agents, but it all happens within the same terminal. I'll probably show a video. The next we have customizable. So one of the reasons I chose this technique, and I tried it for the ACK price. The ACK price was looking to sort of solve puzzles that humans can easily solve just by looking at them. But agent, I chose agent zero because it's customizable in that you can bring in anything. If it's Monte Carlo tree thought, you can bring in the system. Either as an AI model, independent from it, and they collaborate or you could give it as a tool. So it depends on how you structure the tool. Then it's extensible in that... But it's more or less scalable. It just depends on how you manage the code. I think that's where I really couldn't get for. Because there's multiple files, etc. Communication is the main thing. All of the agents running. It's just done through prompt files. So that's going to be a big thing. It's also a good thing in that there's less... It's a competition and we need certain staff to be done. Then we'll have to code. But most of the things will happen through the prompt. Because that's what guides the AI system through different steps. So let's say fast prompt is create our website. Then it would fast go to maybe web search check for best techniques. Then there is a prompt for web searching. If it's tool use, there is prompts for tool use, etc. There could be dangerous. It's not pre-programmed. If you cannot provide the ideal environment, let your agent know. So it's more or less just telling us to be careful. Because it is using our computer. It's not using someone else's. So you can still do stuff on it. If you take it that far. Another cool thing is that the agent can't be autonomous to some certain extent. Let's say if I let it run in a task, it can go and do. If it goes across errors, it can solve them. Basically just use it the LLM. It has in its main logic it's able to do the reasoning. Let's say the reasoning we see from O1. But it's now doing it with whichever model you want. Lastly set up. Did I see GPU? Then you can put GPU access. But yeah that's it. Now next I've got to show you the video of the founder. But this is just a technique. We don't need to use this. I just think it's cool. It's an agent so it's forward looking. The good thing also, we just need to give it tools. We already have, it's like having like us work separately. Then basically just give us tools. So our tools could be the way we use Claude on the side, GPT on the side, maybe sometimes CASA or every time CASA. So it's just the more powerful the tools, the better the agent. So now I think we only have web search. To use, to use could be calculator and what else? Could code tool, think of some, I think there is a memory tool to store stuff in memory. Those are the ones I can remember. Yeah. Then let me ask Dion to do the videos fast. Show the guy or like more ideas. I can watch the videos today. Go with the next idea. This one was, so just let me open the actual link. I think it's someone, oh yeah, there we go. Now not this. This I want there. Let me start it. They want, they want us geometry. Also, you see, now geometry, yep. And hopefully they are done somewhere here. Is it this one? There we go. That's one. And the second one. Here, there. Here. I think it's same. No, no, no, separate. So one of the cool things we saw before, oh, one released. That's when you went to Luton. It was, deep mind released, alpha geometry. Actually, that was early in the year, but maybe I don't know. But alpha geometry, what it did, it got to 25. 25, those was this score on international master limp. It was like more or less highest score for an AI. If I'm not wrong, it was closer to gold. We are projecting it to be someone in the future, whatever they are projecting. But the techniques they used are more or less interesting. So this was mainly for geometric stuff. So like in the previous one, remember how we had to not collect images, questions with images, ETC, because it would be hard for the AI to answer, because it can't maybe see the plot or decide for the plot, ETC. So alpha geometry would now you have your problem, goes to an LLAM. With the LLAM, we have the symbolic engine. I'll have to maybe go through down here. Then now makes the solution. But more or less, the symbolic engine, if I'm not wrong, let's see. Let's just go there. Wait, is it the same thing? It's just fucking same thing. Okay, it's finished. But for my blemages, let's just go through this. Okay, okay. I don't want to say the DSL, I really don't want to say that. Okay, I think I got what they did. The symbolic engine basically from here, from here, why is it? From here, it basically sort of describes how the plot or image comes about. So you'd have like a cyclic, let's say sort of like a phantahedron of sorts. Then you'd give it the angle, angle EAH equals to angle EDH, something like that. Then you have a series of steps that comes up with the image represented as words. Then that goes into the LLAM. Then using that knowledge, we're able to reason through and more or less construct. This is more or less in the back, and at least I don't think we can see that. Maybe they could, yeah, they could, how the LLAM would construct the image using the information we gave it. So this was one of the techniques I thought would be interesting. To get maybe 47 out of 50, that means more or less. We have to also capture like images, most likely, it was 47 out of 50, basically the whole test. Oh, more or less the whole test. No, the test, the reason for your hard-to-do images. Really? There's images at all. Look at the date of the test. No, no, leave the test. The test one is, it tells you which one is similar. But it's all from here, remember? No, but tells you exactly what it's not included. Okay, yeah. Check. I think, I think that was about the previous one. I'm not sure about this one. No, 100 was I'm sure. The previous one, that's what it said. Check on date maybe. Oh, it's already in this chat. It's all already in this chat. I asked it. No, but it's in the chat. It's all in there. I'm going to be a face today on that. Yeah, yeah. Let's go up to the first one. I'm going to go up to the first message. And add it to that one. Yeah, just add it to this one. You added 100 or so. No. You guys all, yeah. Yeah, go back up there. No, no, this is too long. Yeah. Oh. Yeah. Oh, yeah. You can do something. Oh, I have to wait for the streets. I'm going to go home after this. Okay. You can do it. It's all over. I'm eating the open mind. Okay. Even for geometric problems, no diagrams will be provided. The geometric question is. That means that all of the questions. Yeah. There will only have the necessary details for the drawings in question. Okay. But not diagrams. Yeah, there will not have enough details for you to actually create the image. Depends. Depends. If it's because some questions, some questions you'd get them like the ones here. They won't allow you to do that. It gives you like the angle. You see like this question. That basically gives you the plot. No, no. Even if you don't see it. You can just construct the way they did. That's why they brought in the idea. You won't give me the full picture though. Yeah, through the words. As we can, how do you man can? No. And this is how they did it. That's it when they have the image itself. Okay, I have an image to start with. And they turn that into words. And then they use that to give the AI sort of image through the words. But if we have this, we can try and create this. We don't need to, we already have the words itself. Okay. Oh yeah. They don't have the words that we don't have the image. But they have the questions. It's in AI more. They give this to humans. They give it this and this. Yep. So this and this. This and yeah, we only have this. But in... We're more than able to create that. Yeah. I will see. You just can try. You can put it there. Mm-hmm. I think that's one that was... No! This one. Oh, she totally did this one. Oh, hell no. Just return it then. No, this is why the monitor is off. She'll go on. How is it there? Oh, no. The monitor's there. How is it that long? She's. It can't be that long. It's... She'll long? She'll go on. See, see, see, four. Is it on? I think it's on. I think it's on. I think it's on. What's up, you can turn it on. Found the second one. Found the third one. Yeah, this one. It's still from the point. This one, yeah, this one was one you're in the middle. It achieved silVER, but this was I AMOVE. I AMOVE. Let's see, but you know, there's results. Closer to... Closer to what you call it, this thing. Clown T visas. All for proof was more of reasoning behind the... Now, the previous step was the one we went through. So you get your problem, goes to formalize or basically uses a let's see solve a network. Oh my God, is it even here? Let's see. Is there a pay calling? Is it here? Yeah, there is. You know actually. It did perform well. It's down model. I think from what I remember in this part, it just goes into like a DSL, the DSL deconstructs the question, comes up. Now the DSL is like a code language, a specific language that if for example if it's our agent we give it a tool that it can create a DSL to decompose March questions into a specific type of code, maybe let's say something like, let's say, Mamed for example, Mamed makes some types of charts. So if our DSL is Mamed, the formalize a network does that decompose the question, gives us the how you'd explain it in that language, then that becomes your formal problems. Then you use that to train the solve a network, then the solve a network. If I'm not sure now we do search, yeah, from there I think I'm lost. But yeah, from there, let's say formal proofs, we search through solve a network, we give and what are we giving it, the question in that code. It tries to solve the question, but now we take out the proofs. So for example, let me say formal proofs, I think what they meant by trying to get the paper itself, you try and check, let's say if ask GPT1 plus 1 is 2 and give me a reason why, we take out the reason then that's our formal proof. Then now we use that, if the formal proof was wrong, if I said 1 plus 1 is 2 because 0 plus 1 is 2 then that's our wrong reason, you should be saying another good reason. So we take the good reasons of the formal proofs. Sometimes I think they also used human formal proofs, sort of adding the reasoning component, then use that to train the solve a network. Now they improved, the final improved version of the solve a network is now the alpha proof. Now that's what they, sorry, now that's the final model that's perfect, but alpha proof is the whole system. So just to go through quickly, if you have a maths problem, take it through a DS, take it through Gemini itself, Gemini converts it to a particular DSL, DSL it doesn't matter, it just needs to be a language that can easily communicate maths, maths concepts and language and formalities, then that becomes our formal problems, we use the formal problems to train our solve a network, that's the fast round of training, then from there we ask Gemini again to solve the questions and give formal proofs, we take out the formal proofs that are correct, then we use that plus human added formal proofs or improved formal proof versions, use that to train the solve a network the second time, then that gives us our final model. The reason I pointed this out is because of this part, the DSL, that's really interesting because that's also another way in our prize, people used it to decompose the image, for example, if you see an image that's in the fast chart, one square moved up, then left, then right, then we know most likely the next part, for humans it's easy, the next part would be back left, since we started from top went right, went down, so most likely it's left, so for humans it's easy but for AI it's hard because you can't see, so the best or some methods that were used was DSL, explain it, explain the image, fast what is, how does the image look like, now that's how the DSL helps us because it's able to describe it in a language AI, can understand, it could be binary, it could be whatever the language, then maybe the formal proofs part where we collect that, use that in, so far it could be used that in memory, maybe memory, we could choose to train a model but that's later on, think after that there is nothing, agent zero, the videos, review, previous solutions, checks auto methods, okay, let's see, this is just to have it there, then we'll do it once we officially start, but let's see any other ideas, this are the main ones, okay, there is a few more, this are the videos, okay, let me not start with tasks yet, so with agent zero I think I haven't watched the latest video but from what I left off they didn't have a good memory layer, so we might have to get either an open source version, use that as a memory layer, the memory layer would be sort of like a network, maybe neural network, if I'm not wrong, that is optimized for memory and retrieval and I think for this one we have graph memory specifics, I don't go into specifics but it's called memory AI, when we get there we'll see how it goes or I think they might have implemented it but this was suggested by the founder or the creator, apart from that there was another one, another memory layer, so this would be foundation memory layer for agents and the reason we need the memory layer is because the learning component will become hard because it's like if I go to GPT ask it to do this, it does it and forgets, even if we tell it save it in memory that's like just memory that goes into the memory we have here, most likely if we tell in our next prompt say use them, for example as you said go and use the information you have in memory, now that's put in the kv cache or it's put in like somewhere in the system before the prompt is sent in, so you have your memory plus context plus I think create let's say that, if you attach documents then that also, then there is drag but now all that goes into the LLAM gives you answer, so the reason we want this is because it helps us manage how the AI would be able to fast identify the good things about itself, then second to save it, it can always recall them by itself, so it might implement more complicated drag but we'll see how it goes, the more memory we have but hopefully this should help us if, yeah but we'll see one of the truth either way, I think this one's paid, it's free, there's open source, so either most likely we'd have to go with the open source version because with competition we can't really use closed source stuff, I think that's what we would, free bar, yeah, look at the difference, yeah but the problem is like it's closed source, so most likely if you wanted to see what they or how they come up with this, like there you see how we would check GitHub for this, like this, now we can see all the code but let's maybe check the GitHub, but tonight we'll see, don't want to go to deep into that, but yeah, we'll see, then that's competition, okay another idea would be since we have O1 now, create reasoning data set, so that would mean send it a question, tell it to answer, check the answer if it's correct, then now maybe tell it to create the data set from that point or check the actual reasoning steps that it took, maybe this may be clean enough, but now the problem is this are only summarized, the ones we see are only summarized versions of the full, you call it full reasoning steps, so maybe you'd have to prompt it to be a bit more detailed, even if they have restricted it, we might have to push it out from the system, ask it to give us more details on the such reasoning to make the data set, then this would go into a reasoning tool depending on how the tool structure would look like, then the reasoning tool would be sort of maybe a precursor to every question, so once it gets a question from the competition goes through the reasoning tool or user the reasoning tool, user that, user that, from that that goes to context for the LLAM, then plus the answer pretty much, then that can be submitted to cargo, then this adjust previous solutions, I'm going to that, this adjust to refile box, see the techniques they used, then I think that's the last, oh yeah, extra resources, this one is LLAM reasoning, research papers, yeah this adjust extra resources, when you get to that point you'll basically come back to this, find the resources that are helpful, use them in the process, then open it, I'm proving mathematical reasoning, yeah that should be a good one, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, I'm going to introduce this, yeah paper introduces reason evaluation and the machine evaluate mathematical reasoning beyond accuracy, yeah but this adjusts, let me just say this adjusts now the extra concepts that will go through, once I did create sort of like a workflow, might not be the best might not be the best, but I just told on to create it, so week one would be wait, let me check, let me check here, this would be like most of the weight is actually done, so create feedback that needs to be done, review previous top solutions, so I put the links here, so that's basically done, then we'll use them down the line, that's captured in the workflow, check state of the art methods in using other lamps for math including Google DeepMinds or Copenhagen Ice Model, I'll need to add in all one stuff, but maybe that's in the, or this part, the open and high part maybe, then find articles trending or all that have interesting techniques, so maybe the thing will have to take note is with Numina, let me actually open it, bug up, I think it was this one, here, yeah, with Numina, when they did this part of the chain of thought and this was at the time this was more state, let me say state of the art, or it was like something trending, so you'd sit on LinkedIn, those are the papers are you sending, so these are things you'd see on LinkedIn, then people are trying them in the competition, send the feedback and so on and so forth, so usually you find some of the top winning methods have already used like the latest thing like Monte Carlo Treesert or something of the sort, so like tool integration would be something you'd have now and you have agents, but this was already back then when agents was in Tivanna thing, so it's basically trying to see, okay what's new, can it, is it helpful, if it is, then let's implement and improve, then I think, yeah, use notebook LM for reading articles, this was just like a point, if you want, so you can create podcasts for you based on the articles and it's fairly cool, then when we start we'll need to check the data we collected, see why it lacks, EEG need to collect data from questions with images, not sure, so I'm not exactly sure how we collected it, I've kind of forgot, maybe, yeah, we'll have to check if there's sort of like questions with images or like a plot or something like an angle thing, then we'd have to maybe collect more or connect images, yeah, so we might have to look for some, yeah, most likely, even might be better off if we do the separate time, if we collect the second time, then we'd have separate data set with just tags, then separate with just images, then you can treat them separately in the process, then now the workflow, yeah, that's the second last thing, so week one and two, depending on when we start, would be just checking through agent zero, understanding, checking the videos, framework, the GitHub, basically understanding how the system works, try to view the code, maybe trick the code, see how it's, I've done most of that, this was basically for you and actually me, just I didn't do most of the coding part, even though I was working on it a lot, so I'll have to go through it again, then from the research and prioritization, that would be identify the techniques, so some we might have reviewed them, some might be might have seen on LinkedIn, from maybe someone told you HEC, then just read them some arise relevant papers, then discuss, so the maybe one thing I noticed from the previous competition, I was trying to implement everything and that's, it's not a good thing because it's now complex, you have too many files to handle, you have too many complex techniques, so that was the best choice that I made, but for this, it would be better, if we discuss a technique, maybe let's say today it's Monte Carlo research, then we take a week or two, try and implement with this, splitting it could be halfway, like you can do research, I can do research or some person does research, I can, or you do research, I do code, vice versa, it depends, you'll have to discuss that, then implementation and experimentation, so it would have cycles of walks or like this would be walk week one to two, that cycle one, then second, then now the second cycle, HEC, so it would have design control, implemented selected techniques, so this would be sort of, let's say even if it's like rough, we go to draw IO or any software, or even just or no one or any LLM, from the summaries we made, techniques we chose, see how it would actually walk theoretically rather than implementing it fast, then seeing okay this doesn't walk, so that would be design control, if you want to go in depth, that would be maybe try coding something, something to present, that doesn't need to be perfect, then from there we implement the selected technique of the above, then test in the value, this would now include sending the submission to cargo, getting the results back, reviewing that, seeing how we need to improve, maybe even identifying where the steps lock, whether it's the reasoning part or the CCC, okay then now we go to evaluation, yeah I think that's covered, these are yeah findings, then scaling and integration, this would be like once, so this part would be iteration, that would be like a cycle, whichever techniques we tried, maybe we tried Monte Carlo and chain of thought this time, cycle two will try, let's say using a DSL and maybe Monte Carlo was fairly good, so we tried those two, then if Monte Carlo is still good, the DSL isn't as good, would maybe put it here, take maybe a different technique, try that, so depending on the good, the best performing techniques would retain them, then simply attach other methods, another way could be also trying different combinations, but now complexity comes in, so we'll see, I think that's why it takes five months, but now the details, let's see what I didn't capture, this would just be an up, this would be something at the open on the day, so it's actually just only to be detailed, debug step through, modify program, okay this is just guiding us on what to do there, okay establish baseline model, so that's from week three, so it depends if you want we could build, or even let's, let me not even use the fucking wild build, let's just say fine tune, fine tune is way easier than build from scratch, so it would take like, even a modell that's already fine tuned for maths, then fine tune it with, let's say the question data, or reasoning data, or ETC, then that could be our custom reasoning model, then that could be a tool, so the agent has access to another tool, that's an actual model, then say say same shade it could be, if it's not reasoning it could be DSL part and ETC, just depends, you could either choose the key things would be thinking of is how to implement a technique as a model trained or fine tuned, or even rag, or is it implemented as a tool, and the tool would most likely be coded, hard coded, or open source, yeah, then keep the model simple, to isolate effects, so with the models, yeah keep them simple, I think fine tuning would be best of, I'll add that in, how do you write this, fine tune, is a big element, raise the type thing, it can't type it's a pocket figure, sometimes you can, yeah, oh there is, yeah, here, here this way, type, that way, fine tune, okay, but I'll have to save it, but yeah, next initial submission, but that's for here it's assuming the agent is a model, but it's more of a framework, or another thing maybe it's not captured here, we could have the agent submit the results by itself, but it's not necessary, we just need the results, then that goes, we can submit that ourselves, then document the base, yeah, documentation is it as important, but it's just good practice such that even if we are number 200, 300, if someone just wants to go through, maybe it was highly voted, it's good to have something to guide someone with, so like this, just something you can even if it's rough or even casually written, then it's okay, then week four research prioritizes, so that would be the research week, yeah, basically go through all techniques, use the best summarise, we could even speak with MSK, I did put like a, so every four weeks around this point would basically go to any mentor, or any even Dr. Mu, ask them anything could be specific to the research, or it could be specific to other parts, just to enhance sort of like information you can get from other people without having to source it ourselves, because it's not easier to, you might find MSK can tell us in touch a minute rather than searching through the whole week, or even Dr. Mu can tell us something that would take us longer, then depending on the technique we choose, implement, test, then submit, then it's just a cycle, implement, test, submit, then analyse, then if there's improvements, we can do like a mini improvement on that part, if that works in this part, if we analyse and improve on now this system, then could be a loop there, or more or less it's the best techniques within the ones that were tested and analysed that could be combined or even kept separate, so that's, it's more like even versioning, the way it do versioning and get the best, the best version is saved, then you can have, let's say we have best COT and best MCTS, then those could be two good models, try combining, that's your third, see how those work, then continue, then I think, so for some of the techniques I think O1 chose to put them like self-consistency, it wouldn't be smart to put it while we are still choosing a method, because self-consistency is more like helping the model improve on its current self, so if you have a trained model and wanted to improve on how it operates, you'd add self-consistency methods with chain of thought ETC, so this would be, it was smart to put it here, and I think, yeah, integrating external tools, what's this, or this would be simpy, simpy, I knew it, simpy, not simpy, no, it came out, this could be a DSL, it's used to do some math, but yeah, all of this is basically symbolic mathematical representation, then it's sort of, if you wanted to do like modulus, and there's a sign for modulus in human language, you can get it here somehow, then it's all explained, so that could be the method used for the DSL, modify agent architecture, this was placed wrongly, this is basically, while we're testing this, if we choose to go with the main route is the agent, then that would be, would be testing and implementing via the agent, but if we choose to build a model like a mega model from scratch or fine tuning, then that would be, would be improving and like looping through the model itself rather than the agent, just dependent the main technique which is, then text, test complex problem solving, that's for the agent, basically I think this is, because we don't know how the agent does on new information, that's why this is here, then most likely that would be solved with the memory, so it's able to recall, maybe that question had an interesting technique, such that we can remember the technique used, then submission, yeah, I'm down, synthetic, yeah, it would, if we build a model, this would come early, if we choose to go the agent route, this would come in later, once we have a method chosen, then now would use the synthetic data and fine tuning to improve on those techniques, so we'd find a way to plug in this into the, so this could be a custom model added as a tool, or, if not, it could be a technique, let's just say technique one, technique two, technique three, agent can choose technique one, two or three, or it could, in the reasoning process, make sure you go through all techniques, which can also be saved in memory, so this system will have to think through that, then week 10 to 12, iteration and scaling, scaling not as such depends, because that's still early, that's how many three months, 12, yeah, three months, that's three quarters of the way, let's say iteration, so this would be iteration, let's say we have a sub-good model, let's say it even scored 15, for example, then iteration would be seeing where can we improve on optimizing more libraries, more methods, curriculum, combined techniques, reinforcement learning, so this part is miscellaneous, most likely, by the end, because it's not as important, ongoing processes would be documentation, even documentation could be, let's say as you read the article, you could open a recording, just record the process, or if you're coding, record the process, or even at the end, or at the start, record the few thoughts that you had on what you're trying to implement, then regular meetings doesn't need to be weekly, could be, the circles would be one to two weeks, so maybe one, if you want it weekly, maybe two weeks, depends with also schedules, but let's just say weekly for now, then experiment tracking, or weights and biases, will we need it, or if we build a model from scratch, but we'll be fine tuning, yeah, if we choose to build a model, then even if it's for the agent, we can use this adjust experimental, weights and biases, just helps you track the losses, and the learning rate, ETC, log-or-l-experiments, parameters, results, this, I think, this would also be good, since what are, the work I was doing on the previous competition helped me learn all about Docker, because every day I had to log in to Docker, set up the Docker run, the agent, so if we can try and implement techniques industry standard, then this will gonna help us some time down the line, then it's in central repository, okay, so we'll need to make a GitHub and a free camp, I think there is one, there was one from the previous one, I'll just have to change it up, so then additional resources, just links, Trello is more like project management, Asana, if I'm not wrong, most likely it is, okay, like workflow management, okay, so we'll see which is the best, then version, yeah, data, yeah, keep raw process, yeah, collaboration slack, most likely it's better to use slack, because slack, if I could show you, slack is just like a, is it like a discord, let me just open on free, it's just more professional, keeps us separate from WhatsApp, because sometimes we might open WhatsApp, see something weird, then just become totally distracted, but this is basically how it looks, you have different channels, if you open a channel, you have like things here, then you can upload files, then could be specific, it's just connect different stuff, but it's basically that, so the free, no, no, it's free, but the pro version just gives you like a longer history, it's not necessary, even us we don't use it, it depends if you want them, because when I joined I didn't need them, unless now you're like CEO for, yeah, we'll only be able to access last three months of our work, yeah, but is it, that means we're only putting four months for, we won't be able to access the first months of our work, it's not necessary, we could use discord, yeah, this is creating the ass, trying to ensing, the upgrade to the page, oh, I missed it, I'm seeing too much, this is gonna be like for the whole group, yeah, 17, $1,000, just, thank you much, oh, I lied, then final time management, continuous learning, because it's cool team, and how management is gonna be tough? let's just say if we don't do something every day, we got to go gym, man, we just, how many days are we gonna put in depends? one, one each week? yeah, that's what I can do at best, right now, yes, maybe during winter I can do like four days, yeah, but when does it end? it doesn't, five months is like February March, March most likely, yeah, someone there, yeah, that's fine, hmm, good shit, then for week, for cold, like, managing different tasks, choose the one you like, we don't need this, oh, here I also put the specific cases, most likely, most of the time, we can use our own framework, why isn't, so I get two stuff into all these, no, no, no, this one, I think that's mentoring game, yeah, that's remote, keep it there, okay, I gotta speak with the cow, don't that yet? I ain't gonna speak to him for Bob, yeah, that's it, good, desi, good, I need time to proceed now,