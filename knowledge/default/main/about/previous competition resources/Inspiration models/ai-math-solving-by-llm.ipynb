{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca082907",
   "metadata": {
    "papermill": {
     "duration": 0.048671,
     "end_time": "2024-06-20T11:31:16.822438",
     "exception": false,
     "start_time": "2024-06-20T11:31:16.773767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Install Dependence Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "065be8fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:31:16.910292Z",
     "iopub.status.busy": "2024-06-20T11:31:16.909912Z",
     "iopub.status.idle": "2024-06-20T11:34:22.944794Z",
     "shell.execute_reply": "2024-06-20T11:34:22.943596Z"
    },
    "papermill": {
     "duration": 186.081534,
     "end_time": "2024-06-20T11:34:22.947269",
     "exception": false,
     "start_time": "2024-06-20T11:31:16.865735",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git\r\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-aahszz20\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-aahszz20\r\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 35b112d3442e4a9f3873191dcde7d1235b6c72eb\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (3.13.1)\r\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers==4.42.0.dev0)\r\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (2.31.0)\r\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.42.0.dev0)\r\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (0.4.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (4.66.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.0.dev0) (2024.2.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.0.dev0) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.42.0.dev0) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.42.0.dev0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.42.0.dev0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.42.0.dev0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.42.0.dev0) (2024.2.2)\r\n",
      "Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: transformers\r\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.42.0.dev0-py3-none-any.whl size=9165401 sha256=fdf4dab1b1dc5c2f51645b6b7d36e71c1b9b71fb38d94ee1aba6f9d8b27e1817\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-f9j34di6/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\r\n",
      "Successfully built transformers\r\n",
      "Installing collected packages: huggingface-hub, tokenizers, transformers\r\n",
      "  Attempting uninstall: huggingface-hub\r\n",
      "    Found existing installation: huggingface-hub 0.22.2\r\n",
      "    Uninstalling huggingface-hub-0.22.2:\r\n",
      "      Successfully uninstalled huggingface-hub-0.22.2\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.15.2\r\n",
      "    Uninstalling tokenizers-0.15.2:\r\n",
      "      Successfully uninstalled tokenizers-0.15.2\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.39.3\r\n",
      "    Uninstalling transformers-4.39.3:\r\n",
      "      Successfully uninstalled transformers-4.39.3\r\n",
      "Successfully installed huggingface-hub-0.23.4 tokenizers-0.19.1 transformers-4.42.0.dev0\r\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\r\n",
      "Collecting datasets\r\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\r\n",
      "Collecting accelerate\r\n",
      "  Downloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting bitsandbytes\r\n",
      "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\r\n",
      "Collecting requests>=2.32.2 (from datasets)\r\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting tqdm>=4.66.3 (from datasets)\r\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.2.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\r\n",
      "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading accelerate-0.31.0-py3-none-any.whl (309 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tqdm, requests, bitsandbytes, accelerate, datasets\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.66.1\r\n",
      "    Uninstalling tqdm-4.66.1:\r\n",
      "      Successfully uninstalled tqdm-4.66.1\r\n",
      "  Attempting uninstall: requests\r\n",
      "    Found existing installation: requests 2.31.0\r\n",
      "    Uninstalling requests-2.31.0:\r\n",
      "      Successfully uninstalled requests-2.31.0\r\n",
      "  Attempting uninstall: accelerate\r\n",
      "    Found existing installation: accelerate 0.29.3\r\n",
      "    Uninstalling accelerate-0.29.3:\r\n",
      "      Successfully uninstalled accelerate-0.29.3\r\n",
      "  Attempting uninstall: datasets\r\n",
      "    Found existing installation: datasets 2.18.0\r\n",
      "    Uninstalling datasets-2.18.0:\r\n",
      "      Successfully uninstalled datasets-2.18.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "keras-cv 0.8.2 requires keras-core, which is not installed.\r\n",
      "keras-nlp 0.9.3 requires keras-core, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\r\n",
      "beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.1.6 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-pubsub 2.19.0 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed accelerate-0.31.0 bitsandbytes-0.43.1 datasets-2.20.0 requests-2.32.3 tqdm-4.66.4\r\n",
      "Collecting langchain\r\n",
      "  Downloading langchain-0.2.5-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Collecting langchain-community\r\n",
      "  Downloading langchain_community-0.2.5-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting sentence-transformers\r\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting chromadb\r\n",
      "  Downloading chromadb-0.5.3-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting faiss-cpu\r\n",
      "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\r\n",
      "Collecting langchain-core<0.3.0,>=0.2.7 (from langchain)\r\n",
      "  Downloading langchain_core-0.2.9-py3-none-any.whl.metadata (6.0 kB)\r\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\r\n",
      "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\r\n",
      "  Downloading langsmith-0.1.81-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.6.4)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.42.0.dev0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.23.4)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\r\n",
      "Collecting build>=1.0.3 (from chromadb)\r\n",
      "  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\r\n",
      "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\r\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.108.0)\r\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.25.0)\r\n",
      "Collecting posthog>=2.4.0 (from chromadb)\r\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.9.0)\r\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\r\n",
      "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\r\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl.metadata (2.0 kB)\r\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\r\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.19.1)\r\n",
      "Collecting pypika>=0.48.9 (from chromadb)\r\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (7.4.0)\r\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb) (6.1.1)\r\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\r\n",
      "  Downloading grpcio-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\r\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\r\n",
      "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\r\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.9.0)\r\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\r\n",
      "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\r\n",
      "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\r\n",
      "Collecting orjson>=3.9.12 (from chromadb)\r\n",
      "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: httpx>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.27.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: packaging>=19.1 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (21.3)\r\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\r\n",
      "  Downloading pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.0.1)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.1)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\r\n",
      "Requirement already satisfied: starlette<0.33.0,>=0.29.0 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.32.0.post1)\r\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (4.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\r\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (3.6)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\r\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.26.1)\r\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\r\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\r\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (1.33)\r\n",
      "Collecting packaging>=19.1 (from build>=1.0.3->chromadb)\r\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\r\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\r\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\r\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\r\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\r\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\r\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\r\n",
      "Requirement already satisfied: opentelemetry-proto==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\r\n",
      "Collecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (69.0.3)\r\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\r\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\r\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\r\n",
      "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl.metadata (1.4 kB)\r\n",
      "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl.metadata (2.0 kB)\r\n",
      "Collecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting opentelemetry-instrumentation-asgi==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting opentelemetry-instrumentation==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\r\n",
      "Collecting opentelemetry-util-http==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\r\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\r\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\r\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\r\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\r\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\r\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain) (2.4)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.0)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\r\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\r\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\r\n",
      "Downloading langchain-0.2.5-py3-none-any.whl (974 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_community-0.2.5-py3-none-any.whl (2.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading chromadb-0.5.3-py3-none-any.whl (559 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading build-1.2.1-py3-none-any.whl (21 kB)\r\n",
      "Downloading grpcio-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_core-0.2.9-py3-none-any.whl (321 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\r\n",
      "Downloading langsmith-0.1.81-py3-none-any.whl (127 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.1/127.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl (11 kB)\r\n",
      "Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl (14 kB)\r\n",
      "Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl (28 kB)\r\n",
      "Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl (6.9 kB)\r\n",
      "Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\r\n",
      "Downloading packaging-24.1-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\r\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\r\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\r\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=3a12fdc181cd93a09655d195c841f000df0f53d42a1e0b9a2612467ca1421b4c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\r\n",
      "Successfully built pypika\r\n",
      "Installing collected packages: pypika, monotonic, mmh3, pyproject_hooks, packaging, orjson, opentelemetry-util-http, humanfriendly, grpcio, faiss-cpu, chroma-hnswlib, bcrypt, asgiref, posthog, coloredlogs, build, opentelemetry-instrumentation, onnxruntime, langsmith, kubernetes, opentelemetry-instrumentation-asgi, langchain-core, sentence-transformers, opentelemetry-instrumentation-fastapi, langchain-text-splitters, langchain, chromadb, langchain-community\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 21.3\r\n",
      "    Uninstalling packaging-21.3:\r\n",
      "      Successfully uninstalled packaging-21.3\r\n",
      "  Attempting uninstall: orjson\r\n",
      "    Found existing installation: orjson 3.9.10\r\n",
      "    Uninstalling orjson-3.9.10:\r\n",
      "      Successfully uninstalled orjson-3.9.10\r\n",
      "  Attempting uninstall: grpcio\r\n",
      "    Found existing installation: grpcio 1.51.1\r\n",
      "    Uninstalling grpcio-1.51.1:\r\n",
      "      Successfully uninstalled grpcio-1.51.1\r\n",
      "  Attempting uninstall: kubernetes\r\n",
      "    Found existing installation: kubernetes 26.1.0\r\n",
      "    Uninstalling kubernetes-26.1.0:\r\n",
      "      Successfully uninstalled kubernetes-26.1.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 23.8.0 requires cubinlinker, which is not installed.\r\n",
      "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 23.8.0 requires ptxcompiler, which is not installed.\r\n",
      "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "keras-cv 0.8.2 requires keras-core, which is not installed.\r\n",
      "keras-nlp 0.9.3 requires keras-core, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\r\n",
      "cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\r\n",
      "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "cudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\r\n",
      "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\r\n",
      "dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\r\n",
      "dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "distributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\r\n",
      "jupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 30.1.0 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed asgiref-3.8.1 bcrypt-4.1.3 build-1.2.1 chroma-hnswlib-0.7.3 chromadb-0.5.3 coloredlogs-15.0.1 faiss-cpu-1.8.0 grpcio-1.60.0 humanfriendly-10.0 kubernetes-30.1.0 langchain-0.2.5 langchain-community-0.2.5 langchain-core-0.2.9 langchain-text-splitters-0.2.1 langsmith-0.1.81 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.18.0 opentelemetry-instrumentation-0.43b0 opentelemetry-instrumentation-asgi-0.43b0 opentelemetry-instrumentation-fastapi-0.43b0 opentelemetry-util-http-0.43b0 orjson-3.10.5 packaging-24.1 posthog-3.5.0 pypika-0.48.9 pyproject_hooks-1.1.0 sentence-transformers-3.0.1\r\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.23.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.2.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\r\n",
      "Collecting peft\r\n",
      "  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting trl\r\n",
      "  Downloading trl-0.9.4-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (24.1)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\r\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\r\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.42.0.dev0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\r\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.31.0)\r\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.4)\r\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl) (2.20.0)\r\n",
      "Collecting tyro>=0.5.11 (from trl)\r\n",
      "  Downloading tyro-0.8.4-py3-none-any.whl.metadata (7.9 kB)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\r\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.15)\r\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.0)\r\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\r\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (15.0.2)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.6)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (2.1.4)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.70.16)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.9.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.4)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\r\n",
      "Downloading peft-0.11.1-py3-none-any.whl (251 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading trl-0.9.4-py3-none-any.whl (226 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tyro-0.8.4-py3-none-any.whl (102 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/102.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\r\n",
      "Installing collected packages: shtab, tyro, trl, peft\r\n",
      "Successfully installed peft-0.11.1 shtab-1.7.1 trl-0.9.4 tyro-0.8.4\r\n",
      "Requirement already satisfied: umap-learn in /opt/conda/lib/python3.10/site-packages (0.5.6)\r\n",
      "Collecting evaluate\r\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\r\n",
      "Collecting deepeval\r\n",
      "  Downloading deepeval-0.21.59-py3-none-any.whl.metadata (986 bytes)\r\n",
      "Collecting weave\r\n",
      "  Downloading weave-0.50.5-py3-none-any.whl.metadata (8.8 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (1.11.4)\r\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (1.2.2)\r\n",
      "Requirement already satisfied: numba>=0.51.2 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (0.58.1)\r\n",
      "Requirement already satisfied: pynndescent>=0.5 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (0.5.12)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from umap-learn) (4.66.4)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.20.0)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.23.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (24.1)\r\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from deepeval) (8.1.1)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from deepeval) (0.9.0)\r\n",
      "Requirement already satisfied: typer in /opt/conda/lib/python3.10/site-packages (from deepeval) (0.9.0)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from deepeval) (13.7.0)\r\n",
      "Collecting protobuf==4.25.1 (from deepeval)\r\n",
      "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\r\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from deepeval) (2.5.3)\r\n",
      "Requirement already satisfied: sentry-sdk in /opt/conda/lib/python3.10/site-packages (from deepeval) (1.45.0)\r\n",
      "Collecting pytest-repeat (from deepeval)\r\n",
      "  Downloading pytest_repeat-0.9.3-py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Collecting pytest-xdist (from deepeval)\r\n",
      "  Downloading pytest_xdist-3.6.1-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Collecting portalocker (from deepeval)\r\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\r\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (from deepeval) (0.2.5)\r\n",
      "Requirement already satisfied: langchain-core in /opt/conda/lib/python3.10/site-packages (from deepeval) (0.2.9)\r\n",
      "Collecting langchain-openai (from deepeval)\r\n",
      "  Downloading langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting ragas (from deepeval)\r\n",
      "  Downloading ragas-0.1.9-py3-none-any.whl.metadata (5.2 kB)\r\n",
      "Collecting docx2txt~=0.8 (from deepeval)\r\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=6.0.2 in /opt/conda/lib/python3.10/site-packages (from deepeval) (6.11.0)\r\n",
      "Requirement already satisfied: tenacity~=8.2.3 in /opt/conda/lib/python3.10/site-packages (from deepeval) (8.2.3)\r\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from deepeval) (1.22.0)\r\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from deepeval) (1.22.0)\r\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 (from deepeval)\r\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from weave) (4.9.0)\r\n",
      "Requirement already satisfied: pyarrow>=14.0.1 in /opt/conda/lib/python3.10/site-packages (from weave) (15.0.2)\r\n",
      "Collecting openai>=1.0.0 (from weave)\r\n",
      "  Downloading openai-1.35.1-py3-none-any.whl.metadata (21 kB)\r\n",
      "Collecting tiktoken>=0.4.0 (from weave)\r\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: aiohttp>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from weave) (3.9.1)\r\n",
      "Requirement already satisfied: aiofiles>=22.1.0 in /opt/conda/lib/python3.10/site-packages (from weave) (22.1.0)\r\n",
      "Collecting aioprocessing>=2.0.1 (from weave)\r\n",
      "  Downloading aioprocessing-2.0.1-py3-none-any.whl.metadata (7.6 kB)\r\n",
      "Collecting Werkzeug>=3.0.3 (from weave)\r\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Collecting janus>=1.0.0 (from weave)\r\n",
      "  Downloading janus-1.0.0-py3-none-any.whl.metadata (4.5 kB)\r\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from weave) (2.0.7)\r\n",
      "Requirement already satisfied: wandb>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from weave) (0.16.6)\r\n",
      "Collecting graphql-core>3 (from weave)\r\n",
      "  Downloading graphql_core-3.2.3-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting gql>=3.4.1 (from gql[requests]>=3.4.1->weave)\r\n",
      "  Downloading gql-3.5.0-py2.py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Collecting analytics-python>=1.2.9 (from weave)\r\n",
      "  Downloading analytics_python-1.4.post1-py2.py3-none-any.whl.metadata (2.0 kB)\r\n",
      "INFO: pip is looking at multiple versions of weave to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting weave\r\n",
      "  Downloading weave-0.50.4-py3-none-any.whl.metadata (8.8 kB)\r\n",
      "  Downloading weave-0.50.3-py3-none-any.whl.metadata (8.3 kB)\r\n",
      "  Downloading weave-0.50.2-py3-none-any.whl.metadata (8.3 kB)\r\n",
      "Requirement already satisfied: Werkzeug>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from weave) (3.0.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.3->weave) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.3->weave) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.3->weave) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.3->weave) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.3->weave) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.3->weave) (4.0.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from analytics-python>=1.2.9->weave) (1.16.0)\r\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/conda/lib/python3.10/site-packages (from analytics-python>=1.2.9->weave) (1.6)\r\n",
      "Collecting backoff==1.10.0 (from analytics-python>=1.2.9->weave)\r\n",
      "  Downloading backoff-1.10.0-py2.py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: python-dateutil>2.1 in /opt/conda/lib/python3.10/site-packages (from analytics-python>=1.2.9->weave) (2.9.0.post0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\r\n",
      "INFO: pip is looking at multiple versions of gql to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting gql>=3.4.1 (from gql[requests]>=3.4.1->weave)\r\n",
      "  Downloading gql-3.4.1-py2.py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Collecting analytics-python>=1.2.9 (from weave)\r\n",
      "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\r\n",
      "  Downloading analytics_python-1.3.1-py2.py3-none-any.whl.metadata (1.8 kB)\r\n",
      "  Downloading analytics_python-1.2.9-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: backoff<3.0,>=1.11.1 in /opt/conda/lib/python3.10/site-packages (from gql>=3.4.1->gql[requests]>=3.4.1->weave) (2.2.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3.0 in /opt/conda/lib/python3.10/site-packages (from gql>=3.4.1->gql[requests]>=3.4.1->weave) (4.2.0)\r\n",
      "Collecting requests-toolbelt<2,>=1.0.0 (from gql[requests]>=3.4.1->weave)\r\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.0.2->deepeval) (3.17.0)\r\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.2->umap-learn) (0.41.1)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.0.0->weave) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.0.0->weave) (0.27.0)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai>=1.0.0->weave) (1.3.0)\r\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.14.0->deepeval) (1.2.14)\r\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.62.0)\r\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.60.0)\r\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\r\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\r\n",
      "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.14.0 (from deepeval)\r\n",
      "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting opentelemetry-api<2.0.0,>=1.14.0 (from deepeval)\r\n",
      "  Using cached opentelemetry_api-1.25.0-py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-sdk<2.0.0,>=1.14.0->deepeval)\r\n",
      "  Using cached opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->deepeval) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic->deepeval) (2.14.6)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.10/site-packages (from pynndescent>=0.5->umap-learn) (1.4.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->deepeval) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->deepeval) (2.17.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22->umap-learn) (3.2.0)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken>=0.4.0->weave) (2023.12.25)\r\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.16.4->weave) (8.1.7)\r\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.16.4->weave) (3.1.41)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.16.4->weave) (5.9.3)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.16.4->weave) (0.4.0)\r\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb>=0.16.4->weave) (1.3.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb>=0.16.4->weave) (69.0.3)\r\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.16.4->weave) (1.4.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from Werkzeug>=2.0.0->weave) (2.1.3)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain->deepeval) (2.0.25)\r\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain->deepeval) (0.2.1)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain->deepeval) (0.1.81)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core->deepeval) (1.33)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\r\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->deepeval) (2.0.0)\r\n",
      "Requirement already satisfied: pluggy<2.0,>=1.4 in /opt/conda/lib/python3.10/site-packages (from pytest->deepeval) (1.4.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->deepeval) (1.2.0)\r\n",
      "Requirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest->deepeval) (2.0.1)\r\n",
      "Collecting execnet>=2.1 (from pytest-xdist->deepeval)\r\n",
      "  Downloading execnet-2.1.1-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: langchain-community in /opt/conda/lib/python3.10/site-packages (from ragas->deepeval) (0.2.5)\r\n",
      "Collecting pysbd>=0.3.4 (from ragas->deepeval)\r\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ragas->deepeval) (1.5.8)\r\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.14.0->deepeval) (1.14.1)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.16.4->weave) (4.0.11)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->weave) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->weave) (0.14.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->deepeval) (2.4)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->deepeval) (3.10.5)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->deepeval) (0.1.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain->deepeval) (3.0.3)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community->ragas->deepeval) (0.6.4)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval) (3.21.1)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval) (0.9.0)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.16.4->weave) (5.0.1)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval) (1.0.0)\r\n",
      "Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading deepeval-0.21.59-py3-none-any.whl (259 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.7/259.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading weave-0.50.2-py3-none-any.whl (28.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aioprocessing-2.0.1-py3-none-any.whl (14 kB)\r\n",
      "Downloading analytics_python-1.2.9-py2.py3-none-any.whl (13 kB)\r\n",
      "Downloading gql-3.5.0-py2.py3-none-any.whl (74 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading janus-1.0.0-py3-none-any.whl (6.9 kB)\r\n",
      "Downloading openai-1.35.1-py3-none-any.whl (326 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.8/326.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\r\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\r\n",
      "Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_openai-0.1.8-py3-none-any.whl (38 kB)\r\n",
      "Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\r\n",
      "Downloading pytest_repeat-0.9.3-py3-none-any.whl (4.2 kB)\r\n",
      "Downloading pytest_xdist-3.6.1-py3-none-any.whl (46 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ragas-0.1.9-py3-none-any.whl (86 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.1/86.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading execnet-2.1.1-py3-none-any.whl (40 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: docx2txt\r\n",
      "  Building wheel for docx2txt (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=7cea2d1a0818effeee2556f02c1997bee808aa5a1d1534103cde358efce8449e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\r\n",
      "Successfully built docx2txt\r\n",
      "Installing collected packages: docx2txt, pysbd, protobuf, portalocker, janus, graphql-core, execnet, aioprocessing, tiktoken, requests-toolbelt, pytest-xdist, pytest-repeat, opentelemetry-proto, opentelemetry-api, gql, analytics-python, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, openai, weave, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, langchain-openai, evaluate, ragas, deepeval\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 3.20.3\r\n",
      "    Uninstalling protobuf-3.20.3:\r\n",
      "      Successfully uninstalled protobuf-3.20.3\r\n",
      "  Attempting uninstall: requests-toolbelt\r\n",
      "    Found existing installation: requests-toolbelt 0.10.1\r\n",
      "    Uninstalling requests-toolbelt-0.10.1:\r\n",
      "      Successfully uninstalled requests-toolbelt-0.10.1\r\n",
      "  Attempting uninstall: opentelemetry-proto\r\n",
      "    Found existing installation: opentelemetry-proto 1.22.0\r\n",
      "    Uninstalling opentelemetry-proto-1.22.0:\r\n",
      "      Successfully uninstalled opentelemetry-proto-1.22.0\r\n",
      "  Attempting uninstall: opentelemetry-api\r\n",
      "    Found existing installation: opentelemetry-api 1.22.0\r\n",
      "    Uninstalling opentelemetry-api-1.22.0:\r\n",
      "      Successfully uninstalled opentelemetry-api-1.22.0\r\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\r\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.43b0\r\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.43b0:\r\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.43b0\r\n",
      "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\r\n",
      "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.22.0\r\n",
      "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.22.0:\r\n",
      "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.22.0\r\n",
      "  Attempting uninstall: opentelemetry-sdk\r\n",
      "    Found existing installation: opentelemetry-sdk 1.22.0\r\n",
      "    Uninstalling opentelemetry-sdk-1.22.0:\r\n",
      "      Successfully uninstalled opentelemetry-sdk-1.22.0\r\n",
      "  Attempting uninstall: opentelemetry-exporter-otlp-proto-grpc\r\n",
      "    Found existing installation: opentelemetry-exporter-otlp-proto-grpc 1.22.0\r\n",
      "    Uninstalling opentelemetry-exporter-otlp-proto-grpc-1.22.0:\r\n",
      "      Successfully uninstalled opentelemetry-exporter-otlp-proto-grpc-1.22.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 23.8.0 requires cubinlinker, which is not installed.\r\n",
      "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 23.8.0 requires ptxcompiler, which is not installed.\r\n",
      "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.1 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\r\n",
      "cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\r\n",
      "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "cudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\r\n",
      "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.25.1 which is incompatible.\r\n",
      "google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.1 which is incompatible.\r\n",
      "google-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 4.25.1 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 30.1.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.1 which is incompatible.\r\n",
      "kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\r\n",
      "kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.1 which is incompatible.\r\n",
      "opentelemetry-exporter-otlp 1.22.0 requires opentelemetry-exporter-otlp-proto-grpc==1.22.0, but you have opentelemetry-exporter-otlp-proto-grpc 1.25.0 which is incompatible.\r\n",
      "opentelemetry-exporter-otlp-proto-http 1.22.0 requires opentelemetry-exporter-otlp-proto-common==1.22.0, but you have opentelemetry-exporter-otlp-proto-common 1.25.0 which is incompatible.\r\n",
      "opentelemetry-exporter-otlp-proto-http 1.22.0 requires opentelemetry-proto==1.22.0, but you have opentelemetry-proto 1.25.0 which is incompatible.\r\n",
      "opentelemetry-exporter-otlp-proto-http 1.22.0 requires opentelemetry-sdk~=1.22.0, but you have opentelemetry-sdk 1.25.0 which is incompatible.\r\n",
      "opentelemetry-instrumentation-asgi 0.43b0 requires opentelemetry-semantic-conventions==0.43b0, but you have opentelemetry-semantic-conventions 0.46b0 which is incompatible.\r\n",
      "opentelemetry-instrumentation-fastapi 0.43b0 requires opentelemetry-semantic-conventions==0.43b0, but you have opentelemetry-semantic-conventions 0.46b0 which is incompatible.\r\n",
      "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 4.25.1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\r\n",
      "tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.1 which is incompatible.\r\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed aioprocessing-2.0.1 analytics-python-1.2.9 deepeval-0.21.59 docx2txt-0.8 evaluate-0.4.2 execnet-2.1.1 gql-3.5.0 graphql-core-3.2.3 janus-1.0.0 langchain-openai-0.1.8 openai-1.35.1 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 portalocker-2.8.2 protobuf-4.21.12 pysbd-0.3.4 pytest-repeat-0.9.3 pytest-xdist-3.6.1 ragas-0.1.9 requests-toolbelt-1.0.0 tiktoken-0.7.0 weave-0.50.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers.git  # install transformer from source\n",
    "# !pip install --upgrade torch datasets accelerate peft bitsandbytes trl\n",
    "# !pip install --upgrade accelerate peft bitsandbytes trl\n",
    "!pip install --upgrade datasets accelerate bitsandbytes  # add datasets, accelerate , bitsndbytes\n",
    "!pip install langchain  langchain-community sentence-transformers chromadb  faiss-cpu #pypdf\n",
    "!pip install --upgrade huggingface_hub\n",
    "!pip install -qU langchain-text-splitters\n",
    "# for loRA fine tuning \n",
    "!pip install --upgrade peft trl\n",
    "# for advance RAG & LLM evalution \n",
    "!pip install umap-learn evaluate deepeval weave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff431270",
   "metadata": {
    "papermill": {
     "duration": 0.087503,
     "end_time": "2024-06-20T11:34:23.121490",
     "exception": false,
     "start_time": "2024-06-20T11:34:23.033987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d72cd0b",
   "metadata": {
    "papermill": {
     "duration": 0.082554,
     "end_time": "2024-06-20T11:34:23.289215",
     "exception": false,
     "start_time": "2024-06-20T11:34:23.206661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1d27b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:23.457327Z",
     "iopub.status.busy": "2024-06-20T11:34:23.456993Z",
     "iopub.status.idle": "2024-06-20T11:34:23.461872Z",
     "shell.execute_reply": "2024-06-20T11:34:23.460937Z"
    },
    "papermill": {
     "duration": 0.090504,
     "end_time": "2024-06-20T11:34:23.463982",
     "exception": false,
     "start_time": "2024-06-20T11:34:23.373478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json, time\n",
    "import gc\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30636625",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:23.645271Z",
     "iopub.status.busy": "2024-06-20T11:34:23.644893Z",
     "iopub.status.idle": "2024-06-20T11:34:30.623753Z",
     "shell.execute_reply": "2024-06-20T11:34:30.622864Z"
    },
    "papermill": {
     "duration": 7.079088,
     "end_time": "2024-06-20T11:34:30.626130",
     "exception": false,
     "start_time": "2024-06-20T11:34:23.547042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoTokenizer,BitsAndBytesConfig,AutoModelForCausalLM, TrainingArguments\n",
    "# from langchain.document_loaders import TextLoader # old version\n",
    "from langchain_community.document_loaders import TextLoader # new version\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "# Text embedding / Texxt Splitter for RAG \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter , CharacterTextSplitter # Text Splitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "\n",
    "# Adv RAG library \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d85a837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:30.792300Z",
     "iopub.status.busy": "2024-06-20T11:34:30.791785Z",
     "iopub.status.idle": "2024-06-20T11:34:30.870774Z",
     "shell.execute_reply": "2024-06-20T11:34:30.869879Z"
    },
    "papermill": {
     "duration": 0.163559,
     "end_time": "2024-06-20T11:34:30.872832",
     "exception": false,
     "start_time": "2024-06-20T11:34:30.709273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df1f0d3",
   "metadata": {
    "papermill": {
     "duration": 0.082841,
     "end_time": "2024-06-20T11:34:31.037830",
     "exception": false,
     "start_time": "2024-06-20T11:34:30.954989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Use Weights and Bias for LLM evaluation setup in Kaggle, click link for detail \n",
    "### use W&B need setup your Access token key\n",
    "<https://www.kaggle.com/code/samuelcortinhas/weights-biases-tutorial-beginner>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de5a64ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:31.217597Z",
     "iopub.status.busy": "2024-06-20T11:34:31.217220Z",
     "iopub.status.idle": "2024-06-20T11:34:33.197003Z",
     "shell.execute_reply": "2024-06-20T11:34:33.196009Z"
    },
    "papermill": {
     "duration": 2.070326,
     "end_time": "2024-06-20T11:34:33.199020",
     "exception": false,
     "start_time": "2024-06-20T11:34:31.128694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Enable/Disable Function\n",
    "FEW_SHOT_TEST= True# False\n",
    "USE_RAG = True#False #True#True\n",
    "USE_WANDB = True # for  LLM evalution and debug tools  \n",
    "# USE_TRAIN = True\n",
    "if device.type == \"cuda\": #requred GPU support for fine turning \n",
    "    USE_TRAIN =  True#False#True\n",
    "else:\n",
    "    USE_TRAIN= False\n",
    "\n",
    "if USE_WANDB:\n",
    "    # train report to  W&B tool\n",
    "    import wandb\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    reportTo= \"wandb\"\n",
    "    user_secrets = UserSecretsClient()\n",
    "    my_secret = user_secrets.get_secret(\"wandb_api_key\") \n",
    "    wandb.login(key=my_secret) # login \n",
    "else: \n",
    "    reportTo = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4576ead7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:33.367598Z",
     "iopub.status.busy": "2024-06-20T11:34:33.367259Z",
     "iopub.status.idle": "2024-06-20T11:34:33.373013Z",
     "shell.execute_reply": "2024-06-20T11:34:33.372170Z"
    },
    "papermill": {
     "duration": 0.090774,
     "end_time": "2024-06-20T11:34:33.374952",
     "exception": false,
     "start_time": "2024-06-20T11:34:33.284178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a6dcecd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:33.545422Z",
     "iopub.status.busy": "2024-06-20T11:34:33.544981Z",
     "iopub.status.idle": "2024-06-20T11:34:45.874976Z",
     "shell.execute_reply": "2024-06-20T11:34:45.874177Z"
    },
    "papermill": {
     "duration": 12.419414,
     "end_time": "2024-06-20T11:34:45.877580",
     "exception": false,
     "start_time": "2024-06-20T11:34:33.458166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 11:34:35.855726: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-20 11:34:35.855831: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-20 11:34:35.954799: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "if device.type == \"cuda\": #requred GPU support\n",
    "    # for LoRA fine tuning\n",
    "    from trl import SFTTrainer\n",
    "    from peft import LoraConfig, PeftModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e66285",
   "metadata": {
    "papermill": {
     "duration": 0.081585,
     "end_time": "2024-06-20T11:34:46.042982",
     "exception": false,
     "start_time": "2024-06-20T11:34:45.961397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Show available project file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bd8e736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:46.217956Z",
     "iopub.status.busy": "2024-06-20T11:34:46.216886Z",
     "iopub.status.idle": "2024-06-20T11:34:46.292648Z",
     "shell.execute_reply": "2024-06-20T11:34:46.291348Z"
    },
    "papermill": {
     "duration": 0.165326,
     "end_time": "2024-06-20T11:34:46.294742",
     "exception": false,
     "start_time": "2024-06-20T11:34:46.129416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ai-mathematical-olympiad-prize/sample_submission.csv\n",
      "/kaggle/input/ai-mathematical-olympiad-prize/AIMO Prize - Note on Language and Notation.pdf\n",
      "/kaggle/input/ai-mathematical-olympiad-prize/train.csv\n",
      "/kaggle/input/ai-mathematical-olympiad-prize/test.csv\n",
      "/kaggle/input/ai-mathematical-olympiad-prize/aimo/competition.cpython-310-x86_64-linux-gnu.so\n",
      "/kaggle/input/ai-mathematical-olympiad-prize/aimo/__init__.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/model.safetensors.index.json\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00003-of-00004.safetensors\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/config.json\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/LICENSE\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00001-of-00004.safetensors\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/model.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/USE_POLICY.md\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer.json\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer_config.json\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/example_text_completion.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/test_tokenizer.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/requirements.txt\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00004-of-00004.safetensors\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/eval_details.md\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/special_tokens_map.json\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/generation.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00002-of-00004.safetensors\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/__init__.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/example_chat_completion.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/setup.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/generation_config.json\n",
      "/kaggle/input/gemma/transformers/2b-it/3/model.safetensors.index.json\n",
      "/kaggle/input/gemma/transformers/2b-it/3/gemma-2b-it.gguf\n",
      "/kaggle/input/gemma/transformers/2b-it/3/config.json\n",
      "/kaggle/input/gemma/transformers/2b-it/3/model-00001-of-00002.safetensors\n",
      "/kaggle/input/gemma/transformers/2b-it/3/model-00002-of-00002.safetensors\n",
      "/kaggle/input/gemma/transformers/2b-it/3/tokenizer.json\n",
      "/kaggle/input/gemma/transformers/2b-it/3/tokenizer_config.json\n",
      "/kaggle/input/gemma/transformers/2b-it/3/special_tokens_map.json\n",
      "/kaggle/input/gemma/transformers/2b-it/3/.gitattributes\n",
      "/kaggle/input/gemma/transformers/2b-it/3/tokenizer.model\n",
      "/kaggle/input/gemma/transformers/2b-it/3/generation_config.json\n",
      "/kaggle/input/gemma/transformers/7b-it/3/model.safetensors.index.json\n",
      "/kaggle/input/gemma/transformers/7b-it/3/model-00003-of-00004.safetensors\n",
      "/kaggle/input/gemma/transformers/7b-it/3/config.json\n",
      "/kaggle/input/gemma/transformers/7b-it/3/gemma-7b-it.gguf\n",
      "/kaggle/input/gemma/transformers/7b-it/3/model-00001-of-00004.safetensors\n",
      "/kaggle/input/gemma/transformers/7b-it/3/tokenizer.json\n",
      "/kaggle/input/gemma/transformers/7b-it/3/tokenizer_config.json\n",
      "/kaggle/input/gemma/transformers/7b-it/3/model-00004-of-00004.safetensors\n",
      "/kaggle/input/gemma/transformers/7b-it/3/special_tokens_map.json\n",
      "/kaggle/input/gemma/transformers/7b-it/3/.gitattributes\n",
      "/kaggle/input/gemma/transformers/7b-it/3/model-00002-of-00004.safetensors\n",
      "/kaggle/input/gemma/transformers/7b-it/3/tokenizer.model\n",
      "/kaggle/input/gemma/transformers/7b-it/3/generation_config.json\n",
      "/kaggle/input/math-qa-for-aqua-rat-dataset/MathQA/constant_list.txt\n",
      "/kaggle/input/math-qa-for-aqua-rat-dataset/MathQA/dev.json\n",
      "/kaggle/input/math-qa-for-aqua-rat-dataset/MathQA/challenge_test.json\n",
      "/kaggle/input/math-qa-for-aqua-rat-dataset/MathQA/operation_list.txt\n",
      "/kaggle/input/math-qa-for-aqua-rat-dataset/MathQA/train.json\n",
      "/kaggle/input/math-qa-for-aqua-rat-dataset/MathQA/test.json\n",
      "/kaggle/input/math-qsa-dataset/train.csv\n",
      "/kaggle/input/math-qsa-dataset/test.csv\n",
      "/kaggle/input/aimo-external-dataset/external_df.csv\n",
      "/kaggle/input/gsm8k-grade-school-math-8k-dataset-for-llm/gsm8k/README.md\n",
      "/kaggle/input/gsm8k-grade-school-math-8k-dataset-for-llm/gsm8k/socratic/train-00000-of-00001.parquet\n",
      "/kaggle/input/gsm8k-grade-school-math-8k-dataset-for-llm/gsm8k/socratic/test-00000-of-00001.parquet\n",
      "/kaggle/input/gsm8k-grade-school-math-8k-dataset-for-llm/gsm8k/main/train-00000-of-00001.parquet\n",
      "/kaggle/input/gsm8k-grade-school-math-8k-dataset-for-llm/gsm8k/main/test-00000-of-00001.parquet\n"
     ]
    }
   ],
   "source": [
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1dd4f32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:46.459885Z",
     "iopub.status.busy": "2024-06-20T11:34:46.459253Z",
     "iopub.status.idle": "2024-06-20T11:34:46.464691Z",
     "shell.execute_reply": "2024-06-20T11:34:46.463752Z"
    },
    "papermill": {
     "duration": 0.089987,
     "end_time": "2024-06-20T11:34:46.466649",
     "exception": false,
     "start_time": "2024-06-20T11:34:46.376662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampleSubmitFile = \"/kaggle/input/ai-mathematical-olympiad-prize/sample_submission.csv\"\n",
    "trainFile = \"/kaggle/input/ai-mathematical-olympiad-prize/train.csv\"\n",
    "testFile = \"/kaggle/input/ai-mathematical-olympiad-prize/test.csv\"\n",
    "mathQSATrainFile = \"/kaggle/input/math-qsa-dataset/train.csv\"\n",
    "mathQSATestFile = \"/kaggle/input/math-qsa-dataset/test.csv\"\n",
    "gsm8kTrainFile = \"/kaggle/input/gsm8k-grade-school-math-8k-dataset-for-llm/gsm8k/main/train-00000-of-00001.parquet\"\n",
    "gsm8kTestFile = \"/kaggle/input/gsm8k-grade-school-math-8k-dataset-for-llm/gsm8k/main/test-00000-of-00001.parquet\"\n",
    "mathQATrainFile = \"/kaggle/input/math-qa-for-aqua-rat-dataset/MathQA/train.json\"\n",
    "mathQATestFile = \"/kaggle/input/math-qa-for-aqua-rat-dataset/MathQA/test.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec27c8",
   "metadata": {
    "papermill": {
     "duration": 0.084587,
     "end_time": "2024-06-20T11:34:46.636209",
     "exception": false,
     "start_time": "2024-06-20T11:34:46.551622",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1373a7b0",
   "metadata": {
    "papermill": {
     "duration": 0.081586,
     "end_time": "2024-06-20T11:34:46.801916",
     "exception": false,
     "start_time": "2024-06-20T11:34:46.720330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e094a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:46.970765Z",
     "iopub.status.busy": "2024-06-20T11:34:46.970028Z",
     "iopub.status.idle": "2024-06-20T11:34:47.277439Z",
     "shell.execute_reply": "2024-06-20T11:34:47.276582Z"
    },
    "papermill": {
     "duration": 0.39508,
     "end_time": "2024-06-20T11:34:47.279342",
     "exception": false,
     "start_time": "2024-06-20T11:34:46.884262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65ad901d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:47.473594Z",
     "iopub.status.busy": "2024-06-20T11:34:47.472784Z",
     "iopub.status.idle": "2024-06-20T11:34:47.497325Z",
     "shell.execute_reply": "2024-06-20T11:34:47.496446Z"
    },
    "papermill": {
     "duration": 0.120895,
     "end_time": "2024-06-20T11:34:47.499387",
     "exception": false,
     "start_time": "2024-06-20T11:34:47.378492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>problem</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>229ee8</td>\n",
       "      <td>Let $k, l &gt; 0$ be parameters. The parabola $y ...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>246d26</td>\n",
       "      <td>Each of the three-digits numbers $111$ to $999...</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2fc4ad</td>\n",
       "      <td>Let the `sparkle' operation on positive intege...</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>430b63</td>\n",
       "      <td>What is the minimum value of $5x^2+5y^2-8xy$ w...</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5277ed</td>\n",
       "      <td>There exists a unique increasing geometric seq...</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>739bc9</td>\n",
       "      <td>For how many positive integers $m$ does the eq...</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>82e2a0</td>\n",
       "      <td>Suppose that we roll four 6-sided fair dice wi...</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8ee6f3</td>\n",
       "      <td>The points $\\left(x, y\\right)$ satisfying $((\\...</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bedda4</td>\n",
       "      <td>Let $ABCD$ be a unit square. Let $P$ be the po...</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d7e9c9</td>\n",
       "      <td>A function $f: \\mathbb N \\to \\mathbb N$ satisf...</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                            problem  answer\n",
       "0  229ee8  Let $k, l > 0$ be parameters. The parabola $y ...      52\n",
       "1  246d26  Each of the three-digits numbers $111$ to $999...     250\n",
       "2  2fc4ad  Let the `sparkle' operation on positive intege...     702\n",
       "3  430b63  What is the minimum value of $5x^2+5y^2-8xy$ w...     800\n",
       "4  5277ed  There exists a unique increasing geometric seq...     211\n",
       "5  739bc9  For how many positive integers $m$ does the eq...     199\n",
       "6  82e2a0  Suppose that we roll four 6-sided fair dice wi...     185\n",
       "7  8ee6f3  The points $\\left(x, y\\right)$ satisfying $((\\...     320\n",
       "8  bedda4  Let $ABCD$ be a unit square. Let $P$ be the po...     480\n",
       "9  d7e9c9  A function $f: \\mathbb N \\to \\mathbb N$ satisf...     199"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF = pd.read_csv(trainFile)\n",
    "trainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1598280e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:47.667890Z",
     "iopub.status.busy": "2024-06-20T11:34:47.667568Z",
     "iopub.status.idle": "2024-06-20T11:34:47.685613Z",
     "shell.execute_reply": "2024-06-20T11:34:47.684719Z"
    },
    "papermill": {
     "duration": 0.105084,
     "end_time": "2024-06-20T11:34:47.687696",
     "exception": false,
     "start_time": "2024-06-20T11:34:47.582612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>339.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>243.610709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>199.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>230.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>800.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           answer\n",
       "count   10.000000\n",
       "mean   339.800000\n",
       "std    243.610709\n",
       "min     52.000000\n",
       "25%    199.000000\n",
       "50%    230.500000\n",
       "75%    440.000000\n",
       "max    800.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cdb9f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:47.854966Z",
     "iopub.status.busy": "2024-06-20T11:34:47.854663Z",
     "iopub.status.idle": "2024-06-20T11:34:47.860415Z",
     "shell.execute_reply": "2024-06-20T11:34:47.859591Z"
    },
    "papermill": {
     "duration": 0.089925,
     "end_time": "2024-06-20T11:34:47.862191",
     "exception": false,
     "start_time": "2024-06-20T11:34:47.772266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.iloc[7][\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f3eb149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:48.029674Z",
     "iopub.status.busy": "2024-06-20T11:34:48.029334Z",
     "iopub.status.idle": "2024-06-20T11:34:48.051178Z",
     "shell.execute_reply": "2024-06-20T11:34:48.050026Z"
    },
    "papermill": {
     "duration": 0.107339,
     "end_time": "2024-06-20T11:34:48.053160",
     "exception": false,
     "start_time": "2024-06-20T11:34:47.945821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   row_id   3 non-null      int64 \n",
      " 1   id       3 non-null      object\n",
      " 2   problem  3 non-null      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 200.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "testDF = pd.read_csv(testFile)\n",
    "testDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5871d11e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:48.229042Z",
     "iopub.status.busy": "2024-06-20T11:34:48.228694Z",
     "iopub.status.idle": "2024-06-20T11:34:48.359207Z",
     "shell.execute_reply": "2024-06-20T11:34:48.358325Z"
    },
    "papermill": {
     "duration": 0.217099,
     "end_time": "2024-06-20T11:34:48.361420",
     "exception": false,
     "start_time": "2024-06-20T11:34:48.144321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>level</th>\n",
       "      <th>type</th>\n",
       "      <th>solution</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The United States Postal Service charges an ex...</td>\n",
       "      <td>Level 3</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>We calculate the desired ratio for each envelo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many integers between 1000 and 2000 have a...</td>\n",
       "      <td>Level 4</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>A number with 15, 20 and 25 as factors must be...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Given that $n$ is an integer and $0 &lt; 4n &lt;30$,...</td>\n",
       "      <td>Level 2</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>Dividing by $4$, we have $0&lt;n&lt;7\\frac{1}{2}$. T...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many integers between $100$ and $150$ have...</td>\n",
       "      <td>Level 4</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>We will break up the problem into cases based ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regular pentagon $ABCDE$ and regular hexagon $...</td>\n",
       "      <td>Level 4</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>We know that the sum of the degree measures of...</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             problem    level        type  \\\n",
       "0  The United States Postal Service charges an ex...  Level 3  Prealgebra   \n",
       "1  How many integers between 1000 and 2000 have a...  Level 4  Prealgebra   \n",
       "2  Given that $n$ is an integer and $0 < 4n <30$,...  Level 2  Prealgebra   \n",
       "3  How many integers between $100$ and $150$ have...  Level 4  Prealgebra   \n",
       "4  Regular pentagon $ABCDE$ and regular hexagon $...  Level 4  Prealgebra   \n",
       "\n",
       "                                            solution answer  \n",
       "0  We calculate the desired ratio for each envelo...      3  \n",
       "1  A number with 15, 20 and 25 as factors must be...      3  \n",
       "2  Dividing by $4$, we have $0<n<7\\frac{1}{2}$. T...     28  \n",
       "3  We will break up the problem into cases based ...     18  \n",
       "4  We know that the sum of the degree measures of...    132  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainQSADF = pd.read_csv(mathQSATrainFile)\n",
    "trainQSADF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a03ef505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:48.534398Z",
     "iopub.status.busy": "2024-06-20T11:34:48.534063Z",
     "iopub.status.idle": "2024-06-20T11:34:48.540189Z",
     "shell.execute_reply": "2024-06-20T11:34:48.539369Z"
    },
    "papermill": {
     "duration": 0.093925,
     "end_time": "2024-06-20T11:34:48.542235",
     "exception": false,
     "start_time": "2024-06-20T11:34:48.448310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The United States Postal Service charges an extra $\\\\$0.11$ in postage if the length of an envelope, in inches, divided by its height, in inches, is less than $1.3$ or greater than $2.5.$ For how many of these four envelopes must the extra $\\\\$0.11$ in postage be paid? \\\\begin{tabular}[t]{ccc}\\nEnvelope & Length in inches & Height in inches\\\\\\\\\\\\hline\\nA &6 &4\\\\\\\\\\nB &9 &3\\\\\\\\\\nC &6 &6\\\\\\\\\\nD &11 &4\\n\\\\end{tabular}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainQSADF[\"problem\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "616180f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:48.719765Z",
     "iopub.status.busy": "2024-06-20T11:34:48.719137Z",
     "iopub.status.idle": "2024-06-20T11:34:48.761152Z",
     "shell.execute_reply": "2024-06-20T11:34:48.760139Z"
    },
    "papermill": {
     "duration": 0.138352,
     "end_time": "2024-06-20T11:34:48.763207",
     "exception": false,
     "start_time": "2024-06-20T11:34:48.624855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>level</th>\n",
       "      <th>type</th>\n",
       "      <th>solution</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7498</td>\n",
       "      <td>7498</td>\n",
       "      <td>7498</td>\n",
       "      <td>7498</td>\n",
       "      <td>7496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7498</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7498</td>\n",
       "      <td>2907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>A function $f$ has domain $[0,2]$ and range $[...</td>\n",
       "      <td>Level 5</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>For $g(x) = 1 - f(x + 1)$ to be defined, we ne...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2304</td>\n",
       "      <td>1742</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  problem    level     type  \\\n",
       "count                                                7498     7498     7498   \n",
       "unique                                               7498        6        7   \n",
       "top     A function $f$ has domain $[0,2]$ and range $[...  Level 5  Algebra   \n",
       "freq                                                    1     2304     1742   \n",
       "\n",
       "                                                 solution answer  \n",
       "count                                                7498   7496  \n",
       "unique                                               7498   2907  \n",
       "top     For $g(x) = 1 - f(x + 1)$ to be defined, we ne...      2  \n",
       "freq                                                    1    200  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainQSADF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b00adb98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:48.931745Z",
     "iopub.status.busy": "2024-06-20T11:34:48.931428Z",
     "iopub.status.idle": "2024-06-20T11:34:49.064897Z",
     "shell.execute_reply": "2024-06-20T11:34:49.063881Z"
    },
    "papermill": {
     "duration": 0.220302,
     "end_time": "2024-06-20T11:34:49.067216",
     "exception": false,
     "start_time": "2024-06-20T11:34:48.846914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalia sold clips to 48 of her friends in Apr...</td>\n",
       "      <td>Natalia sold 48/2 = &lt;&lt;48/2=24&gt;&gt;24 clips in May...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weng earns $12 an hour for babysitting. Yester...</td>\n",
       "      <td>Weng earns 12/60 = $&lt;&lt;12/60=0.2&gt;&gt;0.2 per minut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Betty is saving money for a new wallet which c...</td>\n",
       "      <td>In the beginning, Betty has only 100 / 2 = $&lt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Julie is reading a 120-page book. Yesterday, s...</td>\n",
       "      <td>Maila read 12 x 2 = &lt;&lt;12*2=24&gt;&gt;24 pages today....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James writes a 3-page letter to 2 different fr...</td>\n",
       "      <td>He writes each friend 3*2=&lt;&lt;3*2=6&gt;&gt;6 pages a w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Natalia sold clips to 48 of her friends in Apr...   \n",
       "1  Weng earns $12 an hour for babysitting. Yester...   \n",
       "2  Betty is saving money for a new wallet which c...   \n",
       "3  Julie is reading a 120-page book. Yesterday, s...   \n",
       "4  James writes a 3-page letter to 2 different fr...   \n",
       "\n",
       "                                              answer  \n",
       "0  Natalia sold 48/2 = <<48/2=24>>24 clips in May...  \n",
       "1  Weng earns 12/60 = $<<12/60=0.2>>0.2 per minut...  \n",
       "2  In the beginning, Betty has only 100 / 2 = $<<...  \n",
       "3  Maila read 12 x 2 = <<12*2=24>>24 pages today....  \n",
       "4  He writes each friend 3*2=<<3*2=6>>6 pages a w...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainGSM8KDF =pd.read_parquet(gsm8kTrainFile)\n",
    "trainGSM8KDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47840e25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:49.239764Z",
     "iopub.status.busy": "2024-06-20T11:34:49.239081Z",
     "iopub.status.idle": "2024-06-20T11:34:49.245441Z",
     "shell.execute_reply": "2024-06-20T11:34:49.244561Z"
    },
    "papermill": {
     "duration": 0.093187,
     "end_time": "2024-06-20T11:34:49.247644",
     "exception": false,
     "start_time": "2024-06-20T11:34:49.154457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainGSM8KDF.iloc[0][\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4687276",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:49.421809Z",
     "iopub.status.busy": "2024-06-20T11:34:49.421068Z",
     "iopub.status.idle": "2024-06-20T11:34:49.448895Z",
     "shell.execute_reply": "2024-06-20T11:34:49.448123Z"
    },
    "papermill": {
     "duration": 0.117697,
     "end_time": "2024-06-20T11:34:49.451174",
     "exception": false,
     "start_time": "2024-06-20T11:34:49.333477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janet’s ducks lay 16 eggs per day. She eats th...</td>\n",
       "      <td>Janet sells 16 - 3 - 4 = &lt;&lt;16-3-4=9&gt;&gt;9 duck eg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A robe takes 2 bolts of blue fiber and half th...</td>\n",
       "      <td>It takes 2/2=&lt;&lt;2/2=1&gt;&gt;1 bolt of white fiber\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh decides to try flipping a house.  He buys...</td>\n",
       "      <td>The cost of the house and repairs came out to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James decides to run 3 sprints 3 times a week....</td>\n",
       "      <td>He sprints 3*3=&lt;&lt;3*3=9&gt;&gt;9 times\\nSo he runs 9*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Every day, Wendi feeds each of her chickens th...</td>\n",
       "      <td>If each chicken eats 3 cups of feed per day, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Janet’s ducks lay 16 eggs per day. She eats th...   \n",
       "1  A robe takes 2 bolts of blue fiber and half th...   \n",
       "2  Josh decides to try flipping a house.  He buys...   \n",
       "3  James decides to run 3 sprints 3 times a week....   \n",
       "4  Every day, Wendi feeds each of her chickens th...   \n",
       "\n",
       "                                              answer  \n",
       "0  Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eg...  \n",
       "1  It takes 2/2=<<2/2=1>>1 bolt of white fiber\\nS...  \n",
       "2  The cost of the house and repairs came out to ...  \n",
       "3  He sprints 3*3=<<3*3=9>>9 times\\nSo he runs 9*...  \n",
       "4  If each chicken eats 3 cups of feed per day, t...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testGSM8KDF = pd.read_parquet(gsm8kTestFile)\n",
    "testGSM8KDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6960e5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T11:18:26.310524Z",
     "iopub.status.busy": "2024-06-14T11:18:26.309842Z",
     "iopub.status.idle": "2024-06-14T11:18:26.877689Z",
     "shell.execute_reply": "2024-06-14T11:18:26.876524Z",
     "shell.execute_reply.started": "2024-06-14T11:18:26.310486Z"
    },
    "papermill": {
     "duration": 0.08361,
     "end_time": "2024-06-20T11:34:49.620591",
     "exception": false,
     "start_time": "2024-06-20T11:34:49.536981",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "trainMathQADF = pd.read_json(mathQATrainFile)\n",
    "trainMathQADF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5888110c",
   "metadata": {
    "papermill": {
     "duration": 0.08431,
     "end_time": "2024-06-20T11:34:49.789606",
     "exception": false,
     "start_time": "2024-06-20T11:34:49.705296",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "635f0a7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:50.005176Z",
     "iopub.status.busy": "2024-06-20T11:34:50.004816Z",
     "iopub.status.idle": "2024-06-20T11:34:50.010845Z",
     "shell.execute_reply": "2024-06-20T11:34:50.010044Z"
    },
    "papermill": {
     "duration": 0.092788,
     "end_time": "2024-06-20T11:34:50.012691",
     "exception": false,
     "start_time": "2024-06-20T11:34:49.919903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A function $f: \\\\mathbb N \\\\to \\\\mathbb N$ satisfies the following two conditions for all positive integers $n$:$f(f(f(n)))=8n-7$ and $f(2n)=2f(n)+1$. Calculate $f(100)$.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF[\"problem\"][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdffe555",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:50.183384Z",
     "iopub.status.busy": "2024-06-20T11:34:50.183072Z",
     "iopub.status.idle": "2024-06-20T11:34:50.186996Z",
     "shell.execute_reply": "2024-06-20T11:34:50.186274Z"
    },
    "papermill": {
     "duration": 0.091098,
     "end_time": "2024-06-20T11:34:50.188917",
     "exception": false,
     "start_time": "2024-06-20T11:34:50.097819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## cleaning data set\n",
    "# trainDF[\"problem\"] = trainDF[\"problem\"].str.replace(\"$\", '')\n",
    "# trainDF[\"problem\"] = trainDF[\"problem\"].str.replace(\"\\\\vert\", '|')\n",
    "# trainDF[\"problem\"] = trainDF[\"problem\"].str.replace(\"\\\\left\", '')\n",
    "# trainDF[\"problem\"] = trainDF[\"problem\"].str.replace(\"\\\\right\", '')\n",
    "# trainDF[\"problem\"] = trainDF[\"problem\"].str.replace(\"\\\\mathbb\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "483819fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:50.356936Z",
     "iopub.status.busy": "2024-06-20T11:34:50.356632Z",
     "iopub.status.idle": "2024-06-20T11:34:50.361447Z",
     "shell.execute_reply": "2024-06-20T11:34:50.360676Z"
    },
    "papermill": {
     "duration": 0.091296,
     "end_time": "2024-06-20T11:34:50.363501",
     "exception": false,
     "start_time": "2024-06-20T11:34:50.272205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?\n"
     ]
    }
   ],
   "source": [
    "print(trainDF[\"problem\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d52ef3bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:50.535179Z",
     "iopub.status.busy": "2024-06-20T11:34:50.534823Z",
     "iopub.status.idle": "2024-06-20T11:34:50.539805Z",
     "shell.execute_reply": "2024-06-20T11:34:50.538859Z"
    },
    "papermill": {
     "duration": 0.094527,
     "end_time": "2024-06-20T11:34:50.542025",
     "exception": false,
     "start_time": "2024-06-20T11:34:50.447498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "print(trainDF[\"answer\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c524e4",
   "metadata": {
    "papermill": {
     "duration": 0.086543,
     "end_time": "2024-06-20T11:34:50.715807",
     "exception": false,
     "start_time": "2024-06-20T11:34:50.629264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f419238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:50.887874Z",
     "iopub.status.busy": "2024-06-20T11:34:50.887505Z",
     "iopub.status.idle": "2024-06-20T11:34:50.894804Z",
     "shell.execute_reply": "2024-06-20T11:34:50.893967Z"
    },
    "papermill": {
     "duration": 0.097912,
     "end_time": "2024-06-20T11:34:50.896897",
     "exception": false,
     "start_time": "2024-06-20T11:34:50.798985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define model \n",
    "USE_LLAMA3 = False # for GPU version\n",
    "modelName1 = \"/kaggle/input/gemma/transformers/2b-it/3\"\n",
    "modelName2 =  \"/kaggle/input/gemma/transformers/7b-it/3\" # careful memory usage , will out of Memory both CPU or GPU\n",
    "modelName3 =  \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\" \n",
    "do_sample= True \n",
    "top_p=0.95 \n",
    "top_k= 2\n",
    "temperature=0.2#0.7 \n",
    "num_beams = 3\n",
    "max_length= 512\n",
    "\n",
    "# Quantized Config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit = True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65a39225",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:51.074887Z",
     "iopub.status.busy": "2024-06-20T11:34:51.074524Z",
     "iopub.status.idle": "2024-06-20T11:34:51.079922Z",
     "shell.execute_reply": "2024-06-20T11:34:51.079079Z"
    },
    "papermill": {
     "duration": 0.094362,
     "end_time": "2024-06-20T11:34:51.082061",
     "exception": false,
     "start_time": "2024-06-20T11:34:50.987699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efab01f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:34:51.261717Z",
     "iopub.status.busy": "2024-06-20T11:34:51.260759Z",
     "iopub.status.idle": "2024-06-20T11:36:48.812775Z",
     "shell.execute_reply": "2024-06-20T11:36:48.811951Z"
    },
    "papermill": {
     "duration": 117.643162,
     "end_time": "2024-06-20T11:36:48.815110",
     "exception": false,
     "start_time": "2024-06-20T11:34:51.171948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32fbeae81584ef6a6974c734abbcd41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if device.type == \"cuda\": # use 7b model gain Math performance\n",
    "    if USE_LLAMA3: \n",
    "        modelSel = modelName3\n",
    "        llmModel = \"llama3_8b\"\n",
    "    else: \n",
    "        modelSel = modelName2\n",
    "        llmModel = \"gemma_7b\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(modelSel , device_map=\"auto\", quantization_config= bnb_config)   # intial with GPU quantized\n",
    "    tokenizer = AutoTokenizer.from_pretrained(modelSel) # inital tokenizer\n",
    "else: \n",
    "    modelSel = modelName1\n",
    "    llmModel = \"gemma_2b\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(modelSel , device_map=\"auto\")   # intial \n",
    "    tokenizer = AutoTokenizer.from_pretrained(modelSel) # inital tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcb8d0db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:36:48.988096Z",
     "iopub.status.busy": "2024-06-20T11:36:48.987400Z",
     "iopub.status.idle": "2024-06-20T11:36:48.995714Z",
     "shell.execute_reply": "2024-06-20T11:36:48.994883Z"
    },
    "papermill": {
     "duration": 0.097418,
     "end_time": "2024-06-20T11:36:48.997722",
     "exception": false,
     "start_time": "2024-06-20T11:36:48.900304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaForCausalLM(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 3072, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x GemmaDecoderLayer(\n",
       "        (self_attn): GemmaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=3072, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=3072, out_features=4096, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=3072, out_features=4096, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=3072, bias=False)\n",
       "          (rotary_emb): GemmaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=3072, out_features=24576, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=3072, out_features=24576, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=24576, out_features=3072, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): GemmaRMSNorm()\n",
       "        (post_attention_layernorm): GemmaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): GemmaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b535df15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:36:49.182353Z",
     "iopub.status.busy": "2024-06-20T11:36:49.181530Z",
     "iopub.status.idle": "2024-06-20T11:36:49.187122Z",
     "shell.execute_reply": "2024-06-20T11:36:49.186289Z"
    },
    "papermill": {
     "duration": 0.101094,
     "end_time": "2024-06-20T11:36:49.189043",
     "exception": false,
     "start_time": "2024-06-20T11:36:49.087949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemma_7b'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llmModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186eb92f",
   "metadata": {
    "papermill": {
     "duration": 0.086031,
     "end_time": "2024-06-20T11:36:49.360064",
     "exception": false,
     "start_time": "2024-06-20T11:36:49.274033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test LLM Model response with Math Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69894c47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:36:49.536756Z",
     "iopub.status.busy": "2024-06-20T11:36:49.536397Z",
     "iopub.status.idle": "2024-06-20T11:36:49.543438Z",
     "shell.execute_reply": "2024-06-20T11:36:49.542531Z"
    },
    "papermill": {
     "duration": 0.096556,
     "end_time": "2024-06-20T11:36:49.545432",
     "exception": false,
     "start_time": "2024-06-20T11:36:49.448876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generateResponse(query, maxOutToken=256):\n",
    "    \"\"\"\n",
    "     Direct send message to gemini, get response\n",
    "    \"\"\"\n",
    "    inputIds = tokenizer(query, return_tensors=\"pt\").to(device)\n",
    "    response = model.generate(**inputIds , \n",
    "                              do_sample =True,\n",
    "                              top_p = 0.95,\n",
    "                              top_k= 2,\n",
    "                              temperature= 0.2, #0.7,#0.3,#0.7,\n",
    "#                               max_length=maxOutToken,\n",
    "                              max_new_tokens= maxOutToken,\n",
    "                             )\n",
    "#     return tokenizer.decode(response[0])\n",
    "    return tokenizer.decode(response[0][len(inputIds[\"input_ids\"]):], skip_special_tokens = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ea3af41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:36:49.724656Z",
     "iopub.status.busy": "2024-06-20T11:36:49.724002Z",
     "iopub.status.idle": "2024-06-20T11:36:49.730760Z",
     "shell.execute_reply": "2024-06-20T11:36:49.729832Z"
    },
    "papermill": {
     "duration": 0.098564,
     "end_time": "2024-06-20T11:36:49.732860",
     "exception": false,
     "start_time": "2024-06-20T11:36:49.634296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generateReponseInst(promptTemp, query, maxOutToken=256):\n",
    "    \"\"\"\n",
    "    Insert prompt template instruction with message\n",
    "    \"\"\"\n",
    "#     prompt = f\"\"\"{promptTemp}\\nQuestion: {query}\\nAnswer: \n",
    "#     \"\"\"\n",
    "    prompt = f\"\"\"{promptTemp}\\nQuestion: {query}\\n### Instruction: Given Answer in JSON format with key 'answer' and 'explanation' ### \n",
    "    \"\"\"\n",
    "    inputIds = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    response = model.generate(**inputIds,\n",
    "                              do_sample =True,\n",
    "                              top_p = 0.95,\n",
    "                              top_k= 2,\n",
    "                              temperature= 0.2, #0.7, # 0.3,#0.7,\n",
    "#                               max_length=maxOutToken,\n",
    "                              max_new_tokens= maxOutToken,)\n",
    "#     return tokenizer.decode(response[0]) # reutrn \n",
    "    return tokenizer.decode(response[0][len(inputIds[\"input_ids\"]):], skip_special_tokens = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f76356b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:36:49.907869Z",
     "iopub.status.busy": "2024-06-20T11:36:49.907245Z",
     "iopub.status.idle": "2024-06-20T11:36:49.913866Z",
     "shell.execute_reply": "2024-06-20T11:36:49.912991Z"
    },
    "papermill": {
     "duration": 0.094847,
     "end_time": "2024-06-20T11:36:49.916082",
     "exception": false,
     "start_time": "2024-06-20T11:36:49.821235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generateReponseRAG(promptTemp, ragContext, query, maxOutToken=256):\n",
    "    \"\"\"\n",
    "    Use Insert prompt insturction, RAG retrieve with query \n",
    "    \"\"\"\n",
    "    info = \"\\n\".join(ragContext)\n",
    "    prompt = f\"\"\"\n",
    "    {promptTemp}\\n\n",
    "    Question: {query}\\n\n",
    "    Information: {info}\\n\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    inputIds = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    response = model.generate(**inputIds, \n",
    "                              do_sample =True,\n",
    "                              top_p = 0.95,\n",
    "                              top_k= 2,\n",
    "                              temperature= 0.2, #0.7, #0.3, #0.7,\n",
    "#                               max_length=maxOutToken,\n",
    "                              max_new_tokens= maxOutToken,)\n",
    "    return tokenizer.decode(response[0][len(inputIds[\"input_ids\"]):], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "230b491c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:36:50.091073Z",
     "iopub.status.busy": "2024-06-20T11:36:50.090452Z",
     "iopub.status.idle": "2024-06-20T11:36:50.094393Z",
     "shell.execute_reply": "2024-06-20T11:36:50.093610Z"
    },
    "papermill": {
     "duration": 0.092234,
     "end_time": "2024-06-20T11:36:50.096253",
     "exception": false,
     "start_time": "2024-06-20T11:36:50.004019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ade427",
   "metadata": {
    "papermill": {
     "duration": 0.087178,
     "end_time": "2024-06-20T11:36:50.270447",
     "exception": false,
     "start_time": "2024-06-20T11:36:50.183269",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Parser function to extract answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7280696d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:36:50.449178Z",
     "iopub.status.busy": "2024-06-20T11:36:50.448534Z",
     "iopub.status.idle": "2024-06-20T11:36:50.464043Z",
     "shell.execute_reply": "2024-06-20T11:36:50.463189Z"
    },
    "papermill": {
     "duration": 0.108494,
     "end_time": "2024-06-20T11:36:50.465915",
     "exception": false,
     "start_time": "2024-06-20T11:36:50.357421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from json.decoder import JSONDecodeError\n",
    "def isInteger(text):\n",
    "    try:\n",
    "        if int(text) >= 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "\n",
    "def llmJSONParser1(txt):\n",
    "#     print(txt)\n",
    "    try:\n",
    "        txt = txt.replace(\"<eos>\", \"\")\n",
    "        subTxt = txt.split(\"```\")\n",
    "        subTxt[1] = subTxt[1].replace(\"json\", \"\")\n",
    "        subTxt[1] = subTxt[1].replace(\"<eos>\", \"\")\n",
    "#             print(subTxt[1])\n",
    "        jsonTxt = json.loads(subTxt[1])\n",
    "    except  JSONDecodeError as e:\n",
    "        print(\"Error LLM JSON parser\", e)\n",
    "        return None\n",
    "    except :\n",
    "        print(f\"\"\"Error LLM JSON parser input txt {txt}\"\"\" )\n",
    "        return None\n",
    "    return jsonTxt\n",
    "\n",
    "\n",
    "def llmJSONParser2(txt):\n",
    "#     print(txt)\n",
    "    try:\n",
    "        subText = txt.split(\"{\")\n",
    "        start = txt.find(\"{\")\n",
    "        end = txt.find(\"}\")\n",
    "        print(f\"Start loc: {start}, End loc: {end}\")\n",
    "        subString = txt[start:end+1]\n",
    "        print(subString)\n",
    "        jsonTxt = json.loads(subString)\n",
    "    except  JSONDecodeError as e:\n",
    "        print(\"Error LLM JSON parser\", e)\n",
    "        return None\n",
    "    except :\n",
    "        print(f\"\"\"Error LLM JSON parser input txt {txt}\"\"\" )\n",
    "        return None\n",
    "    return jsonTxt\n",
    "    \n",
    "def llmJSONParser3(txt):\n",
    "    '''\n",
    "    Manual JSON answer parser without , json library \n",
    "    '''\n",
    "    try:\n",
    "        subText = txt.split(\"{\") # split several {} in list\n",
    "        for txtSeg in subText: # loop in list to find answer\n",
    "            end = txtSeg.find(\"}\") # find end position in text segment\n",
    "            sub = txtSeg[:end] #subsring with {} context\n",
    "            temp = sub.replace(\"*\", \"\") # remove * symbol\n",
    "            temp = temp.replace(\"\\\"\", \"\") # reomve \\\" symbol\n",
    "            temp = temp.lower() # convert to lower case\n",
    "            answerloc = temp.find(\"answer:\") # find key word \"answer\" position\n",
    "            if answerloc != -1:\n",
    "                print(f\"find answer location : {answerloc}\")\n",
    "                newTxt = temp[answerloc:] # substring start answer\n",
    "#                 print(\"Temp: \", temp)\n",
    "                subTxt = newTxt.split(\"\\n\")\n",
    "                #       print(subTxt)\n",
    "                rel =subTxt[0][len(\"answer:\"):].strip() # get answer value with remove space\n",
    "                rel= rel.replace(',', '') # remove , symbol\n",
    "                print(rel)\n",
    "                if isInteger(rel):\n",
    "                    return rel\n",
    "                else:\n",
    "                    continue # not find the value\n",
    "#                 print(rel)\n",
    "                \n",
    "                \n",
    "        return None # can't find answer\n",
    "\n",
    "    except  JSONDecodeError as e:\n",
    "        print(\"Error LLM JSON parser\", e)\n",
    "        return None\n",
    "    except :\n",
    "        print(f\"\"\"Error LLM JSON parser input txt {txt}\"\"\" )\n",
    "        return None\n",
    "    return jsonTxt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "632dabb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:36:50.636670Z",
     "iopub.status.busy": "2024-06-20T11:36:50.636313Z",
     "iopub.status.idle": "2024-06-20T11:36:50.647070Z",
     "shell.execute_reply": "2024-06-20T11:36:50.646389Z"
    },
    "papermill": {
     "duration": 0.098734,
     "end_time": "2024-06-20T11:36:50.648956",
     "exception": false,
     "start_time": "2024-06-20T11:36:50.550222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def getAnswerParser1(txt):\n",
    "    \"\"\"\n",
    "    when json parser failure, use \n",
    "    \"\"\"\n",
    "    # find json format first\n",
    "    pattern = re.compile(r'^{')\n",
    "#     pattern = re.compile(r'Response\\s*:\\s*(.*)')\n",
    "    extracted_texts = []\n",
    "    count = 0\n",
    "    for text in txt:\n",
    "        match = re.search(pattern, txt)\n",
    "        if match:\n",
    "            extracted_texts.append(match.group(1))\n",
    "        else:\n",
    "            extracted_texts.append(\"\")\n",
    "            count += 1\n",
    "    print(f\"Pattern not found for {count} results.\")\n",
    "    return extracted_texts\n",
    "\n",
    "def getAnswerParser2(txt):\n",
    "    \"\"\"\n",
    "    when json parser failure, seem answer not JSON format, \n",
    "    use 'answer' for key word search final answer \n",
    "    \"\"\"\n",
    "    # find answer  \n",
    "    temp = txt.replace(\"*\", \"\") # remove * symbol\n",
    "    temp = temp.replace(\"\\\"\", \"\") # reomve \"\" symbol\n",
    "    temp = temp.lower() # convert to lower case\n",
    "    # find answer key word\n",
    "    start = temp.find(\"answer:\")\n",
    "    print(f\"Start loc: {start}\")\n",
    "    subStr = temp[start:]\n",
    "    if start != -1:\n",
    "        subTxt = subStr.split(\"\\n\")\n",
    "#       print(subTxt)\n",
    "        rel =subTxt[0][len(\"answer:\"):].strip() # get answer value with remove space\n",
    "        rel= rel.replace(',', '') # remove , symbol\n",
    "        print(rel)\n",
    "#         if isInteger(rel):\n",
    "        return rel\n",
    "#                 print(rel)\n",
    "#         return rel\n",
    "    \n",
    "    print(subStr)\n",
    "#     return None\n",
    "\n",
    "\n",
    "\n",
    "def getAnswer(text):\n",
    "    try:\n",
    "        ans = re.search(r'Answer:\\s*([\\s\\S]+)', text).group(1).strip()\n",
    "        ans = ans.replace(\",\",\"\")\n",
    "        if isInteger(ans):\n",
    "            return int(ans) % 1000\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8dab2b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:36:50.826880Z",
     "iopub.status.busy": "2024-06-20T11:36:50.826511Z",
     "iopub.status.idle": "2024-06-20T11:36:50.830937Z",
     "shell.execute_reply": "2024-06-20T11:36:50.829873Z"
    },
    "papermill": {
     "duration": 0.09635,
     "end_time": "2024-06-20T11:36:50.833050",
     "exception": false,
     "start_time": "2024-06-20T11:36:50.736700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rel = generateResponse(\"What is Data Science?\", maxOutToken=100)\n",
    "# print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5821c32b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:28:18.814779Z",
     "iopub.status.busy": "2024-05-19T15:28:18.814106Z",
     "iopub.status.idle": "2024-05-19T15:28:18.820560Z",
     "shell.execute_reply": "2024-05-19T15:28:18.819721Z",
     "shell.execute_reply.started": "2024-05-19T15:28:18.814748Z"
    },
    "papermill": {
     "duration": 0.09247,
     "end_time": "2024-06-20T11:36:51.016838",
     "exception": false,
     "start_time": "2024-06-20T11:36:50.924368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Zero Shot For testing Gemma LLM model Math performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e51ce39d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:36:51.198645Z",
     "iopub.status.busy": "2024-06-20T11:36:51.198252Z",
     "iopub.status.idle": "2024-06-20T11:36:51.202455Z",
     "shell.execute_reply": "2024-06-20T11:36:51.201676Z"
    },
    "papermill": {
     "duration": 0.095736,
     "end_time": "2024-06-20T11:36:51.204500",
     "exception": false,
     "start_time": "2024-06-20T11:36:51.108764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "# # Test without prompt instruction for assist reasoning\n",
    "# result = []\n",
    "# for i, qa in enumerate(trainDF[\"problem\"][:3]):\n",
    "#     rel = generateResponse(qa, maxOutToken=256)\n",
    "#     print(f\"Qusetion {i+1} : {qa}\\nResponse : {rel}\")\n",
    "#     print(\"--\"*20)\n",
    "#     result.append(rel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "175f822f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:36:51.394301Z",
     "iopub.status.busy": "2024-06-20T11:36:51.393628Z",
     "iopub.status.idle": "2024-06-20T11:36:51.715271Z",
     "shell.execute_reply": "2024-06-20T11:36:51.714307Z"
    },
    "papermill": {
     "duration": 0.413969,
     "end_time": "2024-06-20T11:36:51.717303",
     "exception": false,
     "start_time": "2024-06-20T11:36:51.303334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d7d15f",
   "metadata": {
    "papermill": {
     "duration": 0.083427,
     "end_time": "2024-06-20T11:36:51.889697",
     "exception": false,
     "start_time": "2024-06-20T11:36:51.806270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Compare result with Zero shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4548d2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:36:52.060717Z",
     "iopub.status.busy": "2024-06-20T11:36:52.059848Z",
     "iopub.status.idle": "2024-06-20T11:36:52.064121Z",
     "shell.execute_reply": "2024-06-20T11:36:52.063287Z"
    },
    "papermill": {
     "duration": 0.091617,
     "end_time": "2024-06-20T11:36:52.066405",
     "exception": false,
     "start_time": "2024-06-20T11:36:51.974788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compare the result, \n",
    "# for i, rel in enumerate(result):\n",
    "#     print(f\"Question {i} Result: {rel}\\n\")\n",
    "#     print(f\"\"\"Actual Ans: {trainDF[\"answer\"].iloc[i]}\"\"\")\n",
    "#     print(\"--\"*20)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381a3eb8",
   "metadata": {
    "papermill": {
     "duration": 0.08818,
     "end_time": "2024-06-20T11:36:52.239717",
     "exception": false,
     "start_time": "2024-06-20T11:36:52.151537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Result from zero shot no prompt instruction: all answer is failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cefae0f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:36:52.462704Z",
     "iopub.status.busy": "2024-06-20T11:36:52.462347Z",
     "iopub.status.idle": "2024-06-20T11:36:52.467577Z",
     "shell.execute_reply": "2024-06-20T11:36:52.466784Z"
    },
    "papermill": {
     "duration": 0.142981,
     "end_time": "2024-06-20T11:36:52.469446",
     "exception": false,
     "start_time": "2024-06-20T11:36:52.326465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generateFewShotTrain(df,sample=5):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    out= \"\"\n",
    "    for i in range(sample):\n",
    "        out +=f\"\"\"Q: {df[\"problem\"].iloc[i]}\\nA:{df[\"answer\"].iloc[i]}\\n\"\"\"\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d78e9a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:36:52.642087Z",
     "iopub.status.busy": "2024-06-20T11:36:52.641759Z",
     "iopub.status.idle": "2024-06-20T11:36:52.646648Z",
     "shell.execute_reply": "2024-06-20T11:36:52.645791Z"
    },
    "papermill": {
     "duration": 0.093493,
     "end_time": "2024-06-20T11:36:52.648933",
     "exception": false,
     "start_time": "2024-06-20T11:36:52.555440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Let $k, l > 0$ be parameters. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. What is the sum of the squares of the distances from $A$ and $B$ to the origin?\n",
      "A:52\n",
      "Q: Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?\n",
      "A:250\n",
      "Q: Let the `sparkle' operation on positive integer $n$ consist of calculating the sum of the digits of $n$ and taking its factorial, e.g. the sparkle of 13 is $4! = 24$. A robot starts with a positive integer on a blackboard, then after each second for the rest of eternity, replaces the number on the board with its sparkle. For some `special' numbers, if they're the first number, then eventually every number that appears will be less than 6. How many such special numbers are there with at most 36 digits?\n",
      "A:702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fewTrainSample = generateFewShotTrain(trainDF, 3)\n",
    "print(fewTrainSample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ee6ec0",
   "metadata": {
    "papermill": {
     "duration": 0.083991,
     "end_time": "2024-06-20T11:36:52.817843",
     "exception": false,
     "start_time": "2024-06-20T11:36:52.733852",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing with Few Shot learning wihout prompt instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc066f7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:36:52.988663Z",
     "iopub.status.busy": "2024-06-20T11:36:52.988293Z",
     "iopub.status.idle": "2024-06-20T11:36:53.312460Z",
     "shell.execute_reply": "2024-06-20T11:36:53.311609Z"
    },
    "papermill": {
     "duration": 0.41287,
     "end_time": "2024-06-20T11:36:53.314359",
     "exception": false,
     "start_time": "2024-06-20T11:36:52.901489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68814dec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:36:53.489346Z",
     "iopub.status.busy": "2024-06-20T11:36:53.489015Z",
     "iopub.status.idle": "2024-06-20T11:37:09.826659Z",
     "shell.execute_reply": "2024-06-20T11:37:09.825344Z"
    },
    "papermill": {
     "duration": 16.428314,
     "end_time": "2024-06-20T11:37:09.829303",
     "exception": false,
     "start_time": "2024-06-20T11:36:53.400989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjohnsonhk88\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240620_113653-2r2h3ah9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdauntless-feather-5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/johnsonhk88/ai-math-solving-few-show\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/johnsonhk88/ai-math-solving-few-show/runs/2r2h3ah9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if USE_WANDB and FEW_SHOT_TEST:\n",
    "     # Start a new wandb run\n",
    "    runTask1 = wandb.init(project='ai-math-solving-few-show', job_type=\"generation\", anonymous=\"allow\")\n",
    "    # define W&B Table\n",
    "    wandbCol =  [\"model\", \"question\", \"label_answer\", \"llm_generate\", \"llm_answer\"]\n",
    "    wandbFewShotTable =wandb.Table(columns=wandbCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61abc757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:37:10.008740Z",
     "iopub.status.busy": "2024-06-20T11:37:10.008028Z",
     "iopub.status.idle": "2024-06-20T11:38:10.817322Z",
     "shell.execute_reply": "2024-06-20T11:38:10.816329Z"
    },
    "papermill": {
     "duration": 60.899642,
     "end_time": "2024-06-20T11:38:10.819751",
     "exception": false,
     "start_time": "2024-06-20T11:37:09.920109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qusetion 4 : There exists a unique increasing geometric sequence of five 2-digit positive integers. What is their sum?\n",
      "Response : Q: Let $k, l > 0$ be parameters. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. What is the sum of the squares of the distances from $A$ and $B$ to the origin?\n",
      "A:52\n",
      "Q: Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?\n",
      "A:250\n",
      "Q: Let the `sparkle' operation on positive integer $n$ consist of calculating the sum of the digits of $n$ and taking its factorial, e.g. the sparkle of 13 is $4! = 24$. A robot starts with a positive integer on a blackboard, then after each second for the rest of eternity, replaces the number on the board with its sparkle. For some `special' numbers, if they're the first number, then eventually every number that appears will be less than 6. How many such special numbers are there with at most 36 digits?\n",
      "A:702\n",
      "\n",
      "Question: There exists a unique increasing geometric sequence of five 2-digit positive integers. What is their sum?\n",
      "### Instruction: Given Answer in JSON format with key 'answer' and 'explanation' ### \n",
      "    {\n",
      "        \"answer\": 123,\n",
      "        \"explanation\": \"The sequence is 11, 13, 15, 17, 19. Their sum is 123.\"\n",
      "    }\n",
      "\n",
      "Please explain the solutions to the above questions in detail.\n",
      "\n",
      "**Solution 1:**\n",
      "\n",
      "The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. The distance between $A$ and $B$ is 6. We know that the distance between two points on a parabola is given by the formula $d = 2\\sqrt{k(x_2 - x_1)^2 + l(x_2 - x_1)}$, where $d$ is the distance between the points, $k$ is the coefficient of the quadratic term, $l$ is the constant term, and $x_1$ and $x_2$ are the coordinates of the points. Substituting these values into the formula, we get $d = 2\\sqrt{k(6)^2 + l(6)} = 6$. Therefore, the sum of the squares of the distances from $A$ and $B$ to the origin is $d_A^2 + d_B^2 = 6^2 + 6^2 = 36$.\n",
      "\n",
      "**Solution 2:**\n",
      "\n",
      "The sum of any two (not necessarily different) yellow numbers is equal to a blue number. We know that the sum of two numbers is always an even number. Therefore, the maximum number of yellow numbers that can be summed to a blue number is 250.\n",
      "\n",
      "**Solution 3:**\n",
      "\n",
      "The sparkle operation on positive integer $n$ consists of calculating the sum of the digits of $n$ and taking its factorial. If the first number is special, then eventually every number that appears will be less than 6. We know that the factorial of a number is always a product of prime numbers. Therefore, the special numbers are the numbers whose factorial contains only prime factors that are less than 6. There are a total of 702 such numbers with at most 36 digits.\n",
      "\n",
      "**Solution 4:**\n",
      "\n",
      "The unique increasing geometric sequence of five 2-digit positive integers is 11, 13, 15, 17, 19. Their sum is 123.<eos>\n",
      "----------------------------------------\n",
      "Qusetion 5 : For how many positive integers $m$ does the equation \\[\\vert \\vert x-1 \\vert -2 \\vert=\\frac{m}{100}\\] have $4$ distinct solutions?\n",
      "Response : Q: Let $k, l > 0$ be parameters. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. What is the sum of the squares of the distances from $A$ and $B$ to the origin?\n",
      "A:52\n",
      "Q: Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?\n",
      "A:250\n",
      "Q: Let the `sparkle' operation on positive integer $n$ consist of calculating the sum of the digits of $n$ and taking its factorial, e.g. the sparkle of 13 is $4! = 24$. A robot starts with a positive integer on a blackboard, then after each second for the rest of eternity, replaces the number on the board with its sparkle. For some `special' numbers, if they're the first number, then eventually every number that appears will be less than 6. How many such special numbers are there with at most 36 digits?\n",
      "A:702\n",
      "\n",
      "Question: For how many positive integers $m$ does the equation \\[\\vert \\vert x-1 \\vert -2 \\vert=\\frac{m}{100}\\] have $4$ distinct solutions?\n",
      "### Instruction: Given Answer in JSON format with key 'answer' and 'explanation' ### \n",
      "    {\n",
      "        \"answer\": 12,\n",
      "        \"explanation\": \"The equation is equivalent to \\[\\vert x-1 \\vert = \\frac{m}{100} + 2\\]. For each value of $m$, the number of solutions is the number of integers that satisfy this equation within the range of 1 to 100. The solutions are found by finding the integer values that make the left-hand side equal to the right-hand side, taking into account the absolute value and the integer division of the right-hand side. The number of solutions for each value of $m$ is at most 1, so the total number of solutions is the sum of the number of solutions for each value of $m$, which is 12.\"\n",
      "    }<eos>\n",
      "----------------------------------------\n",
      "CPU times: user 59.4 s, sys: 950 ms, total: 1min\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "if FEW_SHOT_TEST:\n",
    "    # Test a few shot learning for assist reasoning\n",
    "    result = []\n",
    "    for i, qa in enumerate(trainDF[\"problem\"][4:6]):\n",
    "        rel = generateReponseInst(fewTrainSample, qa, maxOutToken=2048)\n",
    "        print(f\"Qusetion {i+4} : {qa}\\nResponse : {rel}\")\n",
    "        print(\"--\"*20)\n",
    "        result.append(rel)\n",
    "#         wandbFewShotTable.add_data(fewTrainSample, llmModel, qa, ans, rel, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55602ca8",
   "metadata": {
    "papermill": {
     "duration": 0.086144,
     "end_time": "2024-06-20T11:38:10.995400",
     "exception": false,
     "start_time": "2024-06-20T11:38:10.909256",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c58ff4fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:38:11.185255Z",
     "iopub.status.busy": "2024-06-20T11:38:11.184490Z",
     "iopub.status.idle": "2024-06-20T11:38:11.196374Z",
     "shell.execute_reply": "2024-06-20T11:38:11.195232Z"
    },
    "papermill": {
     "duration": 0.115324,
     "end_time": "2024-06-20T11:38:11.198235",
     "exception": false,
     "start_time": "2024-06-20T11:38:11.082911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find answer location : 9\n",
      "123\n",
      "Question 0 \n",
      "There exists a unique increasing geometric sequence of five 2-digit positive integers. What is their sum?\n",
      "\n",
      "Result: 123\n",
      "Actual Ans: 211\n",
      "----------------------------------------\n",
      "find answer location : 9\n",
      "12\n",
      "Question 1 \n",
      "For how many positive integers $m$ does the equation \\[\\vert \\vert x-1 \\vert -2 \\vert=\\frac{m}{100}\\] have $4$ distinct solutions?\n",
      "\n",
      "Result: 12\n",
      "Actual Ans: 199\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if FEW_SHOT_TEST:\n",
    "    # compare the result, \n",
    "    for i, rel in enumerate(result):\n",
    "        jsonTxt= llmJSONParser3(rel) # use llm JSON parser get answer\n",
    "        if jsonTxt:\n",
    "            # print(f\"\"\"Question {i} \\n{trainDF[\"problem\"].iloc[i+4]}\\n\\nResult: {jsonTxt[\"answer\"]}\"\"\")\n",
    "            print(f\"\"\"Question {i} \\n{trainDF[\"problem\"].iloc[i+4]}\\n\\nResult: {jsonTxt}\"\"\")# for llm json Parser3\n",
    "            print(f\"\"\"Actual Ans: {trainDF[\"answer\"].iloc[i+4]}\"\"\")\n",
    "            if USE_WANDB:\n",
    "                wandbFewShotTable.add_data( llmModel, \n",
    "                                           trainDF[\"problem\"].iloc[i+4], \n",
    "                                           trainDF[\"answer\"].iloc[i+4],\n",
    "                                            rel, # llmm response\n",
    "                                            jsonTxt)\n",
    "        else:\n",
    "#           ans= getAnswer(rel)\n",
    "            ans = getAnswerParser2(rel)\n",
    "            if ans:\n",
    "                print(f\"\"\"Question {i} \\n{trainDF[\"problem\"].iloc[i+4]}\\n\\nResult: {ans}\"\"\")\n",
    "                print(f\"\"\"Actual Ans: {trainDF[\"answer\"].iloc[i+4]}\"\"\")\n",
    "                if USE_WANDB:\n",
    "                    wandbFewShotTable.add_data( llmModel, \n",
    "                                           trainDF[\"problem\"].iloc[i+4], \n",
    "                                           trainDF[\"answer\"].iloc[i+4],\n",
    "                                            rel, # llmm response\n",
    "                                            ans)\n",
    "        print(\"--\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f393a0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:38:11.390415Z",
     "iopub.status.busy": "2024-06-20T11:38:11.389523Z",
     "iopub.status.idle": "2024-06-20T11:38:11.395511Z",
     "shell.execute_reply": "2024-06-20T11:38:11.394657Z"
    },
    "papermill": {
     "duration": 0.102338,
     "end_time": "2024-06-20T11:38:11.397433",
     "exception": false,
     "start_time": "2024-06-20T11:38:11.295095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2938"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba13e3d",
   "metadata": {
    "papermill": {
     "duration": 0.087132,
     "end_time": "2024-06-20T11:38:11.573794",
     "exception": false,
     "start_time": "2024-06-20T11:38:11.486662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cf46203",
   "metadata": {
    "papermill": {
     "duration": 0.088747,
     "end_time": "2024-06-20T11:38:11.750755",
     "exception": false,
     "start_time": "2024-06-20T11:38:11.662008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prompt Engineering\n",
    "## Create instruction prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04129d23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:38:11.927432Z",
     "iopub.status.busy": "2024-06-20T11:38:11.926593Z",
     "iopub.status.idle": "2024-06-20T11:38:12.254067Z",
     "shell.execute_reply": "2024-06-20T11:38:12.253160Z"
    },
    "papermill": {
     "duration": 0.417997,
     "end_time": "2024-06-20T11:38:12.255965",
     "exception": false,
     "start_time": "2024-06-20T11:38:11.837968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c66e2fd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:38:12.440388Z",
     "iopub.status.busy": "2024-06-20T11:38:12.440028Z",
     "iopub.status.idle": "2024-06-20T11:38:12.474309Z",
     "shell.execute_reply": "2024-06-20T11:38:12.473483Z"
    },
    "papermill": {
     "duration": 0.127694,
     "end_time": "2024-06-20T11:38:12.476403",
     "exception": false,
     "start_time": "2024-06-20T11:38:12.348709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if device.type ==\"cuda\":\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05c63053",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:38:12.659921Z",
     "iopub.status.busy": "2024-06-20T11:38:12.659498Z",
     "iopub.status.idle": "2024-06-20T11:38:12.666912Z",
     "shell.execute_reply": "2024-06-20T11:38:12.665824Z"
    },
    "papermill": {
     "duration": 0.104438,
     "end_time": "2024-06-20T11:38:12.669116",
     "exception": false,
     "start_time": "2024-06-20T11:38:12.564678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "templatePrompt1 = \"\"\"\n",
    "you are act as Mathematician, solve the math problem reasonable and logical from given question. \n",
    "Answer the result from question and think step-by-step to make answer. \n",
    "\"\"\"\n",
    "\n",
    "templatePrompt2 = \"\"\"\n",
    "you are act as Mathematician, solve the math problem reasonable and logical from given question. \n",
    "The solving the answer and thinking step by step from question\\n{question}. Only require given final result in JSON format with key \"answer\" and \"explanation\" \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "templatePrompt3 = \"\"\"\n",
    "you are act as Mathematician, solve the math problem reasonable and logical from given question. \n",
    "The solving the answer and thinking step by step from question\\n{question}. Only require given final result answer, output in JSON format with key \"answer\" and \"explanation\" \n",
    "\"\"\"\n",
    "\n",
    "templatePrompt4 = \"\"\"\n",
    "you are act as Mathematician, solve the math problem reasonable and logical from given question. \n",
    "The solving the answer and thinking multiple step by step from question : {question}.\n",
    "Careful to logical reasoning  multiple steps to find the best solution\n",
    "Only require given final answer in JSON format with key \"answer\" and \"explanation\"  \n",
    "\"\"\"\n",
    "    \n",
    "templatePrompt5 = \"\"\"\n",
    "you are act as Mathematician, solve the math problem reasonable and logical from given question. \n",
    "The solving the answer and thinking multiple step by step from question : {question}.\n",
    "Careful to logical reasoning  multiple steps to find the best solution\n",
    "\\nOnly Output answer in json format with key \"answer\" and \"explanation\" \n",
    "\"\"\"\n",
    "\n",
    "templatePrompt15 = \"\"\"\n",
    "### Instruction: you are act as Mathematician, solve the math problem reasonable and logical from given question.###\n",
    "The solving the answer and thinking multiple step by step from Question: {question}.\n",
    "Careful to logical reasoning multiple steps to find the best solution.\n",
    "Only Output answer in json format with key \"answer\" and \"explanation\".\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61a7f19",
   "metadata": {
    "papermill": {
     "duration": 0.094194,
     "end_time": "2024-06-20T11:38:12.857956",
     "exception": false,
     "start_time": "2024-06-20T11:38:12.763762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RAG base Template Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70a5dac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:38:13.052217Z",
     "iopub.status.busy": "2024-06-20T11:38:13.051812Z",
     "iopub.status.idle": "2024-06-20T11:38:13.056943Z",
     "shell.execute_reply": "2024-06-20T11:38:13.055865Z"
    },
    "papermill": {
     "duration": 0.107526,
     "end_time": "2024-06-20T11:38:13.059160",
     "exception": false,
     "start_time": "2024-06-20T11:38:12.951634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "templatePrompt6 = \"\"\"\n",
    "you are act as Mathematician, solve the math problem reasonable and logical from given question follow the requirement as below:\n",
    "CONTEXT: {context}\n",
    "Use context for reference help to solve math question step by step.\n",
    "Solving the answer and rethinking multiple step by step from Question: {question}.\n",
    "Careful to logical reasoning  multiple steps to find the best solution \n",
    "Only Output answer in json format with key \"answer\" and \"explanation\" \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c1f322e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:38:13.252388Z",
     "iopub.status.busy": "2024-06-20T11:38:13.252033Z",
     "iopub.status.idle": "2024-06-20T11:38:13.256973Z",
     "shell.execute_reply": "2024-06-20T11:38:13.255925Z"
    },
    "papermill": {
     "duration": 0.096321,
     "end_time": "2024-06-20T11:38:13.258931",
     "exception": false,
     "start_time": "2024-06-20T11:38:13.162610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "templatePrompt7 = \"\"\"\n",
    "you are act as Mathematician, solve the math problem reasonable and logical from given question follow the requirement as below:\n",
    "CONTEXT: {context}\n",
    "The context contain sample question, solution and answer with similarity to user Question. Use context for assist to solve math question step by step.  \n",
    "Solving the answer and rethinking multiple step by step from user Question.\n",
    "User Question: {question}.\n",
    "Careful to logical reasoning  multiple steps to find the best solution \n",
    "Only Output answer in json format with key \"answer\" and \"explanation\" \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb1f9b2",
   "metadata": {
    "papermill": {
     "duration": 0.089721,
     "end_time": "2024-06-20T11:38:13.437310",
     "exception": false,
     "start_time": "2024-06-20T11:38:13.347589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ohter Prompt Engineering with more instruction step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "320e871f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:38:13.617720Z",
     "iopub.status.busy": "2024-06-20T11:38:13.617312Z",
     "iopub.status.idle": "2024-06-20T11:38:13.623029Z",
     "shell.execute_reply": "2024-06-20T11:38:13.622113Z"
    },
    "papermill": {
     "duration": 0.097865,
     "end_time": "2024-06-20T11:38:13.625050",
     "exception": false,
     "start_time": "2024-06-20T11:38:13.527185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "templatePrompt8 = \"\"\"\n",
    "You are required to answer Arithmetic Reasoning questions. Please follow the steps below as you go about solving the problem. \n",
    "1. All problems should be solved in as many steps as required and each step should be numbered.\n",
    "2. All calculations should be clear and simple to understand.\n",
    "3. Provide an accurate final answer at the end of your reasoning in the following format: \n",
    "4. Output result only in JSON format with key \"answer\" and \"explanation\".\n",
    "Question: {question}\n",
    "You'll be evaluated on:\n",
    "- how easier are the calculations done to understand?\n",
    "- how accurate is the answer?\n",
    "Output result only in JSON format with key\n",
    "\"\"\"\n",
    "\n",
    "templatePrompt18 = \"\"\"\n",
    "### Instruction: You are required to answer Arithmetic Reasoning questions. Please follow the steps below as you go about solving the problem.### \n",
    "1. All problems should be solved in as many steps as required and each step should be numbered.\n",
    "2. All calculations should be clear and simple to understand.\n",
    "3. Provide an accurate final answer at the end of your reasoning in the following format: \n",
    "4. Output result only in JSON format with key \"answer\" and \"explanation\".\n",
    "Question: {question}\n",
    "You'll be evaluated on:\n",
    "- how easier are the calculations done to understand?\n",
    "- how accurate is the answer?\n",
    "Output result only in JSON format with key\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1da3d604",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:38:13.810048Z",
     "iopub.status.busy": "2024-06-20T11:38:13.809726Z",
     "iopub.status.idle": "2024-06-20T11:38:14.812035Z",
     "shell.execute_reply": "2024-06-20T11:38:14.810804Z"
    },
    "papermill": {
     "duration": 1.093941,
     "end_time": "2024-06-20T11:38:14.814305",
     "exception": false,
     "start_time": "2024-06-20T11:38:13.720364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core(s) per socket:                 2\r\n"
     ]
    }
   ],
   "source": [
    "#no.of cores each processor is having\n",
    "!lscpu | grep 'Core(s) per socket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd6b8ca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:38:14.996293Z",
     "iopub.status.busy": "2024-06-20T11:38:14.995365Z",
     "iopub.status.idle": "2024-06-20T11:38:15.995885Z",
     "shell.execute_reply": "2024-06-20T11:38:15.994630Z"
    },
    "papermill": {
     "duration": 1.095438,
     "end_time": "2024-06-20T11:38:15.998527",
     "exception": false,
     "start_time": "2024-06-20T11:38:14.903089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(s) per core:                 2\r\n"
     ]
    }
   ],
   "source": [
    "#no.of threads each core is having\n",
    "!lscpu | grep 'Thread(s) per core'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2dc8351b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:38:16.181010Z",
     "iopub.status.busy": "2024-06-20T11:38:16.180631Z",
     "iopub.status.idle": "2024-06-20T11:38:16.185421Z",
     "shell.execute_reply": "2024-06-20T11:38:16.184527Z"
    },
    "papermill": {
     "duration": 0.097548,
     "end_time": "2024-06-20T11:38:16.187426",
     "exception": false,
     "start_time": "2024-06-20T11:38:16.089878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "# # Test without prompt instruction for assist reasoning\n",
    "# questionPrompt2 = PromptTemplate(input_variables=[\"question\"], template=templatePrompt2)\n",
    "# result = []\n",
    "# for i, qa in enumerate(trainDF[\"problem\"][0:3]):\n",
    "#     finalPrmpt2 = questionPrompt2.format(\n",
    "#         question=qa\n",
    "#     )\"\"\n",
    "#     rel = generateResponse(finalPrmpt2, maxOutToken=512)\n",
    "#     print(f\"Qusetion {i+4} : {qa}\\nResponse : {rel}\")\n",
    "#     print(\"--\"*20)\n",
    "#     result.append(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4acf6cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:38:16.369387Z",
     "iopub.status.busy": "2024-06-20T11:38:16.369037Z",
     "iopub.status.idle": "2024-06-20T11:39:23.662704Z",
     "shell.execute_reply": "2024-06-20T11:39:23.661800Z"
    },
    "papermill": {
     "duration": 67.387145,
     "end_time": "2024-06-20T11:39:23.665076",
     "exception": false,
     "start_time": "2024-06-20T11:38:16.277931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qusetion 1 : Let $k, l > 0$ be parameters. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. What is the sum of the squares of the distances from $A$ and $B$ to the origin?\n",
      "Response : \n",
      "### Instruction: you are act as Mathematician, solve the math problem reasonable and logical from given question.###\n",
      "The solving the answer and thinking multiple step by step from Question: Let $k, l > 0$ be parameters. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. What is the sum of the squares of the distances from $A$ and $B$ to the origin?.\n",
      "Careful to logical reasoning multiple steps to find the best solution.\n",
      "Only Output answer in json format with key \"answer\" and \"explanation\".\n",
      "\n",
      "**Answer:**\n",
      "{\n",
      "  \"answer\": 26,\n",
      "  \"explanation\": \"Given parabola and line intersect at points A and B, distance between A and B is 6. The distance from a point to a parabola is given by the formula d = |ax^2 + bx + c| / sqrt(a). So, the distance from A to the origin is d_A = |k(x_A)^2 - 2k(x_A) + l| / sqrt(k). Similarly, the distance from B to the origin is d_B = |k(x_B)^2 - 2k(x_B) + l| / sqrt(k). The sum of squares of distances is d_A^2 + d_B^2 = |k(x_A)^2 - 2k(x_A) + l|^2 + |k(x_B)^2 - 2k(x_B) + l|^2 = 26.\"\n",
      "}\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "1. **Identify the equation of the parabola:**\n",
      "The parabola is given by the equation $y = kx^2 - 2kx + l$.\n",
      "\n",
      "2. **Find the intersection points with the line:**\n",
      "The line is given by the equation $y = 4$. To find the intersection points, we need to set $y = 4$ in the equation of the parabola and solve for $x$.\n",
      "\n",
      "3. **Calculate the distances from the origin to each point:**\n",
      "The distance from a point to a parabola is given by the formula $d = |ax^2 + bx + c| / sqrt(a). Where d is the distance from the point to the parabola, a is the coefficient of the x^2 term, b is the coefficient of the x term, c is the constant term, and x is the x-coordinate of the point.\n",
      "\n",
      "4. **Calculate the sum of squares of distances:**\n",
      "The sum of squares of distances is d_A^2 + d_B^2 = |k(x_A)^2 - 2k(x_A) + l|^2 + |k(x_B)^2 - 2k(x_B) + l|^2.\n",
      "\n",
      "5. **The answer:**\n",
      "The sum of squares of distances is 26.\n",
      "----------------------------------------\n",
      "Qusetion 2 : Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?\n",
      "Response : \n",
      "### Instruction: you are act as Mathematician, solve the math problem reasonable and logical from given question.###\n",
      "The solving the answer and thinking multiple step by step from Question: Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?.\n",
      "Careful to logical reasoning multiple steps to find the best solution.\n",
      "Only Output answer in json format with key \"answer\" and \"explanation\".\n",
      "\n",
      "**Answer:**\n",
      "{\n",
      "  \"answer\": 3,\n",
      "  \"explanation\": \"The sum of any two yellow numbers is equal to a blue number. So, if we have more than two yellow numbers, the sum of any two yellow numbers will always be equal to a blue number. Therefore, the maximum number of yellow numbers that can be there is 3.\"\n",
      "}\n",
      "\n",
      "**Explanation:**\n",
      "- The sum of any two yellow numbers is equal to a blue number.\n",
      "- If we have more than two yellow numbers, the sum of any two yellow numbers will always be equal to a blue number.\n",
      "- Therefore, the maximum number of yellow numbers that can be there is 3.\n",
      "----------------------------------------\n",
      "Qusetion 3 : Let the `sparkle' operation on positive integer $n$ consist of calculating the sum of the digits of $n$ and taking its factorial, e.g. the sparkle of 13 is $4! = 24$. A robot starts with a positive integer on a blackboard, then after each second for the rest of eternity, replaces the number on the board with its sparkle. For some `special' numbers, if they're the first number, then eventually every number that appears will be less than 6. How many such special numbers are there with at most 36 digits?\n",
      "Response : \n",
      "### Instruction: you are act as Mathematician, solve the math problem reasonable and logical from given question.###\n",
      "The solving the answer and thinking multiple step by step from Question: Let the `sparkle' operation on positive integer $n$ consist of calculating the sum of the digits of $n$ and taking its factorial, e.g. the sparkle of 13 is $4! = 24$. A robot starts with a positive integer on a blackboard, then after each second for the rest of eternity, replaces the number on the board with its sparkle. For some `special' numbers, if they're the first number, then eventually every number that appears will be less than 6. How many such special numbers are there with at most 36 digits?.\n",
      "Careful to logical reasoning multiple steps to find the best solution.\n",
      "Only Output answer in json format with key \"answer\" and \"explanation\".\n",
      "\n",
      "**Answer:**\n",
      "```json\n",
      "{\n",
      "  \"answer\": 1,\n",
      "  \"explanation\": \"The sparkle operation always increases the sum of digits of a number, therefore, if the first number is greater than 6, all the numbers that appear later will also be greater than 6. So, the only special number is 1.\"\n",
      "}\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "- The sparkle operation increases the sum of digits of a number.\n",
      "- If the first number is greater than 6, all the numbers that appear later will also be greater than 6.\n",
      "- Therefore, the only special number is 1.\n",
      "----------------------------------------\n",
      "CPU times: user 1min 6s, sys: 1.06 s, total: 1min 7s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "if FEW_SHOT_TEST:\n",
    "    # Test without prompt instruction for assist reasoning\n",
    "    newPrompt = PromptTemplate(input_variables=[\"question\"], template=templatePrompt15)\n",
    "    result = []\n",
    "    for i, qa in enumerate(trainDF[\"problem\"][0:3]):\n",
    "        finalPrmpt = newPrompt.format(\n",
    "            question=qa\n",
    "        )\n",
    "        rel = generateResponse(finalPrmpt, maxOutToken=2048)\n",
    "        print(f\"Qusetion {i+1} : {qa}\\nResponse : {rel}\")\n",
    "        print(\"--\"*20)\n",
    "        result.append(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7cf6af8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:39:23.855458Z",
     "iopub.status.busy": "2024-06-20T11:39:23.854511Z",
     "iopub.status.idle": "2024-06-20T11:39:23.860700Z",
     "shell.execute_reply": "2024-06-20T11:39:23.859476Z"
    },
    "papermill": {
     "duration": 0.105458,
     "end_time": "2024-06-20T11:39:23.862987",
     "exception": false,
     "start_time": "2024-06-20T11:39:23.757529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "if FEW_SHOT_TEST:\n",
    "    print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d081130d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:39:24.094549Z",
     "iopub.status.busy": "2024-06-20T11:39:24.094204Z",
     "iopub.status.idle": "2024-06-20T11:39:24.098352Z",
     "shell.execute_reply": "2024-06-20T11:39:24.097443Z"
    },
    "papermill": {
     "duration": 0.100912,
     "end_time": "2024-06-20T11:39:24.100498",
     "exception": false,
     "start_time": "2024-06-20T11:39:23.999586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# jsonTxt= llmJSONParser(result[0])\n",
    "# jsonTxt\n",
    "# result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fbe93c6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:39:24.288373Z",
     "iopub.status.busy": "2024-06-20T11:39:24.287489Z",
     "iopub.status.idle": "2024-06-20T11:39:24.291802Z",
     "shell.execute_reply": "2024-06-20T11:39:24.290831Z"
    },
    "papermill": {
     "duration": 0.099857,
     "end_time": "2024-06-20T11:39:24.293946",
     "exception": false,
     "start_time": "2024-06-20T11:39:24.194089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# jsonTxt[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c46a334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:39:24.478014Z",
     "iopub.status.busy": "2024-06-20T11:39:24.477195Z",
     "iopub.status.idle": "2024-06-20T11:39:24.491444Z",
     "shell.execute_reply": "2024-06-20T11:39:24.489991Z"
    },
    "papermill": {
     "duration": 0.107661,
     "end_time": "2024-06-20T11:39:24.493467",
     "exception": false,
     "start_time": "2024-06-20T11:39:24.385806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find answer location : 565\n",
      "\n",
      "find answer location : 3\n",
      "26\n",
      "Question 0 \n",
      "Let $k, l > 0$ be parameters. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. What is the sum of the squares of the distances from $A$ and $B$ to the origin?\n",
      "\n",
      "Result: 26\n",
      "Actual Ans: 52\n",
      "----------------------------------------\n",
      "find answer location : 582\n",
      "\n",
      "find answer location : 3\n",
      "3\n",
      "Question 1 \n",
      "Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?\n",
      "\n",
      "Result: 3\n",
      "Actual Ans: 250\n",
      "----------------------------------------\n",
      "find answer location : 838\n",
      "\n",
      "find answer location : 3\n",
      "1\n",
      "Question 2 \n",
      "Let the `sparkle' operation on positive integer $n$ consist of calculating the sum of the digits of $n$ and taking its factorial, e.g. the sparkle of 13 is $4! = 24$. A robot starts with a positive integer on a blackboard, then after each second for the rest of eternity, replaces the number on the board with its sparkle. For some `special' numbers, if they're the first number, then eventually every number that appears will be less than 6. How many such special numbers are there with at most 36 digits?\n",
      "\n",
      "Result: 1\n",
      "Actual Ans: 702\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if FEW_SHOT_TEST:# compare the result, \n",
    "    for i, rel in enumerate(result):\n",
    "        jsonTxt= llmJSONParser3(rel) # use llm JSON parser get answer\n",
    "        if jsonTxt:\n",
    "            # print(f\"\"\"Question {i} \\n{trainDF[\"problem\"].iloc[i+4]}\\n\\nResult: {jsonTxt[\"answer\"]}\"\"\") # for llm json parser1\n",
    "            print(f\"\"\"Question {i} \\n{trainDF[\"problem\"].iloc[i]}\\n\\nResult: {jsonTxt}\"\"\")# for llm json Parser3\n",
    "            print(f\"\"\"Actual Ans: {trainDF[\"answer\"].iloc[i]}\"\"\")\n",
    "            if USE_WANDB:\n",
    "                wandbFewShotTable.add_data( llmModel, \n",
    "                                           trainDF[\"problem\"].iloc[i], \n",
    "                                           trainDF[\"answer\"].iloc[i],\n",
    "                                            rel, # llmm response\n",
    "                                            jsonTxt)\n",
    "\n",
    "        else:\n",
    "#           ans= getAnswer(rel)\n",
    "            ans = getAnswerParser2(rel)\n",
    "            if ans:\n",
    "                print(f\"\"\"Question {i} \\n{trainDF[\"problem\"].iloc[i]}\\n\\nResult: {ans}\"\"\")\n",
    "                print(f\"\"\"Actual Ans: {trainDF[\"answer\"].iloc[i]}\"\"\")\n",
    "                if USE_WANDB:\n",
    "                    wandbFewShotTable.add_data( llmModel, \n",
    "                                           trainDF[\"problem\"].iloc[i], \n",
    "                                           trainDF[\"answer\"].iloc[i],\n",
    "                                            rel, # llmm response\n",
    "                                            ans)\n",
    "        print(\"--\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2701e736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:39:24.674584Z",
     "iopub.status.busy": "2024-06-20T11:39:24.673755Z",
     "iopub.status.idle": "2024-06-20T11:40:48.412829Z",
     "shell.execute_reply": "2024-06-20T11:40:48.411812Z"
    },
    "papermill": {
     "duration": 83.923824,
     "end_time": "2024-06-20T11:40:48.507132",
     "exception": false,
     "start_time": "2024-06-20T11:39:24.583308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qusetion 1 : Let $k, l > 0$ be parameters. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. What is the sum of the squares of the distances from $A$ and $B$ to the origin?\n",
      "Response : \n",
      "### Instruction: You are required to answer Arithmetic Reasoning questions. Please follow the steps below as you go about solving the problem.### \n",
      "1. All problems should be solved in as many steps as required and each step should be numbered.\n",
      "2. All calculations should be clear and simple to understand.\n",
      "3. Provide an accurate final answer at the end of your reasoning in the following format: \n",
      "4. Output result only in JSON format with key \"answer\" and \"explanation\".\n",
      "Question: Let $k, l > 0$ be parameters. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. What is the sum of the squares of the distances from $A$ and $B$ to the origin?\n",
      "You'll be evaluated on:\n",
      "- how easier are the calculations done to understand?\n",
      "- how accurate is the answer?\n",
      "Output result only in JSON format with key\n",
      "\"answer\": The sum of squares of distances from A and B to the origin is 100.\n",
      "\"explanation\": The parabola intersects the line at two points A and B. The distance from A to the origin is 6. The distance from B to the origin is also 6. The sum of squares of distances from A and B to the origin is 6^2 + 6^2 = 36 + 36 = 100.\n",
      "```\n",
      "\n",
      "**Answer:**\n",
      "```json\n",
      "{\n",
      "  \"answer\": \"100\",\n",
      "  \"explanation\": \"The parabola intersects the line at two points A and B. The distance from A to the origin is 6. The distance from B to the origin is also 6. The sum of squares of distances from A and B to the origin is 6^2 + 6^2 = 36 + 36 = 100.\"\n",
      "}\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "1. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$.\n",
      "2. The distance from a point to the origin is given by the formula $d = √(x^2 + y^2).\n",
      "3. The distance from $A$ to the origin is 6. The distance from $B$ to the origin is also 6.\n",
      "4. The sum of squares of distances from $A$ and $B$ to the origin is 6^2 + 6^2 = 36 + 36 = 100.\n",
      "\n",
      "**Final Answer:**\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"answer\": \"100\",\n",
      "  \"explanation\": \"The parabola intersects the line at two points A and B. The distance from A to the origin is 6. The distance from B to the origin is also 6. The sum of squares of distances from A and B to the origin is 6^2 + 6^2 = 36 + 36 = 100.\"\n",
      "}\n",
      "```\n",
      "----------------------------------------\n",
      "Qusetion 2 : Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?\n",
      "Response : \n",
      "### Instruction: You are required to answer Arithmetic Reasoning questions. Please follow the steps below as you go about solving the problem.### \n",
      "1. All problems should be solved in as many steps as required and each step should be numbered.\n",
      "2. All calculations should be clear and simple to understand.\n",
      "3. Provide an accurate final answer at the end of your reasoning in the following format: \n",
      "4. Output result only in JSON format with key \"answer\" and \"explanation\".\n",
      "Question: Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?\n",
      "You'll be evaluated on:\n",
      "- how easier are the calculations done to understand?\n",
      "- how accurate is the answer?\n",
      "Output result only in JSON format with key\n",
      "\"answer\": The maximum number of yellow numbers is [Answer]\n",
      "\"explanation\": [Explanation]\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "**Step 1:** Identify the multiples of 3 from 111 to 999.\n",
      "Multiples of 3 are multiples of 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, and 96.\n",
      "\n",
      "**Step 2:** Identify the pairs of yellow numbers that sum up to a blue number.\n",
      "There are a total of 10 pairs of yellow numbers that sum up to a blue number.\n",
      "\n",
      "**Step 3:** Count the number of yellow numbers.\n",
      "There are a total of 10 pairs of yellow numbers that sum up to a blue number, so the maximum number of yellow numbers is 10.\n",
      "\n",
      "**Final Answer:**\n",
      "\n",
      "```json\n",
      "\"answer\": 10\n",
      "\"explanation\": \"The sum of any two (not necessarily different) yellow numbers is equal to a blue number. Therefore, the maximum number of yellow numbers is 10.\"\n",
      "```\n",
      "----------------------------------------\n",
      "Qusetion 3 : Let the `sparkle' operation on positive integer $n$ consist of calculating the sum of the digits of $n$ and taking its factorial, e.g. the sparkle of 13 is $4! = 24$. A robot starts with a positive integer on a blackboard, then after each second for the rest of eternity, replaces the number on the board with its sparkle. For some `special' numbers, if they're the first number, then eventually every number that appears will be less than 6. How many such special numbers are there with at most 36 digits?\n",
      "Response : \n",
      "### Instruction: You are required to answer Arithmetic Reasoning questions. Please follow the steps below as you go about solving the problem.### \n",
      "1. All problems should be solved in as many steps as required and each step should be numbered.\n",
      "2. All calculations should be clear and simple to understand.\n",
      "3. Provide an accurate final answer at the end of your reasoning in the following format: \n",
      "4. Output result only in JSON format with key \"answer\" and \"explanation\".\n",
      "Question: Let the `sparkle' operation on positive integer $n$ consist of calculating the sum of the digits of $n$ and taking its factorial, e.g. the sparkle of 13 is $4! = 24$. A robot starts with a positive integer on a blackboard, then after each second for the rest of eternity, replaces the number on the board with its sparkle. For some `special' numbers, if they're the first number, then eventually every number that appears will be less than 6. How many such special numbers are there with at most 36 digits?\n",
      "You'll be evaluated on:\n",
      "- how easier are the calculations done to understand?\n",
      "- how accurate is the answer?\n",
      "Output result only in JSON format with key\n",
      "\"answer\" and \"explanation\":\n",
      "\n",
      "```\n",
      "\"answer\": 1,\n",
      "\"explanation\": \"The explanation for the answer is...\"\n",
      "```\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "```\n",
      "\"answer\": 1,\n",
      "\"explanation\": \"The explanation for the answer is: The sparkle operation always results in a sum of digits and a factorial of that sum. If the first number is greater than 6, then every number that appears will be less than 6. Therefore, there is only one special number with at most 36 digits, which is 1.\"\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "- The sparkle operation calculates the sum of the digits of a number and takes its factorial.\n",
      "- If the first number is greater than 6, then every number that appears will be less than 6.\n",
      "- Therefore, the only special number with at most 36 digits is 1.\n",
      "----------------------------------------\n",
      "CPU times: user 1min 22s, sys: 1.52 s, total: 1min 23s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "if FEW_SHOT_TEST:#\n",
    "    # Test without prompt instruction for assist reasoning\n",
    "    newPrompt = PromptTemplate(input_variables=[\"question\"], template=templatePrompt18)\n",
    "    result = []\n",
    "    for i, qa in enumerate(trainDF[\"problem\"][:3]):\n",
    "        finalPrmpt = newPrompt.format(\n",
    "            question=qa\n",
    "        )\n",
    "        rel = generateResponse(finalPrmpt,  maxOutToken=2048)\n",
    "        print(f\"Qusetion {i+1} : {qa}\\nResponse : {rel}\")\n",
    "        print(\"--\"*20)\n",
    "        result.append(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e808497",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:40:48.687785Z",
     "iopub.status.busy": "2024-06-20T11:40:48.687109Z",
     "iopub.status.idle": "2024-06-20T11:40:48.691088Z",
     "shell.execute_reply": "2024-06-20T11:40:48.690237Z"
    },
    "papermill": {
     "duration": 0.097558,
     "end_time": "2024-06-20T11:40:48.693012",
     "exception": false,
     "start_time": "2024-06-20T11:40:48.595454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92982cf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:40:48.872927Z",
     "iopub.status.busy": "2024-06-20T11:40:48.872598Z",
     "iopub.status.idle": "2024-06-20T11:40:48.887552Z",
     "shell.execute_reply": "2024-06-20T11:40:48.885435Z"
    },
    "papermill": {
     "duration": 0.108061,
     "end_time": "2024-06-20T11:40:48.889566",
     "exception": false,
     "start_time": "2024-06-20T11:40:48.781505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find answer location : 862\n",
      "the sum of squares of distances from a and b to the origin is 100.\n",
      "find answer location : 3\n",
      "100\n",
      "Question 0 \n",
      "Let $k, l > 0$ be parameters. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. What is the sum of the squares of the distances from $A$ and $B$ to the origin?\n",
      "\n",
      "Result: 100\n",
      "Actual Ans: 52\n",
      "----------------------------------------\n",
      "find answer location : 879\n",
      "the maximum number of yellow numbers is [answer]\n",
      "Start loc: 879\n",
      "the maximum number of yellow numbers is [answer]\n",
      "Question 1 \n",
      "Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?\n",
      "\n",
      "Result: the maximum number of yellow numbers is [answer]\n",
      "Actual Ans: 250\n",
      "----------------------------------------\n",
      "find answer location : 1164\n",
      "1\n",
      "Question 2 \n",
      "Let the `sparkle' operation on positive integer $n$ consist of calculating the sum of the digits of $n$ and taking its factorial, e.g. the sparkle of 13 is $4! = 24$. A robot starts with a positive integer on a blackboard, then after each second for the rest of eternity, replaces the number on the board with its sparkle. For some `special' numbers, if they're the first number, then eventually every number that appears will be less than 6. How many such special numbers are there with at most 36 digits?\n",
      "\n",
      "Result: 1\n",
      "Actual Ans: 702\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if FEW_SHOT_TEST:\n",
    "    for i, rel in enumerate(result):\n",
    "        jsonTxt= llmJSONParser3(rel) # use llm JSON parser get answer\n",
    "        if jsonTxt:\n",
    "            # print(f\"\"\"Question {i} \\n{trainDF[\"problem\"].iloc[i+4]}\\n\\nResult: {jsonTxt[\"answer\"]}\"\"\") # for llm json parser1\n",
    "            print(f\"\"\"Question {i} \\n{trainDF[\"problem\"].iloc[i]}\\n\\nResult: {jsonTxt}\"\"\")# for llm json Parser3\n",
    "            print(f\"\"\"Actual Ans: {trainDF[\"answer\"].iloc[i]}\"\"\")\n",
    "            if USE_WANDB:\n",
    "                wandbFewShotTable.add_data( llmModel, \n",
    "                                           trainDF[\"problem\"].iloc[i], \n",
    "                                           trainDF[\"answer\"].iloc[i],\n",
    "                                            rel, # llmm response\n",
    "                                            jsonTxt)\n",
    "\n",
    "        else:\n",
    "#           ans= getAnswer(rel)\n",
    "            ans = getAnswerParser2(rel) # not json format use get anser parser\n",
    "            if ans:\n",
    "                print(f\"\"\"Question {i} \\n{trainDF[\"problem\"].iloc[i]}\\n\\nResult: {ans}\"\"\")\n",
    "                print(f\"\"\"Actual Ans: {trainDF[\"answer\"].iloc[i]}\"\"\")\n",
    "                if USE_WANDB:\n",
    "                    wandbFewShotTable.add_data( llmModel, \n",
    "                                           trainDF[\"problem\"].iloc[i], \n",
    "                                           trainDF[\"answer\"].iloc[i],\n",
    "                                            rel, # llmm response\n",
    "                                            ans)\n",
    "        print(\"--\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "428e88b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:40:49.074350Z",
     "iopub.status.busy": "2024-06-20T11:40:49.074007Z",
     "iopub.status.idle": "2024-06-20T11:40:54.388237Z",
     "shell.execute_reply": "2024-06-20T11:40:54.387529Z"
    },
    "papermill": {
     "duration": 5.410566,
     "end_time": "2024-06-20T11:40:54.390282",
     "exception": false,
     "start_time": "2024-06-20T11:40:48.979716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdauntless-feather-5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/johnsonhk88/ai-math-solving-few-show/runs/2r2h3ah9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/johnsonhk88/ai-math-solving-few-show\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240620_113653-2r2h3ah9/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if FEW_SHOT_TEST and USE_WANDB :\n",
    "    wandb.log({\"few_shot_generations\": wandbFewShotTable})\n",
    "    runTask1.finish()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff25fb5d",
   "metadata": {
    "papermill": {
     "duration": 0.0888,
     "end_time": "2024-06-20T11:40:54.569529",
     "exception": false,
     "start_time": "2024-06-20T11:40:54.480729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test use Prompt Template assist reasoning Math Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8d6b7a53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:40:54.756157Z",
     "iopub.status.busy": "2024-06-20T11:40:54.755398Z",
     "iopub.status.idle": "2024-06-20T11:40:54.760041Z",
     "shell.execute_reply": "2024-06-20T11:40:54.759069Z"
    },
    "papermill": {
     "duration": 0.100245,
     "end_time": "2024-06-20T11:40:54.762070",
     "exception": false,
     "start_time": "2024-06-20T11:40:54.661825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "# # Test prompt Template for assist reasoning\n",
    "# qestionPrompt1 = PromptTemplate(input_variables=[\"question\"], template=templePrompt11)\n",
    "# result = []\n",
    "# for i, qa in enumerate(trainDF[\"problem\"][:3]):\n",
    "#     finalPrmpt = qestionPrompt1.format(\n",
    "#         question=qa\n",
    "#     )\n",
    "#     rel = generateResponse(finalPrmpt, maxOutToken=512)\n",
    "#     print(f\"Qusetion {i+1} : {qa}\\nResponse : {rel}\")\n",
    "#     print(\"--\"*20)\n",
    "#     result.append(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3fb7920d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:40:54.942388Z",
     "iopub.status.busy": "2024-06-20T11:40:54.941552Z",
     "iopub.status.idle": "2024-06-20T11:40:54.945866Z",
     "shell.execute_reply": "2024-06-20T11:40:54.944951Z"
    },
    "papermill": {
     "duration": 0.096881,
     "end_time": "2024-06-20T11:40:54.947718",
     "exception": false,
     "start_time": "2024-06-20T11:40:54.850837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # compare the result, \n",
    "# for i, rel in enumerate(result):\n",
    "#     print(f\"Question {i+1}\\nResult: {rel}\\n\")\n",
    "\n",
    "#     print(f\"\"\"Actual Ans: {trainDF[\"answer\"].iloc[i]}\"\"\")\n",
    "#     print(\"--\"*20)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5e23202",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:40:55.136377Z",
     "iopub.status.busy": "2024-06-20T11:40:55.136005Z",
     "iopub.status.idle": "2024-06-20T11:40:55.139997Z",
     "shell.execute_reply": "2024-06-20T11:40:55.139074Z"
    },
    "papermill": {
     "duration": 0.101988,
     "end_time": "2024-06-20T11:40:55.142134",
     "exception": false,
     "start_time": "2024-06-20T11:40:55.040146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for rel in result:\n",
    "#     Markdown(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c96108b",
   "metadata": {
    "papermill": {
     "duration": 0.090789,
     "end_time": "2024-06-20T11:40:55.323533",
     "exception": false,
     "start_time": "2024-06-20T11:40:55.232744",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b227b4b",
   "metadata": {
    "papermill": {
     "duration": 0.091191,
     "end_time": "2024-06-20T11:40:55.508723",
     "exception": false,
     "start_time": "2024-06-20T11:40:55.417532",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5eb9bc7",
   "metadata": {
    "papermill": {
     "duration": 0.089586,
     "end_time": "2024-06-20T11:40:55.688286",
     "exception": false,
     "start_time": "2024-06-20T11:40:55.598700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RAG - Use RAG Assistance for improve Math Question Answering\n",
    "# Paper for Describe How to use RAG Improve Math Question Answering\n",
    "**<https://arxiv.org/pdf/2310.03184>**\n",
    "\n",
    "\n",
    "## Inital Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4780713",
   "metadata": {
    "papermill": {
     "duration": 0.090035,
     "end_time": "2024-06-20T11:40:55.867420",
     "exception": false,
     "start_time": "2024-06-20T11:40:55.777385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Advance RAG technique (Reranking, Query expansion, embedding adaper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e71d5b72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:40:56.045105Z",
     "iopub.status.busy": "2024-06-20T11:40:56.044364Z",
     "iopub.status.idle": "2024-06-20T11:40:56.050157Z",
     "shell.execute_reply": "2024-06-20T11:40:56.049270Z"
    },
    "papermill": {
     "duration": 0.097151,
     "end_time": "2024-06-20T11:40:56.052103",
     "exception": false,
     "start_time": "2024-06-20T11:40:55.954952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defin RAG alogrithm\n",
    "USE_SIMPLE_RAG = True # simple similairy approach \n",
    "USE_RERANK = False # advance RAG with Re-Ranking \n",
    "USE_QUERY_EXPANSION = False   # advance RAG with \n",
    "USE_EMBEDDING_ADAPER = False\n",
    "if USE_WANDB: # define wandb RAG project name\n",
    "    if USE_SIMPLE_RAG:\n",
    "        wandbRAGProject = \"ai-math-solving-simple-rag\"\n",
    "    elif USE_RERANK:\n",
    "        wandbRAGProject = \"ai-math-solving-re-ranking\"\n",
    "    elif USE_QUERY_EXPANSION:\n",
    "        wandbRAGProject = \"ai-math-solving-query-expansion\"\n",
    "    elif USE_EMBEDDING_ADAPER:\n",
    "        wandbRAGProject = \"ai-math-solving-embedding-adapter\"\n",
    "    else:\n",
    "        wandbRAGProject = \"ai-math-solving-simple-rag\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "896a3789",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:40:56.234615Z",
     "iopub.status.busy": "2024-06-20T11:40:56.234275Z",
     "iopub.status.idle": "2024-06-20T11:41:12.568379Z",
     "shell.execute_reply": "2024-06-20T11:41:12.566971Z"
    },
    "papermill": {
     "duration": 16.429065,
     "end_time": "2024-06-20T11:41:12.571043",
     "exception": false,
     "start_time": "2024-06-20T11:40:56.141978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240620_114056-v42p3ax0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meternal-butterfly-6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/johnsonhk88/ai-math-solving-simple-rag\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/johnsonhk88/ai-math-solving-simple-rag/runs/v42p3ax0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if USE_WANDB and USE_RAG:\n",
    "     # Start a new wandb run\n",
    "    \n",
    "    runTask2 = wandb.init(project=wandbRAGProject, job_type=\"generation\", anonymous=\"allow\")\n",
    "    # define W&B Table\n",
    "    wandbCol2 =  [\"model\", \"question\", \"label_answer\", \"llm_generate\", \"llm_answer\"]\n",
    "    wandbRAGTable =wandb.Table(columns=wandbCol2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "04db463d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:12.754255Z",
     "iopub.status.busy": "2024-06-20T11:41:12.753926Z",
     "iopub.status.idle": "2024-06-20T11:41:12.759180Z",
     "shell.execute_reply": "2024-06-20T11:41:12.758328Z"
    },
    "papermill": {
     "duration": 0.097253,
     "end_time": "2024-06-20T11:41:12.761358",
     "exception": false,
     "start_time": "2024-06-20T11:41:12.664105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddingModel =  \"BAAI/bge-base-en-v1.5\"# \"all-MiniLM-L6-v2\" # \"BAAI/bge-base-en-v1.5\"\n",
    "if device.type == \"cuda\":\n",
    "    model_kwargs = {\"device\": \"cuda\"}\n",
    "else:\n",
    "    model_kwargs = {\"device\": \"cpu\"}\n",
    "\n",
    "def embeddingModelInit(modelName):\n",
    "    embed =  HuggingFaceEmbeddings(model_name=modelName, model_kwargs= model_kwargs)#initial embedding model \n",
    "    return embed\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "919e9709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:12.942003Z",
     "iopub.status.busy": "2024-06-20T11:41:12.941692Z",
     "iopub.status.idle": "2024-06-20T11:41:18.806393Z",
     "shell.execute_reply": "2024-06-20T11:41:18.805424Z"
    },
    "papermill": {
     "duration": 5.957931,
     "end_time": "2024-06-20T11:41:18.808581",
     "exception": false,
     "start_time": "2024-06-20T11:41:12.850650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556164c8c0d943e89a1178b94716dbe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0eb2b6708034ef3aa53940bafa03fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf1b4559c404cbd95a060afa03e14f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/94.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf6e1dea68d48238e1916f688b3698a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666ccd46ae824d0d82326c11b236d49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee989fe959f440797faed467a27a39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d128e9e16d5f4e6b9a38b57454e2d258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0899ef39b5d9430698dac958c9211582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3bc25650fb54aa08fe0effba8e32eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d509f5056c49d8abff5b20e026b14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8ad3f62607433ea6865841f02a8629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding = embeddingModelInit(embeddingModel) #initial embedding model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b617fb2a",
   "metadata": {
    "papermill": {
     "duration": 0.090963,
     "end_time": "2024-06-20T11:41:18.992455",
     "exception": false,
     "start_time": "2024-06-20T11:41:18.901492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Math Document Prepare for Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b4bbea",
   "metadata": {
    "papermill": {
     "duration": 0.094203,
     "end_time": "2024-06-20T11:41:19.183194",
     "exception": false,
     "start_time": "2024-06-20T11:41:19.088991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Text Chunk for Math Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "61318c16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:19.370206Z",
     "iopub.status.busy": "2024-06-20T11:41:19.369124Z",
     "iopub.status.idle": "2024-06-20T11:41:19.374586Z",
     "shell.execute_reply": "2024-06-20T11:41:19.373654Z"
    },
    "papermill": {
     "duration": 0.102905,
     "end_time": "2024-06-20T11:41:19.376673",
     "exception": false,
     "start_time": "2024-06-20T11:41:19.273768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "# textSplitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=30)\n",
    "textSplitter = CharacterTextSplitter(chunk_size= 1000, chunk_overlap=30, \n",
    "                                     length_function=len,\n",
    "                                     separator=\"\\n\\n\",\n",
    "                                    is_separator_regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "085a9a84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:19.565106Z",
     "iopub.status.busy": "2024-06-20T11:41:19.564273Z",
     "iopub.status.idle": "2024-06-20T11:41:19.570453Z",
     "shell.execute_reply": "2024-06-20T11:41:19.569464Z"
    },
    "papermill": {
     "duration": 0.101252,
     "end_time": "2024-06-20T11:41:19.572379",
     "exception": false,
     "start_time": "2024-06-20T11:41:19.471127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def splitTextData(df, columnList):\n",
    "    docsProcess = []\n",
    "    tempDF = df[columnList]\n",
    "    for doc in tempDF:\n",
    "#         print(doc)\n",
    "#         print(type(doc))\n",
    "        if type(doc) != \"str\":\n",
    "             doc = str(doc)\n",
    "        txt =textSplitter.split_text(doc)\n",
    "#         txt = textSplitter.split_documents([doc])\n",
    "        docsProcess.append(doc)\n",
    "#     create_documents(splits)\n",
    "    return textSplitter.create_documents(docsProcess)   #this should return the list of documents.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae7a440",
   "metadata": {
    "papermill": {
     "duration": 0.134798,
     "end_time": "2024-06-20T11:41:19.799795",
     "exception": false,
     "start_time": "2024-06-20T11:41:19.664997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create llm Context for training set or RAG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "877ccd2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:19.985671Z",
     "iopub.status.busy": "2024-06-20T11:41:19.984735Z",
     "iopub.status.idle": "2024-06-20T11:41:19.997384Z",
     "shell.execute_reply": "2024-06-20T11:41:19.996562Z"
    },
    "papermill": {
     "duration": 0.107601,
     "end_time": "2024-06-20T11:41:19.999279",
     "exception": false,
     "start_time": "2024-06-20T11:41:19.891678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>level</th>\n",
       "      <th>type</th>\n",
       "      <th>solution</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The United States Postal Service charges an ex...</td>\n",
       "      <td>Level 3</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>We calculate the desired ratio for each envelo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many integers between 1000 and 2000 have a...</td>\n",
       "      <td>Level 4</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>A number with 15, 20 and 25 as factors must be...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Given that $n$ is an integer and $0 &lt; 4n &lt;30$,...</td>\n",
       "      <td>Level 2</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>Dividing by $4$, we have $0&lt;n&lt;7\\frac{1}{2}$. T...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many integers between $100$ and $150$ have...</td>\n",
       "      <td>Level 4</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>We will break up the problem into cases based ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regular pentagon $ABCDE$ and regular hexagon $...</td>\n",
       "      <td>Level 4</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>We know that the sum of the degree measures of...</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             problem    level        type  \\\n",
       "0  The United States Postal Service charges an ex...  Level 3  Prealgebra   \n",
       "1  How many integers between 1000 and 2000 have a...  Level 4  Prealgebra   \n",
       "2  Given that $n$ is an integer and $0 < 4n <30$,...  Level 2  Prealgebra   \n",
       "3  How many integers between $100$ and $150$ have...  Level 4  Prealgebra   \n",
       "4  Regular pentagon $ABCDE$ and regular hexagon $...  Level 4  Prealgebra   \n",
       "\n",
       "                                            solution answer  \n",
       "0  We calculate the desired ratio for each envelo...      3  \n",
       "1  A number with 15, 20 and 25 as factors must be...      3  \n",
       "2  Dividing by $4$, we have $0<n<7\\frac{1}{2}$. T...     28  \n",
       "3  We will break up the problem into cases based ...     18  \n",
       "4  We know that the sum of the degree measures of...    132  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainQSADF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3d0f5ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:20.184717Z",
     "iopub.status.busy": "2024-06-20T11:41:20.183868Z",
     "iopub.status.idle": "2024-06-20T11:41:20.191266Z",
     "shell.execute_reply": "2024-06-20T11:41:20.190428Z"
    },
    "papermill": {
     "duration": 0.102321,
     "end_time": "2024-06-20T11:41:20.193061",
     "exception": false,
     "start_time": "2024-06-20T11:41:20.090740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tempDF = trainQSADF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "01ed4f88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:20.377879Z",
     "iopub.status.busy": "2024-06-20T11:41:20.377498Z",
     "iopub.status.idle": "2024-06-20T11:41:20.400319Z",
     "shell.execute_reply": "2024-06-20T11:41:20.399413Z"
    },
    "papermill": {
     "duration": 0.118423,
     "end_time": "2024-06-20T11:41:20.402630",
     "exception": false,
     "start_time": "2024-06-20T11:41:20.284207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gener\n",
    "tempDF[\"LLM Content\"] = (\n",
    "    \"question : \" +  tempDF[\"problem\"] + \n",
    "    \"\\nsolution: \" + tempDF[\"solution\"] +\n",
    "    \"\\nanswer: \" + tempDF[\"answer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0d004176",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:20.589867Z",
     "iopub.status.busy": "2024-06-20T11:41:20.589480Z",
     "iopub.status.idle": "2024-06-20T11:41:20.597834Z",
     "shell.execute_reply": "2024-06-20T11:41:20.597027Z"
    },
    "papermill": {
     "duration": 0.102831,
     "end_time": "2024-06-20T11:41:20.599733",
     "exception": false,
     "start_time": "2024-06-20T11:41:20.496902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : The United States Postal Service charges an extra $\\$0.11$ in postage if the length of an envelope, in inches, divided by its height, in inches, is less than $1.3$ or greater than $2.5.$ For how many of these four envelopes must the extra $\\$0.11$ in postage be paid? \\begin{tabular}[t]{ccc}\n",
      "Envelope & Length in inches & Height in inches\\\\\\hline\n",
      "A &6 &4\\\\\n",
      "B &9 &3\\\\\n",
      "C &6 &6\\\\\n",
      "D &11 &4\n",
      "\\end{tabular}\n",
      "solution: We calculate the desired ratio for each envelope: \\begin{align*}\n",
      "\\text{A} &= \\frac{6}{4} = 1.5 \\\\\n",
      "\\text{B} &= \\frac{9}{3} = 3 \\\\\n",
      "\\text{C} &= \\frac{6}{6} = 1 \\\\\n",
      "\\text{D} &= \\frac{11}{4} = 2.75\n",
      "\\end{align*} $\\text B,$ $\\text C,$ and $\\text D$ are out of range, so the answer is $\\boxed{3}.$\n",
      "answer: 3\n",
      "question : How many integers between 1000 and 2000 have all three of the numbers 15, 20 and 25 as factors?\n",
      "solution: A number with 15, 20 and 25 as factors must be divisible by their least common multiple (LCM).  Because $15 = 3\n",
      "\\times 5$, $20 = 2^2 \\times 5$, and $25 = 5^2$, the LCM of 15, 20 and 25 is $2^2 \\times 3 \\times 5^2 = 300$. There are $\\boxed{3}$ multiples of 300 between 1000 and 2000: 1200, 1500 and 1800.\n",
      "answer: 3\n",
      "question : Given that $n$ is an integer and $0 < 4n <30$, what is the sum of all possible integer values of $n$?\n",
      "solution: Dividing by $4$, we have $0<n<7\\frac{1}{2}$. The integer solutions to this chain of inequalities are $n=1,2,3,4,5,6,7$. The sum of these integers is $\\boxed{28}$.\n",
      "answer: 28\n",
      "question : How many integers between $100$ and $150$ have three different digits in increasing order? One such integer is $129$.\n",
      "solution: We will break up the problem into cases based on the second digit and count the number of integers in each case. If the second digit is 0, there are no integers because the first digit (1) is larger than the second. Similarly, if the second digit is 1, there are no integers. If the second digit is 2, there are 7 integers (with third digit from 3 to 9, inclusive). If the second digit is 3, there are 6 integers (with third digit from 4 to 9, inclusive). If the second digit is 4, there are 5 integers (with third digit from 5 to 9, inclusive). Among all the cases, there are $7+6+5=\\boxed{18}$ integers.\n",
      "answer: 18\n"
     ]
    }
   ],
   "source": [
    "for doc in tempDF[\"LLM Content\"][:4]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ef7e1100",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:20.789257Z",
     "iopub.status.busy": "2024-06-20T11:41:20.788964Z",
     "iopub.status.idle": "2024-06-20T11:41:20.834755Z",
     "shell.execute_reply": "2024-06-20T11:41:20.833731Z"
    },
    "papermill": {
     "duration": 0.144148,
     "end_time": "2024-06-20T11:41:20.836832",
     "exception": false,
     "start_time": "2024-06-20T11:41:20.692684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>level</th>\n",
       "      <th>type</th>\n",
       "      <th>solution</th>\n",
       "      <th>answer</th>\n",
       "      <th>LLM Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7498</td>\n",
       "      <td>7498</td>\n",
       "      <td>7498</td>\n",
       "      <td>7498</td>\n",
       "      <td>7496</td>\n",
       "      <td>7496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7498</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7498</td>\n",
       "      <td>2907</td>\n",
       "      <td>7496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>A function $f$ has domain $[0,2]$ and range $[...</td>\n",
       "      <td>Level 5</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>For $g(x) = 1 - f(x + 1)$ to be defined, we ne...</td>\n",
       "      <td>2</td>\n",
       "      <td>question : A function $f$ has domain $[0,2]$ a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2304</td>\n",
       "      <td>1742</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  problem    level     type  \\\n",
       "count                                                7498     7498     7498   \n",
       "unique                                               7498        6        7   \n",
       "top     A function $f$ has domain $[0,2]$ and range $[...  Level 5  Algebra   \n",
       "freq                                                    1     2304     1742   \n",
       "\n",
       "                                                 solution answer  \\\n",
       "count                                                7498   7496   \n",
       "unique                                               7498   2907   \n",
       "top     For $g(x) = 1 - f(x + 1)$ to be defined, we ne...      2   \n",
       "freq                                                    1    200   \n",
       "\n",
       "                                              LLM Content  \n",
       "count                                                7496  \n",
       "unique                                               7496  \n",
       "top     question : A function $f$ has domain $[0,2]$ a...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "12b2c0a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:21.041053Z",
     "iopub.status.busy": "2024-06-20T11:41:21.040696Z",
     "iopub.status.idle": "2024-06-20T11:41:21.047143Z",
     "shell.execute_reply": "2024-06-20T11:41:21.046027Z"
    },
    "papermill": {
     "duration": 0.108772,
     "end_time": "2024-06-20T11:41:21.049359",
     "exception": false,
     "start_time": "2024-06-20T11:41:20.940587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7498"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tempDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "87526e88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:21.243647Z",
     "iopub.status.busy": "2024-06-20T11:41:21.243280Z",
     "iopub.status.idle": "2024-06-20T11:41:21.247800Z",
     "shell.execute_reply": "2024-06-20T11:41:21.246898Z"
    },
    "papermill": {
     "duration": 0.099796,
     "end_time": "2024-06-20T11:41:21.249672",
     "exception": false,
     "start_time": "2024-06-20T11:41:21.149876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "maxQuestionSample= 1500#1500#3000#1000\n",
    "sampleDF  = tempDF[:maxQuestionSample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8b28a6b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:21.470279Z",
     "iopub.status.busy": "2024-06-20T11:41:21.469905Z",
     "iopub.status.idle": "2024-06-20T11:41:21.480335Z",
     "shell.execute_reply": "2024-06-20T11:41:21.479334Z"
    },
    "papermill": {
     "duration": 0.118016,
     "end_time": "2024-06-20T11:41:21.483116",
     "exception": false,
     "start_time": "2024-06-20T11:41:21.365100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : The United States Postal Service charges an extra $\\$0.11$ in postage if the length of an envelope, in inches, divided by its height, in inches, is less than $1.3$ or greater than $2.5.$ For how many of these four envelopes must the extra $\\$0.11$ in postage be paid? \\begin{tabular}[t]{ccc}\n",
      "Envelope & Length in inches & Height in inches\\\\\\hline\n",
      "A &6 &4\\\\\n",
      "B &9 &3\\\\\n",
      "C &6 &6\\\\\n",
      "D &11 &4\n",
      "\\end{tabular}\n",
      "solution: We calculate the desired ratio for each envelope: \\begin{align*}\n",
      "\\text{A} &= \\frac{6}{4} = 1.5 \\\\\n",
      "\\text{B} &= \\frac{9}{3} = 3 \\\\\n",
      "\\text{C} &= \\frac{6}{6} = 1 \\\\\n",
      "\\text{D} &= \\frac{11}{4} = 2.75\n",
      "\\end{align*} $\\text B,$ $\\text C,$ and $\\text D$ are out of range, so the answer is $\\boxed{3}.$\n",
      "answer: 3\n",
      "['question : The United States Postal Service charges an extra $\\\\$0.11$ in postage if the length of an envelope, in inches, divided by its height, in inches, is less than $1.3$ or greater than $2.5.$ For how many of these four envelopes must the extra $\\\\$0.11$ in postage be paid? \\\\begin{tabular}[t]{ccc}\\nEnvelope & Length in inches & Height in inches\\\\\\\\\\\\hline\\nA &6 &4\\\\\\\\\\nB &9 &3\\\\\\\\\\nC &6 &6\\\\\\\\\\nD &11 &4\\n\\\\end{tabular}\\nsolution: We calculate the desired ratio for each envelope: \\\\begin{align*}\\n\\\\text{A} &= \\\\frac{6}{4} = 1.5 \\\\\\\\\\n\\\\text{B} &= \\\\frac{9}{3} = 3 \\\\\\\\\\n\\\\text{C} &= \\\\frac{6}{6} = 1 \\\\\\\\\\n\\\\text{D} &= \\\\frac{11}{4} = 2.75\\n\\\\end{align*} $\\\\text B,$ $\\\\text C,$ and $\\\\text D$ are out of range, so the answer is $\\\\boxed{3}.$\\nanswer: 3']\n",
      "question : How many integers between 1000 and 2000 have all three of the numbers 15, 20 and 25 as factors?\n",
      "solution: A number with 15, 20 and 25 as factors must be divisible by their least common multiple (LCM).  Because $15 = 3\n",
      "\\times 5$, $20 = 2^2 \\times 5$, and $25 = 5^2$, the LCM of 15, 20 and 25 is $2^2 \\times 3 \\times 5^2 = 300$. There are $\\boxed{3}$ multiples of 300 between 1000 and 2000: 1200, 1500 and 1800.\n",
      "answer: 3\n",
      "['question : How many integers between 1000 and 2000 have all three of the numbers 15, 20 and 25 as factors?\\nsolution: A number with 15, 20 and 25 as factors must be divisible by their least common multiple (LCM).  Because $15 = 3\\n\\\\times 5$, $20 = 2^2 \\\\times 5$, and $25 = 5^2$, the LCM of 15, 20 and 25 is $2^2 \\\\times 3 \\\\times 5^2 = 300$. There are $\\\\boxed{3}$ multiples of 300 between 1000 and 2000: 1200, 1500 and 1800.\\nanswer: 3']\n",
      "question : Given that $n$ is an integer and $0 < 4n <30$, what is the sum of all possible integer values of $n$?\n",
      "solution: Dividing by $4$, we have $0<n<7\\frac{1}{2}$. The integer solutions to this chain of inequalities are $n=1,2,3,4,5,6,7$. The sum of these integers is $\\boxed{28}$.\n",
      "answer: 28\n",
      "['question : Given that $n$ is an integer and $0 < 4n <30$, what is the sum of all possible integer values of $n$?\\nsolution: Dividing by $4$, we have $0<n<7\\\\frac{1}{2}$. The integer solutions to this chain of inequalities are $n=1,2,3,4,5,6,7$. The sum of these integers is $\\\\boxed{28}$.\\nanswer: 28']\n",
      "question : How many integers between $100$ and $150$ have three different digits in increasing order? One such integer is $129$.\n",
      "solution: We will break up the problem into cases based on the second digit and count the number of integers in each case. If the second digit is 0, there are no integers because the first digit (1) is larger than the second. Similarly, if the second digit is 1, there are no integers. If the second digit is 2, there are 7 integers (with third digit from 3 to 9, inclusive). If the second digit is 3, there are 6 integers (with third digit from 4 to 9, inclusive). If the second digit is 4, there are 5 integers (with third digit from 5 to 9, inclusive). Among all the cases, there are $7+6+5=\\boxed{18}$ integers.\n",
      "answer: 18\n",
      "['question : How many integers between $100$ and $150$ have three different digits in increasing order? One such integer is $129$.\\nsolution: We will break up the problem into cases based on the second digit and count the number of integers in each case. If the second digit is 0, there are no integers because the first digit (1) is larger than the second. Similarly, if the second digit is 1, there are no integers. If the second digit is 2, there are 7 integers (with third digit from 3 to 9, inclusive). If the second digit is 3, there are 6 integers (with third digit from 4 to 9, inclusive). If the second digit is 4, there are 5 integers (with third digit from 5 to 9, inclusive). Among all the cases, there are $7+6+5=\\\\boxed{18}$ integers.\\nanswer: 18']\n",
      "question : Regular pentagon $ABCDE$ and regular hexagon $AEFGHI$ are drawn on opposite sides of line segment $AE$ such that they are coplanar. What is the degree measure of exterior angle $DEF$? [asy]\n",
      "draw((0,2.5)--(0,7.5)--(4,10)--(8,7.5)--(8,2.5)--(4,0)--cycle,linewidth(1));\n",
      "draw((8,2.5)--(11.5,-1)--(9,-5)--(5,-4.5)--(4,0),linewidth(1));\n",
      "dot((0,2.5)); dot((0,7.5)); dot ((4,10)); dot((8,7.5)); dot((8,2.5)); dot((4,0));\n",
      "\n",
      "label(\"I\",(0,2.5),W); label(\"H\",(0,7.5),W); label(\"G\",(4,10),N);\n",
      "\n",
      "label(\"F\",(8,7.5),E); label(\"E\",(8,2.5),NW); label(\"A\",(4,0),SW);\n",
      "dot((11.5,-1)); dot((9,-5)); dot((5,-4.5));\n",
      "label(\"D\",(11.5,-1),E); label(\"C\",(9,-5),SE); label(\"B\",(5,-4.5),SW);\n",
      "[/asy]\n",
      "solution: We know that the sum of the degree measures of the interior angles of a polygon can be found using the formula $180(n-2)$ where $n$ is the total number of sides of the polygon. Since the polygons in this problem are regular, each interior angle measure can be found by substituting the appropriate $n$ into the formula $\\frac{180(n-2)}{n}$. From this, we know that $\\angle DEA$, an interior angle of a regular pentagon, has degree measure $\\frac{180(5-2)}{5}=108 ^{\\circ}$. We also have that $\\angle FEA$, an interior angle of a regular hexagon, has degree measure $\\frac{180(6-2)}{6}=120 ^{\\circ}$.\n",
      "\n",
      "Finally, we know that the angle measures of $\\angle DEA$, $\\angle FEA$, and $\\angle DEF$ must sum to $360 ^\\circ$, so $\\angle DEF$ has an angle measure of $360 - 108 - 120 = \\boxed{132}$ degrees.\n",
      "answer: 132\n",
      "['question : Regular pentagon $ABCDE$ and regular hexagon $AEFGHI$ are drawn on opposite sides of line segment $AE$ such that they are coplanar. What is the degree measure of exterior angle $DEF$? [asy]\\ndraw((0,2.5)--(0,7.5)--(4,10)--(8,7.5)--(8,2.5)--(4,0)--cycle,linewidth(1));\\ndraw((8,2.5)--(11.5,-1)--(9,-5)--(5,-4.5)--(4,0),linewidth(1));\\ndot((0,2.5)); dot((0,7.5)); dot ((4,10)); dot((8,7.5)); dot((8,2.5)); dot((4,0));\\n\\nlabel(\"I\",(0,2.5),W); label(\"H\",(0,7.5),W); label(\"G\",(4,10),N);', 'label(\"F\",(8,7.5),E); label(\"E\",(8,2.5),NW); label(\"A\",(4,0),SW);\\ndot((11.5,-1)); dot((9,-5)); dot((5,-4.5));\\nlabel(\"D\",(11.5,-1),E); label(\"C\",(9,-5),SE); label(\"B\",(5,-4.5),SW);\\n[/asy]\\nsolution: We know that the sum of the degree measures of the interior angles of a polygon can be found using the formula $180(n-2)$ where $n$ is the total number of sides of the polygon. Since the polygons in this problem are regular, each interior angle measure can be found by substituting the appropriate $n$ into the formula $\\\\frac{180(n-2)}{n}$. From this, we know that $\\\\angle DEA$, an interior angle of a regular pentagon, has degree measure $\\\\frac{180(5-2)}{5}=108 ^{\\\\circ}$. We also have that $\\\\angle FEA$, an interior angle of a regular hexagon, has degree measure $\\\\frac{180(6-2)}{6}=120 ^{\\\\circ}$.', 'Finally, we know that the angle measures of $\\\\angle DEA$, $\\\\angle FEA$, and $\\\\angle DEF$ must sum to $360 ^\\\\circ$, so $\\\\angle DEF$ has an angle measure of $360 - 108 - 120 = \\\\boxed{132}$ degrees.\\nanswer: 132']\n",
      "question : A storm in Sydney, Australia, caused $\\$$30 million in damage. That estimate was in Australian dollars. At that time, 1.5 Australian dollars were worth 1 American dollar. Determine the number of American dollars of damage the storm caused.\n",
      "solution: Since 1.5 Australian dollars are worth 1 American dollar, 1 Australian dollar is worth $\\dfrac{1}{1.5}=\\dfrac{2}{3}$ American dollars. Therefore, the number of American dollars of damage was $$\\left( \\dfrac{2}{3} \\right) (30,\\!000,\\!000)=\\boxed{20,\\!000,\\!000}.$$\n",
      "answer: 20,\\!000,\\!000\n",
      "['question : A storm in Sydney, Australia, caused $\\\\$$30 million in damage. That estimate was in Australian dollars. At that time, 1.5 Australian dollars were worth 1 American dollar. Determine the number of American dollars of damage the storm caused.\\nsolution: Since 1.5 Australian dollars are worth 1 American dollar, 1 Australian dollar is worth $\\\\dfrac{1}{1.5}=\\\\dfrac{2}{3}$ American dollars. Therefore, the number of American dollars of damage was $$\\\\left( \\\\dfrac{2}{3} \\\\right) (30,\\\\!000,\\\\!000)=\\\\boxed{20,\\\\!000,\\\\!000}.$$\\nanswer: 20,\\\\!000,\\\\!000']\n",
      "question : How many 4-digit positive integers exist that satisfy the following conditions: (A) Each of the first two digits must be 1, 4, or 5, and (B) the last two digits cannot be the same digit, and (C) each of the last two digits must be 5, 7, or 8?\n",
      "solution: The first two digits may be any of 3, so there are $3^2 = 9$ choices for the first two. There are $3\\times 2$ possible values for the last two, since we have 3 choices for the first and then 2 for the second, so there are $9\\times 6 = \\boxed{54}$ possible integers.\n",
      "answer: 54\n",
      "['question : How many 4-digit positive integers exist that satisfy the following conditions: (A) Each of the first two digits must be 1, 4, or 5, and (B) the last two digits cannot be the same digit, and (C) each of the last two digits must be 5, 7, or 8?\\nsolution: The first two digits may be any of 3, so there are $3^2 = 9$ choices for the first two. There are $3\\\\times 2$ possible values for the last two, since we have 3 choices for the first and then 2 for the second, so there are $9\\\\times 6 = \\\\boxed{54}$ possible integers.\\nanswer: 54']\n",
      "question : A $\\textit{palindrome}$ is a positive integer which reads the same forward and backward, like $12321$ or $4884$.\n",
      "\n",
      "How many $4$-digit palindromes are there?\n",
      "solution: Once we've picked the first two digits of a $4$-digit palindrome, the other two digits are automatically chosen. Thus, we can make exactly one $4$-digit palindrome for every $2$-digit number. There are $90$ two-digit numbers ($10$ through $99$). Accordingly, there are also $\\boxed{90}$ four-digit palindromes.\n",
      "answer: 90\n",
      "[\"question : A $\\\\textit{palindrome}$ is a positive integer which reads the same forward and backward, like $12321$ or $4884$.\\n\\nHow many $4$-digit palindromes are there?\\nsolution: Once we've picked the first two digits of a $4$-digit palindrome, the other two digits are automatically chosen. Thus, we can make exactly one $4$-digit palindrome for every $2$-digit number. There are $90$ two-digit numbers ($10$ through $99$). Accordingly, there are also $\\\\boxed{90}$ four-digit palindromes.\\nanswer: 90\"]\n",
      "question : A circular garden is enlarged so that the new diameter is twice the old diameter. What is the ratio of the original area to the enlarged area? Express your answer as a common fraction.\n",
      "solution: If any linear dimension (such as radius, side length, height, etc.) of a two-dimensional figure is multiplied by $k$ while the shape of the figure remains the same, the area of the figure is multiplied by $k^2$.  Since the new diameter is 2 times the original diameter, the new area is $2^2=4$ times the old area.  Therefore, the ratio of original area to new area is $\\boxed{\\frac{1}{4}}$.\n",
      "answer: \\frac{1}{4}\n",
      "['question : A circular garden is enlarged so that the new diameter is twice the old diameter. What is the ratio of the original area to the enlarged area? Express your answer as a common fraction.\\nsolution: If any linear dimension (such as radius, side length, height, etc.) of a two-dimensional figure is multiplied by $k$ while the shape of the figure remains the same, the area of the figure is multiplied by $k^2$.  Since the new diameter is 2 times the original diameter, the new area is $2^2=4$ times the old area.  Therefore, the ratio of original area to new area is $\\\\boxed{\\\\frac{1}{4}}$.\\nanswer: \\\\frac{1}{4}']\n",
      "question : Calculate $[(12^{12} \\div 12^{11})^2 \\cdot 4^2] \\div 2^4$.\n",
      "solution: Remembering proper order of operations, first simplify the terms in the parentheses using the quotient of powers rule:\n",
      "\n",
      "$12^{12} \\div 12^{11} = 12^{12-11} = 12$ so that the expression becomes  \\[(12^2 \\cdot 4^2) \\div 2^4 = 12^2 \\cdot 4^2 \\div 2^4.\\] Since $4^2 = 4 \\cdot 4 = 2 \\cdot 2 \\cdot 2 \\cdot 2 = 2^4$, we have \\[12^2 \\cdot 4^2 \\div 2^4 = 12^2 \\cdot 1 = \\boxed{144}.\\]\n",
      "answer: 144\n",
      "['question : Calculate $[(12^{12} \\\\div 12^{11})^2 \\\\cdot 4^2] \\\\div 2^4$.\\nsolution: Remembering proper order of operations, first simplify the terms in the parentheses using the quotient of powers rule:\\n\\n$12^{12} \\\\div 12^{11} = 12^{12-11} = 12$ so that the expression becomes  \\\\[(12^2 \\\\cdot 4^2) \\\\div 2^4 = 12^2 \\\\cdot 4^2 \\\\div 2^4.\\\\] Since $4^2 = 4 \\\\cdot 4 = 2 \\\\cdot 2 \\\\cdot 2 \\\\cdot 2 = 2^4$, we have \\\\[12^2 \\\\cdot 4^2 \\\\div 2^4 = 12^2 \\\\cdot 1 = \\\\boxed{144}.\\\\]\\nanswer: 144']\n"
     ]
    }
   ],
   "source": [
    "if USE_RAG:\n",
    "    for doc in sampleDF[\"LLM Content\"][:10]:\n",
    "        print(doc)\n",
    "        txt =textSplitter.split_text(doc)\n",
    "        print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "234ff761",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:21.679102Z",
     "iopub.status.busy": "2024-06-20T11:41:21.678200Z",
     "iopub.status.idle": "2024-06-20T11:41:21.739591Z",
     "shell.execute_reply": "2024-06-20T11:41:21.738321Z"
    },
    "papermill": {
     "duration": 0.163437,
     "end_time": "2024-06-20T11:41:21.741431",
     "exception": false,
     "start_time": "2024-06-20T11:41:21.577994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1663\n"
     ]
    }
   ],
   "source": [
    "# set max question sample for retrive\n",
    "# maxQuestionSample= 2000#1000\n",
    "if USE_RAG:\n",
    "    docList = splitTextData(tempDF[:maxQuestionSample], \"LLM Content\") \n",
    "    print(len(docList))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fffd415",
   "metadata": {
    "papermill": {
     "duration": 0.096165,
     "end_time": "2024-06-20T11:41:21.931340",
     "exception": false,
     "start_time": "2024-06-20T11:41:21.835175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bb83b9b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:22.128054Z",
     "iopub.status.busy": "2024-06-20T11:41:22.127683Z",
     "iopub.status.idle": "2024-06-20T11:41:22.131925Z",
     "shell.execute_reply": "2024-06-20T11:41:22.130948Z"
    },
    "papermill": {
     "duration": 0.103227,
     "end_time": "2024-06-20T11:41:22.133973",
     "exception": false,
     "start_time": "2024-06-20T11:41:22.030746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# docList[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ec9c53",
   "metadata": {
    "papermill": {
     "duration": 0.1032,
     "end_time": "2024-06-20T11:41:22.338827",
     "exception": false,
     "start_time": "2024-06-20T11:41:22.235627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# VectorDB inital and store document into Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "97060a63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:22.530135Z",
     "iopub.status.busy": "2024-06-20T11:41:22.529737Z",
     "iopub.status.idle": "2024-06-20T11:41:52.711235Z",
     "shell.execute_reply": "2024-06-20T11:41:52.710205Z"
    },
    "papermill": {
     "duration": 30.373364,
     "end_time": "2024-06-20T11:41:52.808015",
     "exception": false,
     "start_time": "2024-06-20T11:41:22.434651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1663\n",
      "CPU times: user 31 s, sys: 121 ms, total: 31.1 s\n",
      "Wall time: 30.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if USE_RAG:\n",
    "    # VectorDB inital and store document into Vector DB\n",
    "    db = FAISS.from_documents(documents =docList, embedding= embedding)\n",
    "    print(db.index.ntotal) # number of total index size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad613f45",
   "metadata": {
    "papermill": {
     "duration": 0.094449,
     "end_time": "2024-06-20T11:41:52.997071",
     "exception": false,
     "start_time": "2024-06-20T11:41:52.902622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6735319",
   "metadata": {
    "papermill": {
     "duration": 0.094024,
     "end_time": "2024-06-20T11:41:53.185940",
     "exception": false,
     "start_time": "2024-06-20T11:41:53.091916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Simiarity  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8fc2aa6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:53.375646Z",
     "iopub.status.busy": "2024-06-20T11:41:53.374645Z",
     "iopub.status.idle": "2024-06-20T11:41:53.404837Z",
     "shell.execute_reply": "2024-06-20T11:41:53.403857Z"
    },
    "papermill": {
     "duration": 0.12693,
     "end_time": "2024-06-20T11:41:53.407094",
     "exception": false,
     "start_time": "2024-06-20T11:41:53.280164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_RAG:\n",
    "    query = trainDF[\"problem\"][1]\n",
    "    resultRAG =db.similarity_search(query)\n",
    "# resultRAG = db.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6672dfde",
   "metadata": {
    "papermill": {
     "duration": 0.094206,
     "end_time": "2024-06-20T11:41:53.596672",
     "exception": false,
     "start_time": "2024-06-20T11:41:53.502466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# create retriever object from vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c865a82e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:53.793432Z",
     "iopub.status.busy": "2024-06-20T11:41:53.792615Z",
     "iopub.status.idle": "2024-06-20T11:41:53.797425Z",
     "shell.execute_reply": "2024-06-20T11:41:53.796497Z"
    },
    "papermill": {
     "duration": 0.104586,
     "end_time": "2024-06-20T11:41:53.799295",
     "exception": false,
     "start_time": "2024-06-20T11:41:53.694709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_RAG:\n",
    "    num_docs= 2 # set max top k=  3 rank similarity  \n",
    "    retriever  = db.as_retriever(  search_kwargs={\"k\": num_docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "589af9a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:53.987603Z",
     "iopub.status.busy": "2024-06-20T11:41:53.987261Z",
     "iopub.status.idle": "2024-06-20T11:41:54.012621Z",
     "shell.execute_reply": "2024-06-20T11:41:54.011706Z"
    },
    "papermill": {
     "duration": 0.122628,
     "end_time": "2024-06-20T11:41:54.014534",
     "exception": false,
     "start_time": "2024-06-20T11:41:53.891906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test reteriver invoke\n",
    "if USE_RAG:\n",
    "    query = trainDF[\"problem\"][1]\n",
    "    resultRAG = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a3a07e82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:54.207421Z",
     "iopub.status.busy": "2024-06-20T11:41:54.206460Z",
     "iopub.status.idle": "2024-06-20T11:41:54.210489Z",
     "shell.execute_reply": "2024-06-20T11:41:54.209726Z"
    },
    "papermill": {
     "duration": 0.103068,
     "end_time": "2024-06-20T11:41:54.212573",
     "exception": false,
     "start_time": "2024-06-20T11:41:54.109505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for similariry search with score rseult\n",
    "# print(resultRAG[0][0]) # for page context\n",
    "# print(resultRAG[0][1]) # for socre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c56ed",
   "metadata": {
    "papermill": {
     "duration": 0.094252,
     "end_time": "2024-06-20T11:41:54.403388",
     "exception": false,
     "start_time": "2024-06-20T11:41:54.309136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2db6fab2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:54.592972Z",
     "iopub.status.busy": "2024-06-20T11:41:54.592619Z",
     "iopub.status.idle": "2024-06-20T11:41:54.600372Z",
     "shell.execute_reply": "2024-06-20T11:41:54.599056Z"
    },
    "papermill": {
     "duration": 0.105234,
     "end_time": "2024-06-20T11:41:54.602323",
     "exception": false,
     "start_time": "2024-06-20T11:41:54.497089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1:\n",
      "question : The three-digit integer $63\\underline{\\hphantom{0}}$ is a multiple of 3. What is the greatest possible difference between two of the possibilities for the units digit?\n",
      "solution: The integer is a multiple of three if the sum of its digits is a multiple of three. Since 6 and 3 are both multiples of three, the units digit must also be a multiple of three. The possibilities for this digit are 0, 3, 6, or 9. The greatest possible difference between any two possibilities is $9-0=\\boxed{9}$.\n",
      "answer: 9\n",
      "Rank 2:\n",
      "question : How many distinct three-digit numbers can be written with the digits $1$, $2$, $3$ and $4$ if no digit may be used more than once in a three-digit number?\n",
      "solution: There are 4 choices for which number can be in the hundreds place.  For each possibility, there are 3 choices remaining for which number can be in the tens place, leaving 2 choices for the units place.  This gives a total of $4\\cdot 3\\cdot 2 = \\boxed{24}$ possible three-digit numbers.\n",
      "answer: 24\n",
      "question : The three-digit integer $63\\underline{\\hphantom{0}}$ is a multiple of 3. What is the greatest possible difference between two of the possibilities for the units digit?\n",
      "solution: The integer is a multiple of three if the sum of its digits is a multiple of three. Since 6 and 3 are both multiples of three, the units digit must also be a multiple of three. The possibilities for this digit are 0, 3, 6, or 9. The greatest possible difference between any two possibilities is $9-0=\\boxed{9}$.\n",
      "answer: 9\n",
      "question : How many distinct three-digit numbers can be written with the digits $1$, $2$, $3$ and $4$ if no digit may be used more than once in a three-digit number?\n",
      "solution: There are 4 choices for which number can be in the hundreds place.  For each possibility, there are 3 choices remaining for which number can be in the tens place, leaving 2 choices for the units place.  This gives a total of $4\\cdot 3\\cdot 2 = \\boxed{24}$ possible three-digit numbers.\n",
      "answer: 24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if USE_RAG:\n",
    "    out= \"\"\n",
    "    for i, ret in enumerate(resultRAG):\n",
    "        print(f\"Rank {i+1}:\")\n",
    "        print(ret.page_content)\n",
    "        out += ret.page_content +\"\\n\"\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d1099b",
   "metadata": {
    "papermill": {
     "duration": 0.098685,
     "end_time": "2024-06-20T11:41:54.795235",
     "exception": false,
     "start_time": "2024-06-20T11:41:54.696550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c116bd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:54.982918Z",
     "iopub.status.busy": "2024-06-20T11:41:54.982095Z",
     "iopub.status.idle": "2024-06-20T11:41:54.987692Z",
     "shell.execute_reply": "2024-06-20T11:41:54.986668Z"
    },
    "papermill": {
     "duration": 0.101665,
     "end_time": "2024-06-20T11:41:54.989696",
     "exception": false,
     "start_time": "2024-06-20T11:41:54.888031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?\n",
      "Similarity:\n",
      "question : The three-digit integer $63\\underline{\\hphantom{0}}$ is a multiple of 3. What is the greatest possible difference between two of the possibilities for the units digit?\n",
      "solution: The integer is a multiple of three if the sum of its digits is a multiple of three. Since 6 and 3 are both multiples of three, the units digit must also be a multiple of three. The possibilities for this digit are 0, 3, 6, or 9. The greatest possible difference between any two possibilities is $9-0=\\boxed{9}$.\n",
      "answer: 9\n"
     ]
    }
   ],
   "source": [
    "if USE_RAG:\n",
    "    print(f\"\"\"Question: {query}\\nSimilarity:\\n{resultRAG[0].page_content}\"\"\")\n",
    "# print(f\"\"\"Question: {query}\\nSimilarity: {resultRAG[0][0]}\"\"\") # for silimarity with score\n",
    "# [0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "030fd5f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:55.179987Z",
     "iopub.status.busy": "2024-06-20T11:41:55.179633Z",
     "iopub.status.idle": "2024-06-20T11:41:55.183810Z",
     "shell.execute_reply": "2024-06-20T11:41:55.182933Z"
    },
    "papermill": {
     "duration": 0.101983,
     "end_time": "2024-06-20T11:41:55.185724",
     "exception": false,
     "start_time": "2024-06-20T11:41:55.083741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_RAG:\n",
    "    len(resultRAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fbc72fb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:55.377830Z",
     "iopub.status.busy": "2024-06-20T11:41:55.377464Z",
     "iopub.status.idle": "2024-06-20T11:41:55.383012Z",
     "shell.execute_reply": "2024-06-20T11:41:55.382021Z"
    },
    "papermill": {
     "duration": 0.102507,
     "end_time": "2024-06-20T11:41:55.385017",
     "exception": false,
     "start_time": "2024-06-20T11:41:55.282510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : The three-digit integer $63\\underline{\\hphantom{0}}$ is a multiple of 3. What is the greatest possible difference between two of the possibilities for the units digit?\n",
      "solution: The integer is a multiple of three if the sum of its digits is a multiple of three. Since 6 and 3 are both multiples of three, the units digit must also be a multiple of three. The possibilities for this digit are 0, 3, 6, or 9. The greatest possible difference between any two possibilities is $9-0=\\boxed{9}$.\n",
      "answer: 9\n"
     ]
    }
   ],
   "source": [
    "if USE_RAG:\n",
    "    print(resultRAG[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6cd86828",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:55.621907Z",
     "iopub.status.busy": "2024-06-20T11:41:55.621087Z",
     "iopub.status.idle": "2024-06-20T11:41:55.625505Z",
     "shell.execute_reply": "2024-06-20T11:41:55.624665Z"
    },
    "papermill": {
     "duration": 0.102075,
     "end_time": "2024-06-20T11:41:55.627426",
     "exception": false,
     "start_time": "2024-06-20T11:41:55.525351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del tempDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9e8597",
   "metadata": {
    "papermill": {
     "duration": 0.097759,
     "end_time": "2024-06-20T11:41:55.818023",
     "exception": false,
     "start_time": "2024-06-20T11:41:55.720264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test LLM Respoonse with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dc665229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:41:56.014511Z",
     "iopub.status.busy": "2024-06-20T11:41:56.013770Z",
     "iopub.status.idle": "2024-06-20T11:43:24.959492Z",
     "shell.execute_reply": "2024-06-20T11:43:24.958588Z"
    },
    "papermill": {
     "duration": 89.145378,
     "end_time": "2024-06-20T11:43:25.059886",
     "exception": false,
     "start_time": "2024-06-20T11:41:55.914508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1:\n",
      "question : The smaller square in the figure below has a perimeter of $4$ cm, and the larger square has an area of $16$ $\\text{cm}^2$.  What is the distance from point $A$ to point $B$? Express your answer as a decimal to the nearest tenth.\n",
      "Rank 2:\n",
      "In order to find $x$, we consider the three red lines.  Since $k$ and $\\ell$ are parallel, we determine that we have the  pair of corresponding angles below:\n",
      "\n",
      "[asy]\n",
      "size(200);\n",
      "import markers;\n",
      "pair A = dir(-22)*(0,0);\n",
      "pair B = dir(-22)*(4,0);\n",
      "pair C = dir(-22)*(4,2);\n",
      "pair D = dir(-22)*(0,2);\n",
      "pair F = dir(-22)*(0,1.3);\n",
      "pair G = dir(-22)*(4,1.3);\n",
      "pair H = dir(-22)*(2,1);\n",
      "pair I = dir(-22)*(1.35,1.3);\n",
      "\n",
      "markangle(Label(\"$x$\",Relative(0.5)),n=1,radius=11,I+B,I,(2*I-B));\n",
      "markangle(Label(\"$30^\\circ$\",Relative(0.2)),n=1,radius=16,(2*I-B),I,I-B,red);\n",
      "\n",
      "pair X,Y;\n",
      "\n",
      "X=A;\n",
      "Y=B;\n",
      "draw(1.3*X-.3*Y--1.3*Y-.3*X,red+1bp);\n",
      "\n",
      "X=B;\n",
      "Y=D;\n",
      "draw(1.3*X-.3*Y--1.3*Y-.3*X,red+1bp);\n",
      "\n",
      "X=G;\n",
      "Y=F;\n",
      "draw(1.3*X-.3*Y--1.3*Y-.3*X,red+1bp);\n",
      "\n",
      "label(\"$\\ell$\",1.4*A-.4*B);\n",
      "label(\"$k$\",1.4*F-.4*G);\n",
      "\n",
      "label(\"$30^\\circ$\",B+(-.9,.6),red);\n",
      "[/asy]\n",
      "\n",
      "This angle is the supplement of $x$, so the measure of $x$ is  \\[180^\\circ-30^\\circ=\\boxed{150^\\circ}.\\]\n",
      "answer: 150^\\circ\n",
      "Qusetion 2 : Let $k, l > 0$ be parameters. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. What is the sum of the squares of the distances from $A$ and $B$ to the origin?\n",
      "Response : \n",
      "you are act as Mathematician, solve the math problem reasonable and logical from given question follow the requirement as below:\n",
      "CONTEXT: question : The smaller square in the figure below has a perimeter of $4$ cm, and the larger square has an area of $16$ $\\text{cm}^2$.  What is the distance from point $A$ to point $B$? Express your answer as a decimal to the nearest tenth.\n",
      "In order to find $x$, we consider the three red lines.  Since $k$ and $\\ell$ are parallel, we determine that we have the  pair of corresponding angles below:\n",
      "\n",
      "[asy]\n",
      "size(200);\n",
      "import markers;\n",
      "pair A = dir(-22)*(0,0);\n",
      "pair B = dir(-22)*(4,0);\n",
      "pair C = dir(-22)*(4,2);\n",
      "pair D = dir(-22)*(0,2);\n",
      "pair F = dir(-22)*(0,1.3);\n",
      "pair G = dir(-22)*(4,1.3);\n",
      "pair H = dir(-22)*(2,1);\n",
      "pair I = dir(-22)*(1.35,1.3);\n",
      "\n",
      "markangle(Label(\"$x$\",Relative(0.5)),n=1,radius=11,I+B,I,(2*I-B));\n",
      "markangle(Label(\"$30^\\circ$\",Relative(0.2)),n=1,radius=16,(2*I-B),I,I-B,red);\n",
      "\n",
      "pair X,Y;\n",
      "\n",
      "X=A;\n",
      "Y=B;\n",
      "draw(1.3*X-.3*Y--1.3*Y-.3*X,red+1bp);\n",
      "\n",
      "X=B;\n",
      "Y=D;\n",
      "draw(1.3*X-.3*Y--1.3*Y-.3*X,red+1bp);\n",
      "\n",
      "X=G;\n",
      "Y=F;\n",
      "draw(1.3*X-.3*Y--1.3*Y-.3*X,red+1bp);\n",
      "\n",
      "label(\"$\\ell$\",1.4*A-.4*B);\n",
      "label(\"$k$\",1.4*F-.4*G);\n",
      "\n",
      "label(\"$30^\\circ$\",B+(-.9,.6),red);\n",
      "[/asy]\n",
      "\n",
      "This angle is the supplement of $x$, so the measure of $x$ is  \\[180^\\circ-30^\\circ=\\boxed{150^\\circ}.\\]\n",
      "answer: 150^\\circ\n",
      "\n",
      "The context contain sample question, solution and answer with similarity to user Question. Use context for assist to solve math question step by step.  \n",
      "Solving the answer and rethinking multiple step by step from user Question.\n",
      "User Question: Let $k, l > 0$ be parameters. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. What is the sum of the squares of the distances from $A$ and $B$ to the origin?.\n",
      "Careful to logical reasoning  multiple steps to find the best solution \n",
      "Only Output answer in json format with key \"answer\" and \"explanation\" \n",
      "{\"answer\": \"The sum of squares of distances from A and B to the origin is 100.\", \"explanation\": \"The given information is: The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. The distance from a point to the origin is given by the formula $d = \\sqrt{x^2 + y^2}$. So, the distance from $A$ to the origin is $d_A = \\sqrt{x_A^2 + y_A^2}$, where $x_A$ and $y_A$ are the coordinates of point $A$. Similarly, the distance from $B$ to the origin is $d_B = \\sqrt{x_B^2 + y_B^2}$, where $x_B$ and $y_B$ are the coordinates of point $B$. The sum of squares of distances from $A$ and $B$ to the origin is $S = d_A^2 + d_B^2$. Substituting the values of $d_A$ and $d_B$ into this equation, we get $S = (\\sqrt{x_A^2 + y_A^2})^2 + (\\sqrt{x_B^2 + y_B^2})^2$. Therefore, the sum of squares of distances from $A$ and $B$ to the origin is 100.\"}\n",
      "\n",
      "**Note:** This is a sample problem and solution. The provided text does not contain information about the actual problem or solution. Therefore, I have created a sample problem and solution that is similar to the text provided.\n",
      "----------------------------------------\n",
      "Rank 1:\n",
      "question : The three-digit integer $63\\underline{\\hphantom{0}}$ is a multiple of 3. What is the greatest possible difference between two of the possibilities for the units digit?\n",
      "solution: The integer is a multiple of three if the sum of its digits is a multiple of three. Since 6 and 3 are both multiples of three, the units digit must also be a multiple of three. The possibilities for this digit are 0, 3, 6, or 9. The greatest possible difference between any two possibilities is $9-0=\\boxed{9}$.\n",
      "answer: 9\n",
      "Rank 2:\n",
      "question : How many distinct three-digit numbers can be written with the digits $1$, $2$, $3$ and $4$ if no digit may be used more than once in a three-digit number?\n",
      "solution: There are 4 choices for which number can be in the hundreds place.  For each possibility, there are 3 choices remaining for which number can be in the tens place, leaving 2 choices for the units place.  This gives a total of $4\\cdot 3\\cdot 2 = \\boxed{24}$ possible three-digit numbers.\n",
      "answer: 24\n",
      "Qusetion 2 : Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?\n",
      "Response : \n",
      "you are act as Mathematician, solve the math problem reasonable and logical from given question follow the requirement as below:\n",
      "CONTEXT: question : The three-digit integer $63\\underline{\\hphantom{0}}$ is a multiple of 3. What is the greatest possible difference between two of the possibilities for the units digit?\n",
      "solution: The integer is a multiple of three if the sum of its digits is a multiple of three. Since 6 and 3 are both multiples of three, the units digit must also be a multiple of three. The possibilities for this digit are 0, 3, 6, or 9. The greatest possible difference between any two possibilities is $9-0=\\boxed{9}$.\n",
      "answer: 9\n",
      "question : How many distinct three-digit numbers can be written with the digits $1$, $2$, $3$ and $4$ if no digit may be used more than once in a three-digit number?\n",
      "solution: There are 4 choices for which number can be in the hundreds place.  For each possibility, there are 3 choices remaining for which number can be in the tens place, leaving 2 choices for the units place.  This gives a total of $4\\cdot 3\\cdot 2 = \\boxed{24}$ possible three-digit numbers.\n",
      "answer: 24\n",
      "\n",
      "The context contain sample question, solution and answer with similarity to user Question. Use context for assist to solve math question step by step.  \n",
      "Solving the answer and rethinking multiple step by step from user Question.\n",
      "User Question: Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?.\n",
      "Careful to logical reasoning  multiple steps to find the best solution \n",
      "Only Output answer in json format with key \"answer\" and \"explanation\" \n",
      "{\"answer\": 111, \"explanation\": \"The sum of any two yellow numbers is equal to a blue number. So, the maximum number of yellow numbers is the number that is divisible by 2 and 3, which is 111.\"}\n",
      "\n",
      "**SOLUTION:**\n",
      "\n",
      "**1. Identify the multiples of 2 and 3 within the range:**\n",
      "- Multiples of 2: $120, $240, $360, ..., $960\n",
      "- Multiples of 3: $180, $360, $540, ..., $930\n",
      "\n",
      "**2. Find the common multiples:**\n",
      "- The common multiples are $360, $540, $960\n",
      "\n",
      "**3. Count the number of yellow numbers:**\n",
      "- To be yellow, the number must be divisible by both 2 and 3.\n",
      "- The number of multiples of 2 and 3 within the range is 3.\n",
      "\n",
      "**Therefore, the maximum number of yellow numbers is 3.**\n",
      "\n",
      "**Answer:**\n",
      "{\"answer\": 3, \"explanation\": \"The sum of any two yellow numbers is equal to a blue number. So, the maximum number of yellow numbers is the number that is divisible by 2 and 3, which is 3.\"}\n",
      "----------------------------------------\n",
      "Rank 1:\n",
      "question : A lucky integer is a positive integer which is divisible by the sum of its digits. What is the least positive multiple of 9 that is not a lucky integer?\n",
      "solution: List the first few multiples of 9: $9, 18, 27, 36, \\dots$. We see that these are all lucky integers because their digits sum to 9, and the pattern of increasing the first digit by 1 while decreasing the second digit by 1 preserves this property. However, this pattern stops after the last digit reaches zero. Indeed, 90 is still a lucky integer, but 99 is not, since the digits sum to 18 and 99 is not divisible by 18. Thus $\\boxed{99}$ is the least positive multiple of 9 which is not a lucky integer.\n",
      "answer: 99\n",
      "Rank 2:\n",
      "question : How many 4-digit positive integers exist that satisfy the following conditions: (A) Each of the first two digits must be 1, 4, or 5, and (B) the last two digits cannot be the same digit, and (C) each of the last two digits must be 5, 7, or 8?\n",
      "solution: The first two digits may be any of 3, so there are $3^2 = 9$ choices for the first two. There are $3\\times 2$ possible values for the last two, since we have 3 choices for the first and then 2 for the second, so there are $9\\times 6 = \\boxed{54}$ possible integers.\n",
      "answer: 54\n",
      "Qusetion 2 : Let the `sparkle' operation on positive integer $n$ consist of calculating the sum of the digits of $n$ and taking its factorial, e.g. the sparkle of 13 is $4! = 24$. A robot starts with a positive integer on a blackboard, then after each second for the rest of eternity, replaces the number on the board with its sparkle. For some `special' numbers, if they're the first number, then eventually every number that appears will be less than 6. How many such special numbers are there with at most 36 digits?\n",
      "Response : \n",
      "you are act as Mathematician, solve the math problem reasonable and logical from given question follow the requirement as below:\n",
      "CONTEXT: question : A lucky integer is a positive integer which is divisible by the sum of its digits. What is the least positive multiple of 9 that is not a lucky integer?\n",
      "solution: List the first few multiples of 9: $9, 18, 27, 36, \\dots$. We see that these are all lucky integers because their digits sum to 9, and the pattern of increasing the first digit by 1 while decreasing the second digit by 1 preserves this property. However, this pattern stops after the last digit reaches zero. Indeed, 90 is still a lucky integer, but 99 is not, since the digits sum to 18 and 99 is not divisible by 18. Thus $\\boxed{99}$ is the least positive multiple of 9 which is not a lucky integer.\n",
      "answer: 99\n",
      "question : How many 4-digit positive integers exist that satisfy the following conditions: (A) Each of the first two digits must be 1, 4, or 5, and (B) the last two digits cannot be the same digit, and (C) each of the last two digits must be 5, 7, or 8?\n",
      "solution: The first two digits may be any of 3, so there are $3^2 = 9$ choices for the first two. There are $3\\times 2$ possible values for the last two, since we have 3 choices for the first and then 2 for the second, so there are $9\\times 6 = \\boxed{54}$ possible integers.\n",
      "answer: 54\n",
      "\n",
      "The context contain sample question, solution and answer with similarity to user Question. Use context for assist to solve math question step by step.  \n",
      "Solving the answer and rethinking multiple step by step from user Question.\n",
      "User Question: Let the `sparkle' operation on positive integer $n$ consist of calculating the sum of the digits of $n$ and taking its factorial, e.g. the sparkle of 13 is $4! = 24$. A robot starts with a positive integer on a blackboard, then after each second for the rest of eternity, replaces the number on the board with its sparkle. For some `special' numbers, if they're the first number, then eventually every number that appears will be less than 6. How many such special numbers are there with at most 36 digits?.\n",
      "Careful to logical reasoning  multiple steps to find the best solution \n",
      "Only Output answer in json format with key \"answer\" and \"explanation\" \n",
      "{\"answer\": 1, \"explanation\": \"The sparkle operation consists of calculating the sum of the digits of a number and taking its factorial. If the first number is special, then eventually every number that appears will be less than 6. The special numbers are 1, 2, 3, 4, and 5.\"}\n",
      "\n",
      "**SOLUTION:**\n",
      "\n",
      "**Step 1: Identify the special numbers.**\n",
      "\n",
      "The special numbers are the numbers whose sparkle is less than 6. To find these numbers, we need to calculate the sparkle of each number and see if it is less than 6. The sparkle of a number is the factorial of the sum of its digits. For example, the sparkle of 13 is 4!, which is 24.\n",
      "\n",
      "**Step 2: Count the number of special numbers.**\n",
      "\n",
      "Once we have identified the special numbers, we can count them. There are a total of 5 special numbers with at most 36 digits: 1, 2, 3, 4, and 5.\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "{\"answer\": 5, \"explanation\": \"The sparkle operation consists of calculating the sum of the digits of a number and taking its factorial. If the first number is special, then eventually every number that appears will be less than 6. The special numbers are 1, 2, 3, 4, and 5.\"}\n",
      "----------------------------------------\n",
      "CPU times: user 1min 25s, sys: 3.19 s, total: 1min 28s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if USE_RAG:\n",
    "    # Test without prompt instruction for assist reasoning\n",
    "    newPrompt = PromptTemplate(input_variables=[\"question\", \"context\"], template=templatePrompt7)\n",
    "    result = []\n",
    "    for i, qa in enumerate(trainDF[\"problem\"][0:3]):\n",
    "        ragContext = \"\" # for reg context input to prompt \n",
    "        resultRAG = retriever.invoke(qa)\n",
    "        #     ragContext = resultRAG[0].page_content\n",
    "        for i, ret in enumerate(resultRAG):\n",
    "            print(f\"Rank {i+1}:\")\n",
    "            print(ret.page_content)\n",
    "            ragContext += ret.page_content +\"\\n\"\n",
    "        finalPrmpt = newPrompt.format(\n",
    "            question=qa,\n",
    "            context=ragContext\n",
    "        )\n",
    "        rel = generateResponse(finalPrmpt, maxOutToken=2048)\n",
    "        print(f\"Qusetion {i+1} : {qa}\\nResponse : {rel}\")\n",
    "        print(\"--\"*20)\n",
    "        result.append(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cb3c6dc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:25.255665Z",
     "iopub.status.busy": "2024-06-20T11:43:25.255299Z",
     "iopub.status.idle": "2024-06-20T11:43:25.269819Z",
     "shell.execute_reply": "2024-06-20T11:43:25.268033Z"
    },
    "papermill": {
     "duration": 0.111626,
     "end_time": "2024-06-20T11:43:25.271791",
     "exception": false,
     "start_time": "2024-06-20T11:43:25.160165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find answer location : 0\n",
      "the sum of squares of distances from a and b to the origin is 100. explanation: the given information is: the parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $a$ and $b$. these points are distance 6 apart. the distance from a point to the origin is given by the formula $d = \\sqr\n",
      "Start loc: 1252\n",
      "150^\\circ\n",
      "Question 0 \n",
      "Let $k, l > 0$ be parameters. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. What is the sum of the squares of the distances from $A$ and $B$ to the origin?\n",
      "\n",
      "Result: 150^\\circ\n",
      "Actual Ans: 52\n",
      "----------------------------------------\n",
      "find answer location : 0\n",
      "111 explanation: the sum of any two yellow numbers is equal to a blue number. so the maximum number of yellow numbers is the number that is divisible by 2 and 3 which is 111.\n",
      "find answer location : 0\n",
      "3 explanation: the sum of any two yellow numbers is equal to a blue number. so the maximum number of yellow numbers is the number that is divisible by 2 and 3 which is 3.\n",
      "Start loc: 640\n",
      "9\n",
      "Question 1 \n",
      "Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?\n",
      "\n",
      "Result: 9\n",
      "Actual Ans: 250\n",
      "----------------------------------------\n",
      "find answer location : 0\n",
      "1 explanation: the sparkle operation consists of calculating the sum of the digits of a number and taking its factorial. if the first number is special then eventually every number that appears will be less than 6. the special numbers are 1 2 3 4 and 5.\n",
      "find answer location : 0\n",
      "5 explanation: the sparkle operation consists of calculating the sum of the digits of a number and taking its factorial. if the first number is special then eventually every number that appears will be less than 6. the special numbers are 1 2 3 4 and 5.\n",
      "Start loc: 816\n",
      "99\n",
      "Question 2 \n",
      "Let the `sparkle' operation on positive integer $n$ consist of calculating the sum of the digits of $n$ and taking its factorial, e.g. the sparkle of 13 is $4! = 24$. A robot starts with a positive integer on a blackboard, then after each second for the rest of eternity, replaces the number on the board with its sparkle. For some `special' numbers, if they're the first number, then eventually every number that appears will be less than 6. How many such special numbers are there with at most 36 digits?\n",
      "\n",
      "Result: 99\n",
      "Actual Ans: 702\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if USE_RAG:\n",
    "    # compare the result, \n",
    "    for i, rel in enumerate(result):\n",
    "        jsonTxt= llmJSONParser3(rel) # use llm JSON parser get answer\n",
    "        if jsonTxt:\n",
    "            # print(f\"\"\"Question {i} \\n{trainDF[\"problem\"].iloc[i+4]}\\n\\nResult: {jsonTxt[\"answer\"]}\"\"\") # for llm json parser1\n",
    "            print(f\"\"\"Question {i} \\n{trainDF[\"problem\"].iloc[i]}\\n\\nResult: {jsonTxt}\"\"\")# for llm json Parser3\n",
    "            print(f\"\"\"Actual Ans: {trainDF[\"answer\"].iloc[i]}\"\"\")\n",
    "            if USE_WANDB:\n",
    "                wandbRAGTable.add_data( llmModel, \n",
    "                                           trainDF[\"problem\"].iloc[i], \n",
    "                                           trainDF[\"answer\"].iloc[i],\n",
    "                                            rel, # llmm response\n",
    "                                            jsonTxt)\n",
    "\n",
    "        else:\n",
    "#           ans= getAnswer(rel)\n",
    "            ans = getAnswerParser2(rel) # not json format use get anser parser\n",
    "            if ans:\n",
    "                print(f\"\"\"Question {i} \\n{trainDF[\"problem\"].iloc[i]}\\n\\nResult: {ans}\"\"\")\n",
    "                print(f\"\"\"Actual Ans: {trainDF[\"answer\"].iloc[i]}\"\"\")\n",
    "                if USE_WANDB:\n",
    "                    wandbRAGTable.add_data( llmModel, \n",
    "                                           trainDF[\"problem\"].iloc[i], \n",
    "                                           trainDF[\"answer\"].iloc[i],\n",
    "                                            rel, # llmm response\n",
    "                                            ans)\n",
    "        print(\"--\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "98dd5d09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:25.468621Z",
     "iopub.status.busy": "2024-06-20T11:43:25.467640Z",
     "iopub.status.idle": "2024-06-20T11:43:31.164420Z",
     "shell.execute_reply": "2024-06-20T11:43:31.163557Z"
    },
    "papermill": {
     "duration": 5.799572,
     "end_time": "2024-06-20T11:43:31.166486",
     "exception": false,
     "start_time": "2024-06-20T11:43:25.366914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33meternal-butterfly-6\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/johnsonhk88/ai-math-solving-simple-rag/runs/v42p3ax0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/johnsonhk88/ai-math-solving-simple-rag\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240620_114056-v42p3ax0/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if USE_RAG and USE_WANDB :\n",
    "    wandb.log({\"rag_generations\": wandbRAGTable})\n",
    "    runTask2.finish()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9eb109c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:31.381427Z",
     "iopub.status.busy": "2024-06-20T11:43:31.380540Z",
     "iopub.status.idle": "2024-06-20T11:43:31.777875Z",
     "shell.execute_reply": "2024-06-20T11:43:31.776940Z"
    },
    "papermill": {
     "duration": 0.512361,
     "end_time": "2024-06-20T11:43:31.779728",
     "exception": false,
     "start_time": "2024-06-20T11:43:31.267367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3566"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9fb421",
   "metadata": {
    "papermill": {
     "duration": 0.094215,
     "end_time": "2024-06-20T11:43:31.969375",
     "exception": false,
     "start_time": "2024-06-20T11:43:31.875160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LoRA fine tuning\n",
    "# Improve LARGE LANGUAGE MODEL FINE-TUNING FOR SOLVING MATH PROBLEMS : Paper\n",
    "<https://arxiv.org/pdf/2310.10047>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "53c59cef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:32.162566Z",
     "iopub.status.busy": "2024-06-20T11:43:32.162187Z",
     "iopub.status.idle": "2024-06-20T11:43:48.428998Z",
     "shell.execute_reply": "2024-06-20T11:43:48.427831Z"
    },
    "papermill": {
     "duration": 16.363771,
     "end_time": "2024-06-20T11:43:48.431488",
     "exception": false,
     "start_time": "2024-06-20T11:43:32.067717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240620_114332-j93htt5y\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfearless-planet-3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/johnsonhk88/ai-math-solving-lora-fine-tuning\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/johnsonhk88/ai-math-solving-lora-fine-tuning/runs/j93htt5y\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if USE_WANDB and USE_TRAIN:\n",
    "     # Start a new wandb run\n",
    "    wandbFineTuningProject = \"ai-math-solving-lora-fine-tuning\"\n",
    "    runTask3 = wandb.init(project=wandbFineTuningProject, job_type=\"generation\", anonymous=\"allow\")\n",
    "    # define W&B Table\n",
    "    wandbCol3 =  [\"model\", \"question\", \"label_answer\", \"llm_generate\", \"llm_answer\"]\n",
    "    wandbFineTuneTable =wandb.Table(columns=wandbCol3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a5044334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:48.629281Z",
     "iopub.status.busy": "2024-06-20T11:43:48.628513Z",
     "iopub.status.idle": "2024-06-20T11:43:48.633867Z",
     "shell.execute_reply": "2024-06-20T11:43:48.632902Z"
    },
    "papermill": {
     "duration": 0.103615,
     "end_time": "2024-06-20T11:43:48.635939",
     "exception": false,
     "start_time": "2024-06-20T11:43:48.532324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_TRAIN:\n",
    "    # LoRA configure  LoraConfig\n",
    "    lora_config = LoraConfig(\n",
    "        r = 8, # rank =8\n",
    "        lora_alpha=16,\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules = [\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    #     lora_dropout=0.1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6e2eaf9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:48.831049Z",
     "iopub.status.busy": "2024-06-20T11:43:48.830395Z",
     "iopub.status.idle": "2024-06-20T11:43:49.187414Z",
     "shell.execute_reply": "2024-06-20T11:43:49.186349Z"
    },
    "papermill": {
     "duration": 0.456654,
     "end_time": "2024-06-20T11:43:49.189724",
     "exception": false,
     "start_time": "2024-06-20T11:43:48.733070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2922"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c479804",
   "metadata": {
    "papermill": {
     "duration": 0.097821,
     "end_time": "2024-06-20T11:43:49.384437",
     "exception": false,
     "start_time": "2024-06-20T11:43:49.286616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Test Training parameter by Open Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9fcd36cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:49.578004Z",
     "iopub.status.busy": "2024-06-20T11:43:49.577317Z",
     "iopub.status.idle": "2024-06-20T11:43:49.582318Z",
     "shell.execute_reply": "2024-06-20T11:43:49.581296Z"
    },
    "papermill": {
     "duration": 0.102101,
     "end_time": "2024-06-20T11:43:49.584224",
     "exception": false,
     "start_time": "2024-06-20T11:43:49.482123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To custom tokenize format for training  open dataset 1\n",
    "def tokenizeFunc1(sample):\n",
    "    return tokenizer(sample[\"quote\"], padding=\"max_length\", truncation=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cd3c66fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:49.777072Z",
     "iopub.status.busy": "2024-06-20T11:43:49.776760Z",
     "iopub.status.idle": "2024-06-20T11:43:49.781150Z",
     "shell.execute_reply": "2024-06-20T11:43:49.780321Z"
    },
    "papermill": {
     "duration": 0.10199,
     "end_time": "2024-06-20T11:43:49.782992",
     "exception": false,
     "start_time": "2024-06-20T11:43:49.681002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To custom tokenize format for training  Math  \n",
    "def tokenizeFunc2(sample):\n",
    "    return tokenizer(sample[\"LLM Content\"],  max_length=512, padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82729df1",
   "metadata": {
    "papermill": {
     "duration": 0.095676,
     "end_time": "2024-06-20T11:43:49.975096",
     "exception": false,
     "start_time": "2024-06-20T11:43:49.879420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### load traning dataset \"Abirate/english_quotes\"\n",
    "<https://huggingface.co/datasets/Abirate/english_quotes>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "96ef7670",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:50.170438Z",
     "iopub.status.busy": "2024-06-20T11:43:50.169529Z",
     "iopub.status.idle": "2024-06-20T11:43:51.740814Z",
     "shell.execute_reply": "2024-06-20T11:43:51.739946Z"
    },
    "papermill": {
     "duration": 1.672349,
     "end_time": "2024-06-20T11:43:51.743044",
     "exception": false,
     "start_time": "2024-06-20T11:43:50.070695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdaa2a9bde1746d2aa5188d42124aa8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/5.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a83f67da1548a9a40a5600aeb489e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/647k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017e2b4bb66a4ac0ab0c128500dbd42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_name = \"Abirate/english_quotes\" # open dataset 1\n",
    "dataEng  = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "32e973ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:51.937903Z",
     "iopub.status.busy": "2024-06-20T11:43:51.937004Z",
     "iopub.status.idle": "2024-06-20T11:43:51.943531Z",
     "shell.execute_reply": "2024-06-20T11:43:51.942588Z"
    },
    "papermill": {
     "duration": 0.103485,
     "end_time": "2024-06-20T11:43:51.945518",
     "exception": false,
     "start_time": "2024-06-20T11:43:51.842033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['quote', 'author', 'tags'],\n",
       "        num_rows: 2508\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataEng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10cad86",
   "metadata": {
    "papermill": {
     "duration": 0.096827,
     "end_time": "2024-06-20T11:43:52.137995",
     "exception": false,
     "start_time": "2024-06-20T11:43:52.041168",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## tokenizer dataEng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1ae56a91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:52.334712Z",
     "iopub.status.busy": "2024-06-20T11:43:52.333846Z",
     "iopub.status.idle": "2024-06-20T11:43:53.008911Z",
     "shell.execute_reply": "2024-06-20T11:43:53.007946Z"
    },
    "papermill": {
     "duration": 0.774018,
     "end_time": "2024-06-20T11:43:53.011184",
     "exception": false,
     "start_time": "2024-06-20T11:43:52.237166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49938e2fcd045f9a165a2f51b4fb802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# dataEngTokenize = dataEng.map(lambda sample : tokenizer(sample[\"quote\"]), batched=True)\n",
    "dataEngTokenize = dataEng.map(tokenizeFunc1, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c128428d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:53.207806Z",
     "iopub.status.busy": "2024-06-20T11:43:53.207421Z",
     "iopub.status.idle": "2024-06-20T11:43:53.213560Z",
     "shell.execute_reply": "2024-06-20T11:43:53.212599Z"
    },
    "papermill": {
     "duration": 0.105617,
     "end_time": "2024-06-20T11:43:53.215386",
     "exception": false,
     "start_time": "2024-06-20T11:43:53.109769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['quote', 'author', 'tags', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2508\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataEngTokenize # tokenize dataset result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f2ae7",
   "metadata": {
    "papermill": {
     "duration": 0.098974,
     "end_time": "2024-06-20T11:43:53.410014",
     "exception": false,
     "start_time": "2024-06-20T11:43:53.311040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0857483",
   "metadata": {
    "papermill": {
     "duration": 0.097757,
     "end_time": "2024-06-20T11:43:53.609272",
     "exception": false,
     "start_time": "2024-06-20T11:43:53.511515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea05a3",
   "metadata": {
    "papermill": {
     "duration": 0.097148,
     "end_time": "2024-06-20T11:43:53.806059",
     "exception": false,
     "start_time": "2024-06-20T11:43:53.708911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001b933c",
   "metadata": {
    "papermill": {
     "duration": 0.095899,
     "end_time": "2024-06-20T11:43:53.996414",
     "exception": false,
     "start_time": "2024-06-20T11:43:53.900515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "561b944b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:54.189851Z",
     "iopub.status.busy": "2024-06-20T11:43:54.188965Z",
     "iopub.status.idle": "2024-06-20T11:43:54.215049Z",
     "shell.execute_reply": "2024-06-20T11:43:54.213979Z"
    },
    "papermill": {
     "duration": 0.12579,
     "end_time": "2024-06-20T11:43:54.217272",
     "exception": false,
     "start_time": "2024-06-20T11:43:54.091482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#generate train set\n",
    "# tempTrainDF = trainQSADF.copy()\n",
    "if USE_TRAIN:\n",
    "    maxTrainData = 1500\n",
    "    tempTrainDF = tempDF[:maxTrainData]\n",
    "    # Convert dataset to hugging face format\n",
    "    dataset = Dataset.from_pandas(tempTrainDF, split=\"train\")\n",
    "#     datasetToken = dataset.map(lambda sample: tokenizer(sample[\"LLM Content\"]),  batched=True)\n",
    "#     print(type(tempTrainDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9dbd759e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:54.411150Z",
     "iopub.status.busy": "2024-06-20T11:43:54.410798Z",
     "iopub.status.idle": "2024-06-20T11:43:54.415392Z",
     "shell.execute_reply": "2024-06-20T11:43:54.414478Z"
    },
    "papermill": {
     "duration": 0.102835,
     "end_time": "2024-06-20T11:43:54.417323",
     "exception": false,
     "start_time": "2024-06-20T11:43:54.314488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset\n",
    "if USE_TRAIN:\n",
    "    dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718d48f8",
   "metadata": {
    "papermill": {
     "duration": 0.100657,
     "end_time": "2024-06-20T11:43:54.613851",
     "exception": false,
     "start_time": "2024-06-20T11:43:54.513194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## How to load two pandas dataframe into hugginface's dataset object?\n",
    "<https://stackoverflow.com/questions/72499850/how-to-load-two-pandas-dataframe-into-hugginfaces-dataset-object>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e6edb7ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:54.809895Z",
     "iopub.status.busy": "2024-06-20T11:43:54.809270Z",
     "iopub.status.idle": "2024-06-20T11:43:54.813657Z",
     "shell.execute_reply": "2024-06-20T11:43:54.812785Z"
    },
    "papermill": {
     "duration": 0.104673,
     "end_time": "2024-06-20T11:43:54.815771",
     "exception": false,
     "start_time": "2024-06-20T11:43:54.711098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert dataset to  Datasetdict \n",
    "if USE_TRAIN:\n",
    "    datasetDict = DatasetDict({\n",
    "        'train': dataset\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "093412f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:55.011697Z",
     "iopub.status.busy": "2024-06-20T11:43:55.011050Z",
     "iopub.status.idle": "2024-06-20T11:43:55.015391Z",
     "shell.execute_reply": "2024-06-20T11:43:55.014459Z"
    },
    "papermill": {
     "duration": 0.104736,
     "end_time": "2024-06-20T11:43:55.017314",
     "exception": false,
     "start_time": "2024-06-20T11:43:54.912578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_TRAIN:\n",
    "    datasetDict  # print datasetDict struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e26c5de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:55.222732Z",
     "iopub.status.busy": "2024-06-20T11:43:55.221993Z",
     "iopub.status.idle": "2024-06-20T11:43:55.226017Z",
     "shell.execute_reply": "2024-06-20T11:43:55.225110Z"
    },
    "papermill": {
     "duration": 0.109601,
     "end_time": "2024-06-20T11:43:55.227982",
     "exception": false,
     "start_time": "2024-06-20T11:43:55.118381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer.max_len_single_sente = 512\n",
    "# tokenizer.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b9d3ee8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:55.423022Z",
     "iopub.status.busy": "2024-06-20T11:43:55.422121Z",
     "iopub.status.idle": "2024-06-20T11:43:56.465576Z",
     "shell.execute_reply": "2024-06-20T11:43:56.464584Z"
    },
    "papermill": {
     "duration": 1.143182,
     "end_time": "2024-06-20T11:43:56.467612",
     "exception": false,
     "start_time": "2024-06-20T11:43:55.324430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a5515191f249ada5d3e73dd2c86070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# datasetDict= datasetDict.map(lambda sample : tokenizer(sample[\"LLM Content\"]), batched=True) #\n",
    "if USE_TRAIN:\n",
    "    datasetDict = datasetDict.map(tokenizeFunc2, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b333a286",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:56.665259Z",
     "iopub.status.busy": "2024-06-20T11:43:56.664425Z",
     "iopub.status.idle": "2024-06-20T11:43:56.668861Z",
     "shell.execute_reply": "2024-06-20T11:43:56.667938Z"
    },
    "papermill": {
     "duration": 0.104795,
     "end_time": "2024-06-20T11:43:56.670729",
     "exception": false,
     "start_time": "2024-06-20T11:43:56.565934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_TRAIN:\n",
    "    datasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "53e9a7b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:56.865869Z",
     "iopub.status.busy": "2024-06-20T11:43:56.865520Z",
     "iopub.status.idle": "2024-06-20T11:43:56.869360Z",
     "shell.execute_reply": "2024-06-20T11:43:56.868583Z"
    },
    "papermill": {
     "duration": 0.10428,
     "end_time": "2024-06-20T11:43:56.871266",
     "exception": false,
     "start_time": "2024-06-20T11:43:56.766986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# datasetDict[\"train\"][\"LLM Content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8c712555",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:57.068402Z",
     "iopub.status.busy": "2024-06-20T11:43:57.067638Z",
     "iopub.status.idle": "2024-06-20T11:43:57.072767Z",
     "shell.execute_reply": "2024-06-20T11:43:57.071622Z"
    },
    "papermill": {
     "duration": 0.105833,
     "end_time": "2024-06-20T11:43:57.074855",
     "exception": false,
     "start_time": "2024-06-20T11:43:56.969022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_OPEN_DATASET1= False#True\n",
    "if USE_TRAIN:\n",
    "    if USE_OPEN_DATASET1:\n",
    "\n",
    "        finalDataset = dataEngTokenize\n",
    "    \n",
    "    else:\n",
    "        finalDataset = datasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a4c17080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:57.274288Z",
     "iopub.status.busy": "2024-06-20T11:43:57.273914Z",
     "iopub.status.idle": "2024-06-20T11:43:57.278199Z",
     "shell.execute_reply": "2024-06-20T11:43:57.277320Z"
    },
    "papermill": {
     "duration": 0.10544,
     "end_time": "2024-06-20T11:43:57.280305",
     "exception": false,
     "start_time": "2024-06-20T11:43:57.174865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_TRAIN:\n",
    "    finalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2326eed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:57.476130Z",
     "iopub.status.busy": "2024-06-20T11:43:57.475376Z",
     "iopub.status.idle": "2024-06-20T11:43:57.481169Z",
     "shell.execute_reply": "2024-06-20T11:43:57.480305Z"
    },
    "papermill": {
     "duration": 0.107325,
     "end_time": "2024-06-20T11:43:57.483135",
     "exception": false,
     "start_time": "2024-06-20T11:43:57.375810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### generate training data format for User open \n",
    "# - \"Quote\" = feature (input)\n",
    "# - \"author\" = label(output)\n",
    "if USE_TRAIN:\n",
    "    def formatFuc1(sample):\n",
    "        text = f\"Quote: {sample['quote'][0]}\\nAuthor: {sample['author'][0]}\"\n",
    "        return [text]\n",
    "    \n",
    "    def formatFuc2(sample):\n",
    "        text = f\"{sample['LLM Content']}\"\n",
    "        retrun [text]\n",
    "\n",
    "    if USE_OPEN_DATASET1:\n",
    "        formatFuc = formatFuc1\n",
    "    else:\n",
    "        formatFuc = formatFuc2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e6dce4",
   "metadata": {
    "papermill": {
     "duration": 0.098229,
     "end_time": "2024-06-20T11:43:57.721789",
     "exception": false,
     "start_time": "2024-06-20T11:43:57.623560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f5221bb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:57.918149Z",
     "iopub.status.busy": "2024-06-20T11:43:57.917822Z",
     "iopub.status.idle": "2024-06-20T11:43:59.372937Z",
     "shell.execute_reply": "2024-06-20T11:43:59.372064Z"
    },
    "papermill": {
     "duration": 1.555246,
     "end_time": "2024-06-20T11:43:59.375015",
     "exception": false,
     "start_time": "2024-06-20T11:43:57.819769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:278: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:397: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "if USE_TRAIN:\n",
    "    # training Argrament\n",
    "    trainArg =  transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=2,\n",
    "        max_steps=100,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=1,\n",
    "        output_dir= '/kaggle/working/lora_model',#\"./results\",#\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        report_to= reportTo # avoid wnb access token request during training\n",
    "\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # SFTTrainer\n",
    "    trainer = SFTTrainer (\n",
    "            model=model,\n",
    "            train_dataset = finalDataset[\"train\"], #dataset ,#tempTrainDF, # training data set\n",
    "#             dataset_text_field = \"LLM Content\",\n",
    "            args = trainArg,\n",
    "#             tokenizer= tokenizer,\n",
    "            peft_config = lora_config,\n",
    "#             packing= False,\n",
    "            formatting_func = formatFuc, #formatFuc1,\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2447d583",
   "metadata": {
    "papermill": {
     "duration": 0.09526,
     "end_time": "2024-06-20T11:43:59.570164",
     "exception": false,
     "start_time": "2024-06-20T11:43:59.474904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Start training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b2062175",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:43:59.764935Z",
     "iopub.status.busy": "2024-06-20T11:43:59.764053Z",
     "iopub.status.idle": "2024-06-20T11:57:42.134246Z",
     "shell.execute_reply": "2024-06-20T11:57:42.133224Z"
    },
    "papermill": {
     "duration": 822.468353,
     "end_time": "2024-06-20T11:57:42.136422",
     "exception": false,
     "start_time": "2024-06-20T11:43:59.668069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 13:33, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.342900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.709600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.218700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.635700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.434800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.727300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.833900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.660500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.094800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.538700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.258600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.360400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.186000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.548200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.383300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.226100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.306500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.985200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.185600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.078900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.907400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.186200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.167500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.087200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.791900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.077900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.919100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.170900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.175700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.048100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.058500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.520400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.188400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.091600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.831600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.112600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.065800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.244200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.988500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.085700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.968500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.929300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.945400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.086400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.061200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.971900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.135400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.062900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.041300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.084000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.273600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.928300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.763700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.843700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.081700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.992900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.919900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.934100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.074700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.119500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.126200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.016200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.979700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.050200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.063400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>1.090700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.229500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.807200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>1.185400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.152600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>1.246400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.730200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.963700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.063100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.873400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.158700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.940800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.888100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.871400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.788800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>1.068500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.951500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.911000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.976700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.107700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.828300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.055800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /kaggle/input/gemma/transformers/7b-it/3 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if USE_TRAIN:\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "291241ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:57:42.334660Z",
     "iopub.status.busy": "2024-06-20T11:57:42.333297Z",
     "iopub.status.idle": "2024-06-20T11:58:07.622574Z",
     "shell.execute_reply": "2024-06-20T11:58:07.621219Z"
    },
    "papermill": {
     "duration": 25.391218,
     "end_time": "2024-06-20T11:58:07.625551",
     "exception": false,
     "start_time": "2024-06-20T11:57:42.234333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "# save adpater model\n",
    "if USE_TRAIN:\n",
    "    model.save_pretrained('/kaggle/working/lora_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d8fcc490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:58:08.778802Z",
     "iopub.status.busy": "2024-06-20T11:58:08.777961Z",
     "iopub.status.idle": "2024-06-20T11:58:35.080082Z",
     "shell.execute_reply": "2024-06-20T11:58:35.078986Z"
    },
    "papermill": {
     "duration": 26.440497,
     "end_time": "2024-06-20T11:58:35.082767",
     "exception": false,
     "start_time": "2024-06-20T11:58:08.642270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "if USE_TRAIN:\n",
    "    def model_to_zip(model_path, archive_name):\n",
    "      \"\"\"\n",
    "      Zips a saved TensorFlow model (including weights)\n",
    "\n",
    "      Args:\n",
    "          model_path: Path to the saved model directory.\n",
    "          archive_name: Name of the output zip archive.\n",
    "      \"\"\"\n",
    "      with zipfile.ZipFile(archive_name, 'w') as zip_file:\n",
    "        for root, _, files in os.walk(model_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                zip_file.write(file_path, os.path.relpath(file_path, model_path))\n",
    "\n",
    "    # Replace with your model path and desired archive name\n",
    "    model_to_zip('/kaggle/working/lora_model','lora.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d6589",
   "metadata": {
    "papermill": {
     "duration": 0.104262,
     "end_time": "2024-06-20T11:58:35.299569",
     "exception": false,
     "start_time": "2024-06-20T11:58:35.195307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test Fine Tuning Response for OPEN Dataset1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6354055c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:58:35.511923Z",
     "iopub.status.busy": "2024-06-20T11:58:35.511460Z",
     "iopub.status.idle": "2024-06-20T11:58:35.516946Z",
     "shell.execute_reply": "2024-06-20T11:58:35.515885Z"
    },
    "papermill": {
     "duration": 0.116159,
     "end_time": "2024-06-20T11:58:35.519214",
     "exception": false,
     "start_time": "2024-06-20T11:58:35.403055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_TRAIN == True and USE_OPEN_DATASET1 == True:\n",
    "    query= \"Quote: A woman is like a tea bag\"\n",
    "    ret = generateResponse(query)\n",
    "    print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "30e400e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:58:35.736113Z",
     "iopub.status.busy": "2024-06-20T11:58:35.735717Z",
     "iopub.status.idle": "2024-06-20T11:58:35.740805Z",
     "shell.execute_reply": "2024-06-20T11:58:35.739884Z"
    },
    "papermill": {
     "duration": 0.116067,
     "end_time": "2024-06-20T11:58:35.742882",
     "exception": false,
     "start_time": "2024-06-20T11:58:35.626815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_TRAIN == True and USE_OPEN_DATASET1 == True:\n",
    "    query = \"Quote: Outside of a dog, a book is man's\"\n",
    "    ret = generateResponse(query)\n",
    "    print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "77933a6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:58:35.959909Z",
     "iopub.status.busy": "2024-06-20T11:58:35.959483Z",
     "iopub.status.idle": "2024-06-20T12:03:49.255347Z",
     "shell.execute_reply": "2024-06-20T12:03:49.254332Z"
    },
    "papermill": {
     "duration": 313.507091,
     "end_time": "2024-06-20T12:03:49.358424",
     "exception": false,
     "start_time": "2024-06-20T11:58:35.851333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qusetion 1 : Let $k, l > 0$ be parameters. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. What is the sum of the squares of the distances from $A$ and $B$ to the origin?\n",
      "Response : \n",
      "you are act as Mathematician, solve the math problem reasonable and logical from given question. \n",
      "The solving the answer and thinking multiple step by step from question : Let $k, l > 0$ be parameters. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. What is the sum of the squares of the distances from $A$ and $B$ to the origin?.\n",
      "Careful to logical reasoning  multiple steps to find the best solution\n",
      "\n",
      "Only Output answer in json format with key \"answer\" and \"explanation\" \n",
      "{\n",
      "\"answer\": 100,\n",
      "\"explanation\": \"The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at the points $A$ and $B$. The distance between $A$ and $B$ is 6, so the distance between $A$ and the origin is 6/2 = 3. The distance between $B$ and the origin is also 3. The sum of squares of these distances is $3^2 + 3^2 = \\boxed{100}$.\"\n",
      "}\n",
      "solution: The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at the points $A$ and $B$. The distance between $A$ and $B$ is 6, so the distance between $A$ and the origin is 6/2 = 3. The distance between $B$ and the origin is also 3. The sum of squares of these distances is $3^2 + 3^2 = \\boxed{100}$.\n",
      "answer: 100\n",
      "explanation: The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at the points $A$ and $B$. The distance between $A$ and $B$ is 6, so the distance between $A$ and the origin is 6/2 = 3. The distance between $B$ and the origin is also 3. The sum of squares of these distances is $3^2 + 3^2 = \\boxed{100}$.\n",
      "----------------------------------------\n",
      "Qusetion 2 : Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?\n",
      "Response : \n",
      "you are act as Mathematician, solve the math problem reasonable and logical from given question. \n",
      "The solving the answer and thinking multiple step by step from question : Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?.\n",
      "Careful to logical reasoning  multiple steps to find the best solution\n",
      "\n",
      "Only Output answer in json format with key \"answer\" and \"explanation\" \n",
      "{\n",
      "\"answer\": 111,\n",
      "\"explanation\": \"Since the sum of any two yellow numbers is a blue number, the maximum number of yellow numbers is 1, since the sum of 1 and 1 is 2, which is a blue number. The only way to do this is to make all the numbers 1. \"\n",
      "}\n",
      "{\n",
      "\"answer\": 111,\n",
      "\"explanation\": \"Since the sum of any two yellow numbers is a blue number, the maximum number of yellow numbers is 1, since the sum of 1 and 1 is 2, which is a blue number. The only way to do this is to make all the numbers 1. \"\n",
      "}\n",
      "{\n",
      "\"answer\": 111,\n",
      "\"explanation\": \"Since the sum of any two yellow numbers is a blue number, the maximum number of yellow numbers is 1, since the sum of 1 and 1 is 2, which is a blue number. The only way to do this is to make all the numbers 1. \"\n",
      "}\n",
      "{\n",
      "\"answer\": 111,\n",
      "\"explanation\": \"Since the sum of any two yellow numbers is a blue number, the maximum number of yellow numbers is 1, since the sum of 1 and 1 is 2, which is a blue number. The only way to do this is to make all the numbers 1. \"\n",
      "}\n",
      "{\n",
      "\"answer\": 111,\n",
      "\"explanation\": \"Since the sum of any two yellow numbers is a blue number, the maximum number of yellow numbers is 1, since the sum of 1 and 1 is 2, which is a blue number. The only way to do this is to make all the numbers 1. \"\n",
      "}\n",
      "{\n",
      "\"answer\": 111,\n",
      "\"explanation\": \"Since the sum of any two yellow numbers is a blue number, the maximum number of yellow numbers is 1, since the sum of 1 and 1 is 2, which is a blue number. The only way to do this is to make all the numbers 1. \"\n",
      "}\n",
      "{\n",
      "\"answer\": 111,\n",
      "\"explanation\": \"Since the sum of any two yellow numbers is a blue number, the maximum number of yellow numbers is 1, since the sum of 1 and 1 is 2, which is a blue number. The only way to do this is to make all the numbers 1. \"\n",
      "}\n",
      "{\n",
      "\"answer\": 111,\n",
      "\"explanation\": \"Since the sum of any two yellow numbers is a blue number, the maximum number of yellow numbers is 1, since the sum of 1 and 1 is 2, which is a blue number. The only way to do this is to make all the numbers 1. \"\n",
      "}\n",
      "{\n",
      "\"answer\": 111,\n",
      "\"explanation\": \"Since the sum of any two yellow numbers is a blue number, the maximum number of yellow numbers is 1, since the sum of 1 and 1 is 2, which is a blue number. The only way to do this is to make all the numbers 1. \"\n",
      "}\n",
      "{\n",
      "\"answer\": 111,\n",
      "\"explanation\": \"Since the sum of any two yellow numbers is a blue number, the maximum number of yellow numbers is 1, since the sum of 1 and 1 is 2, which is a blue number. The only way to do this is to make all the numbers 1. \"\n",
      "}\n",
      "{\n",
      "\"answer\": 111,\n",
      "\"explanation\": \"Since the sum of any two yellow numbers is a blue number, the maximum number of yellow numbers is 1, since the sum of 1 and 1 is 2, which is a blue number. The only way to do this is to make all the numbers 1. \"\n",
      "}\n",
      "}\n",
      "{\n",
      "\"answer\": 111,\n",
      "\"explanation\": \"Since the sum of any two yellow numbers is a blue number, the maximum number of yellow numbers is 1, since the sum of 1 and 1 is 2, which is a blue number. The only way to do this is to make all the numbers 1. \"\n",
      "}\n",
      "{\n",
      "\"answer\": 111,\n",
      "\"explanation\": \"Since the sum of any two yellow numbers is a blue number, the maximum number of yellow numbers is 1, since the sum of 1 and 1 is 2, which is a blue number. The only way to do this is to make all the numbers 1. \"\n",
      "}\n",
      "{\n",
      "\"answer\": 111,\n",
      "\"explanation\": \"Since the sum of any two yellow numbers is a blue number, the maximum number of yellow numbers\n",
      "----------------------------------------\n",
      "Qusetion 3 : Let the `sparkle' operation on positive integer $n$ consist of calculating the sum of the digits of $n$ and taking its factorial, e.g. the sparkle of 13 is $4! = 24$. A robot starts with a positive integer on a blackboard, then after each second for the rest of eternity, replaces the number on the board with its sparkle. For some `special' numbers, if they're the first number, then eventually every number that appears will be less than 6. How many such special numbers are there with at most 36 digits?\n",
      "Response : \n",
      "you are act as Mathematician, solve the math problem reasonable and logical from given question. \n",
      "The solving the answer and thinking multiple step by step from question : Let the `sparkle' operation on positive integer $n$ consist of calculating the sum of the digits of $n$ and taking its factorial, e.g. the sparkle of 13 is $4! = 24$. A robot starts with a positive integer on a blackboard, then after each second for the rest of eternity, replaces the number on the board with its sparkle. For some `special' numbers, if they're the first number, then eventually every number that appears will be less than 6. How many such special numbers are there with at most 36 digits?.\n",
      "Careful to logical reasoning  multiple steps to find the best solution\n",
      "\n",
      "Only Output answer in json format with key \"answer\" and \"explanation\" \n",
      "{\n",
      "\"answer\": 1,\n",
      "\"explanation\": \"The sparkle operation is to add the sum of the digits of the number and take the factorial of the sum. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than 6, then the number is not a special number. If the sum of the digits is exactly 6, then the number is a special number. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than 6, then the number is not a special number. If the sum of the digits is exactly 6, then the number is a special number. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than 6, then the number is not a special number. If the sum of the digits is exactly 6, then the number is a special number. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than 6, then the number is not a special number. If the sum of the digits is exactly 6, then the number is a special number. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than 6, then the number is not a special number. If the sum of the digits is exactly 6, then the number is a special number. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than 6, then the number is not a special number. If the sum of the digits is exactly 6, then the number is a special number. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than 6, then the number is not a special number. If the sum of the digits is exactly 6, then the number is a special number. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than 6, then the number is not a special number. If the sum of the digits is exactly 6, then the number is a special number. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than 6, then the number is not a special number. If the sum of the digits is exactly 6, then the number is a special number. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than 6, then the number is not a special number. If the sum of the digits is exactly 6, then the number is a special number. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than 6, then the number is not a special number. If the sum of the digits is exactly 6, then the number is a special number. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than 6, then the number is not a special number. If the sum of the digits is exactly 6, then the number is a special number. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than 6, then the number is not a special number. If the sum of the digits is exactly 6, then the number is a special number. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than 6, then the number is not a special number. If the sum of the digits is exactly 6, then the number is a special number. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than 6, then the number is not a special number. If the sum of the digits is exactly 6, then the number is a special number. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than 6, then the number is not a special number. If the sum of the digits is exactly 6, then the number is a special number. If the sum of the digits is less than 6, then the number is a special number. If the sum of the digits is greater than\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if USE_TRAIN == True and USE_OPEN_DATASET1 == False: # test math \n",
    "    newPrompt = PromptTemplate(input_variables=[\"question\"], template=templatePrompt5)\n",
    "    result = []\n",
    "    for i, qa in enumerate(trainDF[\"problem\"][0:3]):\n",
    "        finalPrmpt = newPrompt.format(\n",
    "            question=qa\n",
    "        )\n",
    "        rel = generateResponse(finalPrmpt, maxOutToken=1024)\n",
    "        print(f\"Qusetion {i+1} : {qa}\\nResponse : {rel}\")\n",
    "        print(\"--\"*20)\n",
    "        result.append(rel)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bb798b4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:03:49.556418Z",
     "iopub.status.busy": "2024-06-20T12:03:49.555397Z",
     "iopub.status.idle": "2024-06-20T12:03:49.568896Z",
     "shell.execute_reply": "2024-06-20T12:03:49.567783Z"
    },
    "papermill": {
     "duration": 0.11581,
     "end_time": "2024-06-20T12:03:49.570666",
     "exception": false,
     "start_time": "2024-06-20T12:03:49.454856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find answer location : 1\n",
      "100\n",
      "Question 0 \n",
      "Let $k, l > 0$ be parameters. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. What is the sum of the squares of the distances from $A$ and $B$ to the origin?\n",
      "\n",
      "Result: 100\n",
      "Actual Ans: 52\n",
      "----------------------------------------\n",
      "find answer location : 1\n",
      "111\n",
      "Question 1 \n",
      "Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?\n",
      "\n",
      "Result: 111\n",
      "Actual Ans: 250\n",
      "----------------------------------------\n",
      "find answer location : 1\n",
      "1\n",
      "Question 2 \n",
      "Let the `sparkle' operation on positive integer $n$ consist of calculating the sum of the digits of $n$ and taking its factorial, e.g. the sparkle of 13 is $4! = 24$. A robot starts with a positive integer on a blackboard, then after each second for the rest of eternity, replaces the number on the board with its sparkle. For some `special' numbers, if they're the first number, then eventually every number that appears will be less than 6. How many such special numbers are there with at most 36 digits?\n",
      "\n",
      "Result: 1\n",
      "Actual Ans: 702\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if USE_TRAIN == True and USE_OPEN_DATASET1 == False: # test math \n",
    "    for i, rel in enumerate(result):\n",
    "        jsonTxt= llmJSONParser3(rel) # use llm JSON parser get answer\n",
    "        if jsonTxt:\n",
    "            # print(f\"\"\"Question {i} \\n{trainDF[\"problem\"].iloc[i+4]}\\n\\nResult: {jsonTxt[\"answer\"]}\"\"\") # for llm json parser1\n",
    "            print(f\"\"\"Question {i} \\n{trainDF[\"problem\"].iloc[i]}\\n\\nResult: {jsonTxt}\"\"\")# for llm json Parser3\n",
    "            print(f\"\"\"Actual Ans: {trainDF[\"answer\"].iloc[i]}\"\"\")\n",
    "            if USE_WANDB:\n",
    "                wandbFineTuneTable.add_data( llmModel, \n",
    "                                           trainDF[\"problem\"].iloc[i], \n",
    "                                           trainDF[\"answer\"].iloc[i],\n",
    "                                            rel, # llmm response\n",
    "                                            jsonTxt)\n",
    "        else:\n",
    "#           ans= getAnswer(rel)\n",
    "            ans = getAnswerParser2(rel) # not json format use get anser parser\n",
    "            if ans:\n",
    "                print(f\"\"\"Question {i} \\n{trainDF[\"problem\"].iloc[i]}\\n\\nResult: {ans}\"\"\")\n",
    "                print(f\"\"\"Actual Ans: {trainDF[\"answer\"].iloc[i]}\"\"\")\n",
    "                if USE_WANDB:\n",
    "                    wandbFineTuneTable.add_data( llmModel, \n",
    "                                           trainDF[\"problem\"].iloc[i], \n",
    "                                           trainDF[\"answer\"].iloc[i],\n",
    "                                            rel, # llmm response\n",
    "                                            ans)\n",
    "        print(\"--\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9ac57948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:03:49.767200Z",
     "iopub.status.busy": "2024-06-20T12:03:49.766423Z",
     "iopub.status.idle": "2024-06-20T12:03:56.489941Z",
     "shell.execute_reply": "2024-06-20T12:03:56.488955Z"
    },
    "papermill": {
     "duration": 6.824586,
     "end_time": "2024-06-20T12:03:56.492303",
     "exception": false,
     "start_time": "2024-06-20T12:03:49.667717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train/grad_norm ▃▃ █▇▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/learning_rate ▄████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/loss █▇▆▆▃▂▂▂▂▁▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               total_flos 9555457081344000.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/epoch 0.26667\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train/global_step 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/grad_norm 1.75539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      train/learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/loss 1.0558\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train_loss 1.54085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train_runtime 821.9217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_samples_per_second 0.487\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train_steps_per_second 0.122\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfearless-planet-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/johnsonhk88/ai-math-solving-lora-fine-tuning/runs/j93htt5y\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/johnsonhk88/ai-math-solving-lora-fine-tuning\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240620_114332-j93htt5y/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if USE_TRAIN and USE_WANDB :\n",
    "    wandb.log({\"fine_tuning_generations\": wandbFineTuneTable})\n",
    "    runTask3.finish()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cbbe3ad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:03:56.699310Z",
     "iopub.status.busy": "2024-06-20T12:03:56.698366Z",
     "iopub.status.idle": "2024-06-20T12:03:57.219435Z",
     "shell.execute_reply": "2024-06-20T12:03:57.218559Z"
    },
    "papermill": {
     "duration": 0.623232,
     "end_time": "2024-06-20T12:03:57.221652",
     "exception": false,
     "start_time": "2024-06-20T12:03:56.598420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3448"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4bf60d",
   "metadata": {
    "papermill": {
     "duration": 0.102236,
     "end_time": "2024-06-20T12:03:57.429155",
     "exception": false,
     "start_time": "2024-06-20T12:03:57.326919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predict output for Submit competition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dbcc3631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:03:57.634564Z",
     "iopub.status.busy": "2024-06-20T12:03:57.633776Z",
     "iopub.status.idle": "2024-06-20T12:03:57.681760Z",
     "shell.execute_reply": "2024-06-20T12:03:57.680960Z"
    },
    "papermill": {
     "duration": 0.15212,
     "end_time": "2024-06-20T12:03:57.683763",
     "exception": false,
     "start_time": "2024-06-20T12:03:57.531643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the evaluation API\n",
    "import aimo\n",
    "\n",
    "env = aimo.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e5c474",
   "metadata": {
    "papermill": {
     "duration": 0.098539,
     "end_time": "2024-06-20T12:03:57.880754",
     "exception": false,
     "start_time": "2024-06-20T12:03:57.782215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5e50c4bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:03:58.084630Z",
     "iopub.status.busy": "2024-06-20T12:03:58.084279Z",
     "iopub.status.idle": "2024-06-20T12:04:14.387830Z",
     "shell.execute_reply": "2024-06-20T12:04:14.386654Z"
    },
    "papermill": {
     "duration": 16.407667,
     "end_time": "2024-06-20T12:04:14.390064",
     "exception": false,
     "start_time": "2024-06-20T12:03:57.982397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240620_120358-bf1src2d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexpert-frog-3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/johnsonhk88/ai-math-solving-competition-submit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/johnsonhk88/ai-math-solving-competition-submit/runs/bf1src2d\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if USE_WANDB :\n",
    "     # Start a new wandb run\n",
    "    wandbFineTuningProject = \"ai-math-solving-competition-submit\"\n",
    "    runTask4 = wandb.init(project=wandbFineTuningProject, job_type=\"generation\", anonymous=\"allow\")\n",
    "    # define W&B Table\n",
    "    wandbCol4 =  [\"model\", \"question\", \"llm_generate\", \"llm_answer\"]\n",
    "    wandbSubmitTable =wandb.Table(columns=wandbCol4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7fe84f9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:04:14.638883Z",
     "iopub.status.busy": "2024-06-20T12:04:14.638047Z",
     "iopub.status.idle": "2024-06-20T12:04:14.649385Z",
     "shell.execute_reply": "2024-06-20T12:04:14.648511Z"
    },
    "papermill": {
     "duration": 0.159973,
     "end_time": "2024-06-20T12:04:14.651351",
     "exception": false,
     "start_time": "2024-06-20T12:04:14.491378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>000aaa</td>\n",
       "      <td>What is $1-1$?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>111bbb</td>\n",
       "      <td>What is $0\\times10$?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>222ccc</td>\n",
       "      <td>Solve $4+x=4$ for $x$.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id      id                 problem\n",
       "0       0  000aaa          What is $1-1$?\n",
       "1       1  111bbb    What is $0\\times10$?\n",
       "2       2  222ccc  Solve $4+x=4$ for $x$."
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d38687",
   "metadata": {
    "papermill": {
     "duration": 0.097573,
     "end_time": "2024-06-20T12:04:14.847174",
     "exception": false,
     "start_time": "2024-06-20T12:04:14.749601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3ec4b67a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:04:15.060004Z",
     "iopub.status.busy": "2024-06-20T12:04:15.059628Z",
     "iopub.status.idle": "2024-06-20T12:04:15.079457Z",
     "shell.execute_reply": "2024-06-20T12:04:15.078594Z"
    },
    "papermill": {
     "duration": 0.130186,
     "end_time": "2024-06-20T12:04:15.081271",
     "exception": false,
     "start_time": "2024-06-20T12:04:14.951085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define infer \n",
    "from tqdm import tqdm\n",
    "def inferDF(df):\n",
    "    \"\"\"\n",
    "    Inference input DataFrame , iter each row automate \n",
    "    \"\"\"\n",
    "    result= [] \n",
    "    for i, row in tqdm(df.iterrows()): \n",
    "        print(i)\n",
    "#         print(row)\n",
    "        if USE_TRAIN:\n",
    "            newPrompt = PromptTemplate(input_variables=[\"question\"], template=templatePrompt5)\n",
    "            finalPrmpt = newPrompt.format(\n",
    "            question=row[\"problem\"]\n",
    "            )\n",
    "            rel = generateResponse(finalPrmpt, maxOutToken=2048)\n",
    "            jsonTxt= llmJSONParser3(rel) # use llm JSON parser get answer\n",
    "            if jsonTxt:\n",
    "                result.append([row.id, jsonTxt])\n",
    "                if USE_WANDB:\n",
    "                    wandbSubmitTable.add_data( llmModel, \n",
    "                                           row[\"problem\"],\n",
    "                                            rel, # llmm response\n",
    "                                            jsonTxt)\n",
    "            else:\n",
    "                ans = getAnswerParser2(rel) # not json format use get anser parser\n",
    "                if ans:\n",
    "                    result.append([row.id, ans]) \n",
    "                    if USE_WANDB:\n",
    "                        wandbSubmitTable.add_data( llmModel, \n",
    "                                            row[\"problem\"],\n",
    "                                            rel, # llmm response\n",
    "                                            ans)\n",
    "        elif USE_RAG:\n",
    "            newPrompt = PromptTemplate(input_variables=[\"question\", \"context\"], template=templatePrompt7)\n",
    "            ragContext = \"\" # for reg context input to prompt \n",
    "            resultRAG = retriever.invoke(row[\"problem\"])\n",
    "            #     ragContext = resultRAG[0].page_content\n",
    "            for i, ret in enumerate(resultRAG):\n",
    "#                 print(f\"Rank {i+1}:\")\n",
    "#                 print(ret.page_content)\n",
    "                ragContext += ret.page_content +\"\\n\"\n",
    "            finalPrmpt = newPrompt.format(\n",
    "                question=row[\"problem\"],\n",
    "                context=ragContext\n",
    "            )\n",
    "            rel = generateResponse(finalPrmpt, maxOutToken=2048)\n",
    "            jsonTxt= llmJSONParser3(rel) # use llm JSON parser get answer\n",
    "            if jsonTxt:\n",
    "                result.append([row.id, jsonTxt])\n",
    "                if USE_WANDB:\n",
    "                    wandbSubmitTable.add_data( llmModel, \n",
    "                                           row[\"problem\"],\n",
    "                                            rel, # llmm response\n",
    "                                            jsonTxt)\n",
    "            else:\n",
    "                ans = getAnswerParser2(rel) # not json format use get anser parser\n",
    "                if ans:\n",
    "                    result.append([row.id, ans]) \n",
    "                    if USE_WANDB:\n",
    "                        wandbSubmitTable.add_data( llmModel, \n",
    "                                            row[\"problem\"],\n",
    "                                            rel, # llmm response\n",
    "                                            ans)\n",
    "            \n",
    "        \n",
    "        elif FEW_SHOT_TEST:\n",
    "            rel = generateReponseInst(fewTrainSample, row[\"problem\"], maxOutToken=2048)\n",
    "            jsonTxt= llmJSONParser3(rel) # use llm JSON parser get answer\n",
    "            if jsonTxt:\n",
    "                result.append([row.id, jsonTxt])\n",
    "                if USE_WANDB:\n",
    "                    wandbSubmitTable.add_data( llmModel, \n",
    "                                           row[\"problem\"],\n",
    "                                            rel, # llmm response\n",
    "                                            jsonTxt)\n",
    "            else:\n",
    "                ans = getAnswerParser2(rel) # not json format use get anser parser\n",
    "                if ans:\n",
    "                    result.append([row.id, ans]) \n",
    "                    if USE_WANDB:\n",
    "                        wandbSubmitTable.add_data( llmModel, \n",
    "                                            row[\"problem\"],\n",
    "                                            rel, # llmm response\n",
    "                                            ans)\n",
    "        \n",
    "        else:\n",
    "            # default few shot leanring\n",
    "            rel = generateReponseInst(fewTrainSample, row[\"problem\"], maxOutToken=2048)\n",
    "            jsonTxt= llmJSONParser3(rel) # use llm JSON parser get answer\n",
    "            if jsonTxt:\n",
    "                result.append([row.id, jsonTxt])\n",
    "                if USE_WANDB:\n",
    "                    wandbSubmitTable.add_data( llmModel, \n",
    "                                           row[\"problem\"],\n",
    "                                            rel, # llmm response\n",
    "                                            jsonTxt)\n",
    "            else:\n",
    "                ans = getAnswerParser2(rel) # not json format use get anser parser\n",
    "                if ans:\n",
    "                    result.append([row.id, ans]) \n",
    "                    if USE_WANDB:\n",
    "                        wandbSubmitTable.add_data( llmModel, \n",
    "                                            row[\"problem\"],\n",
    "                                            rel, # llmm response\n",
    "                                            ans)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "56b158be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:04:15.284246Z",
     "iopub.status.busy": "2024-06-20T12:04:15.283908Z",
     "iopub.status.idle": "2024-06-20T12:04:51.170423Z",
     "shell.execute_reply": "2024-06-20T12:04:51.169489Z"
    },
    "papermill": {
     "duration": 36.105187,
     "end_time": "2024-06-20T12:04:51.286558",
     "exception": false,
     "start_time": "2024-06-20T12:04:15.181371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:08,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find answer location : 3\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:21, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find answer location : 1\n",
      "0\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:35, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find answer location : 1\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictResult = inferDF(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4a94aafa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:04:51.505443Z",
     "iopub.status.busy": "2024-06-20T12:04:51.505094Z",
     "iopub.status.idle": "2024-06-20T12:04:51.511430Z",
     "shell.execute_reply": "2024-06-20T12:04:51.510244Z"
    },
    "papermill": {
     "duration": 0.111932,
     "end_time": "2024-06-20T12:04:51.513348",
     "exception": false,
     "start_time": "2024-06-20T12:04:51.401416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['000aaa', '0'], ['111bbb', '0'], ['222ccc', '0']]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f63dbb5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:04:51.721628Z",
     "iopub.status.busy": "2024-06-20T12:04:51.721267Z",
     "iopub.status.idle": "2024-06-20T12:04:51.736056Z",
     "shell.execute_reply": "2024-06-20T12:04:51.734985Z"
    },
    "papermill": {
     "duration": 0.122356,
     "end_time": "2024-06-20T12:04:51.738170",
     "exception": false,
     "start_time": "2024-06-20T12:04:51.615814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000aaa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111bbb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222ccc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id answer\n",
       "0  000aaa      0\n",
       "1  111bbb      0\n",
       "2  222ccc      0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe \n",
    "finalDF =  pd.DataFrame(predictResult, columns=[\"id\", \"answer\"])\n",
    "# finalDF.to_csv(\"submission.csv\",index=False,header=True)\n",
    "finalDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "902f59bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:04:51.946380Z",
     "iopub.status.busy": "2024-06-20T12:04:51.946051Z",
     "iopub.status.idle": "2024-06-20T12:09:46.737781Z",
     "shell.execute_reply": "2024-06-20T12:09:46.736758Z"
    },
    "papermill": {
     "duration": 294.899266,
     "end_time": "2024-06-20T12:09:46.739841",
     "exception": false,
     "start_time": "2024-06-20T12:04:51.840575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:16, 16.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find answer location : 3\n",
      "?\n",
      "Start loc: 340\n",
      "?\n",
      "       id         problem\n",
      "0  000aaa  What is $1-1$?\n",
      "       id       answer\n",
      "0  000aaa  [000aaa, ?] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [04:23, 263.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find answer location : 1\n",
      "0\n",
      "       id               problem\n",
      "0  111bbb  What is $0\\times10$?\n",
      "       id       answer\n",
      "0  111bbb  [111bbb, 0] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:14, 14.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find answer location : 1\n",
      "0\n",
      "       id                 problem\n",
      "0  222ccc  Solve $4+x=4$ for $x$.\n",
      "       id       answer\n",
      "0  222ccc  [222ccc, 0] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the test set and use the model make predictions\n",
    "for test, sample_submission in iter_test:\n",
    "    sample_submission['answer'] = inferDF(test)#model.predict(test)\n",
    "    env.predict(sample_submission)\n",
    "    print(test)\n",
    "    print(sample_submission, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f5b3f023",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:09:46.947257Z",
     "iopub.status.busy": "2024-06-20T12:09:46.946943Z",
     "iopub.status.idle": "2024-06-20T12:09:46.954299Z",
     "shell.execute_reply": "2024-06-20T12:09:46.953403Z"
    },
    "papermill": {
     "duration": 0.112739,
     "end_time": "2024-06-20T12:09:46.956423",
     "exception": false,
     "start_time": "2024-06-20T12:09:46.843684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [222ccc, 0]\n",
       "Name: answer, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " sample_submission['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4f027f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:09:47.162782Z",
     "iopub.status.busy": "2024-06-20T12:09:47.162431Z",
     "iopub.status.idle": "2024-06-20T12:09:52.064335Z",
     "shell.execute_reply": "2024-06-20T12:09:52.063689Z"
    },
    "papermill": {
     "duration": 5.008046,
     "end_time": "2024-06-20T12:09:52.066634",
     "exception": false,
     "start_time": "2024-06-20T12:09:47.058588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mexpert-frog-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/johnsonhk88/ai-math-solving-competition-submit/runs/bf1src2d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/johnsonhk88/ai-math-solving-competition-submit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240620_120358-bf1src2d/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if USE_WANDB :\n",
    "    wandb.log({\"submit_competition_generations\": wandbSubmitTable})\n",
    "    runTask4.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d10437",
   "metadata": {
    "papermill": {
     "duration": 0.106181,
     "end_time": "2024-06-20T12:09:52.278874",
     "exception": false,
     "start_time": "2024-06-20T12:09:52.172693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20a76d",
   "metadata": {
    "papermill": {
     "duration": 0.103279,
     "end_time": "2024-06-20T12:09:52.489980",
     "exception": false,
     "start_time": "2024-06-20T12:09:52.386701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a8250",
   "metadata": {
    "papermill": {
     "duration": 0.10697,
     "end_time": "2024-06-20T12:09:52.700820",
     "exception": false,
     "start_time": "2024-06-20T12:09:52.593850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8365361,
     "sourceId": 73231,
     "sourceType": "competition"
    },
    {
     "datasetId": 4717118,
     "sourceId": 8008788,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4717827,
     "sourceId": 8009768,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5054889,
     "sourceId": 8476517,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5057396,
     "sourceId": 8479491,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 8318,
     "sourceId": 28785,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 8332,
     "sourceId": 28808,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2321.896673,
   "end_time": "2024-06-20T12:09:55.841133",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-20T11:31:13.944460",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "017e2b4bb66a4ac0ab0c128500dbd42d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_eef48bc106ad4ccead20d5d9111fafcd",
        "IPY_MODEL_c3b7af467af84cff99925172158ff07b",
        "IPY_MODEL_88fd91123e094d09b63d314d59069292"
       ],
       "layout": "IPY_MODEL_b7c1124e1f8c4db2874ce41dab3ee4f5"
      }
     },
     "0189edca8da549fe82c9590e57e668c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "01d13a7281d14705b673e51a56781025": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "029db36ec8db436eb31cad703d3801eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "048d1cfe161e438f87b83b317b201017": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_116f61e9a9f646078672c0c961ab9b32",
       "max": 711396.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0854144440694490a14034bf63889601",
       "value": 711396.0
      }
     },
     "062dae1f53524ff381473550b221d9c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ef453c0e28e24c2786084918952b430a",
       "max": 124.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5defab559ff5432cb3ce1f5639a7cf51",
       "value": 124.0
      }
     },
     "073b333c338a4fa8affd3984ee26041c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "07b1d0941a2a4a2ebaad0a05a1f7d5cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d6db8e90b4c541399e4efb50837c165c",
       "placeholder": "​",
       "style": "IPY_MODEL_813f93915e7b4fa79b20a7cbf3ef5e47",
       "value": "Computing checksums: 100%"
      }
     },
     "0802d3d4650c4f7584fa90e60694cb9f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0854144440694490a14034bf63889601": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0899ef39b5d9430698dac958c9211582": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_758ebbd906044b2285c1f700d291365b",
        "IPY_MODEL_c71fa82e300d485891e8227a92d9ecb2",
        "IPY_MODEL_0935d8866caa4a9ba535f4943a07bc55"
       ],
       "layout": "IPY_MODEL_56fdca9a8ae64d14a38c7b12feb64631"
      }
     },
     "0935d8866caa4a9ba535f4943a07bc55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cd223be05bfa4496901457a3f7cf6575",
       "placeholder": "​",
       "style": "IPY_MODEL_a5b75e8382ec49178d141896345e51aa",
       "value": " 232k/232k [00:00&lt;00:00, 4.92MB/s]"
      }
     },
     "097b0398789a470ea9b81416f7154f95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0ae9114f38d84ee1a0364ac521c0edce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "115a96597536472b8a3d4a08c331102b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "116f61e9a9f646078672c0c961ab9b32": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "117fb054d61e496ea50bfbcb14a401c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a651fdc09e7d4e269e0cddf24f47942f",
       "placeholder": "​",
       "style": "IPY_MODEL_b0344e01a8dc420983e29e9465fa524e",
       "value": "config.json: 100%"
      }
     },
     "11e1a9235fac4573b5e8bb8474734276": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_678dca113ac044babaaf82757470aac2",
       "placeholder": "​",
       "style": "IPY_MODEL_909b3e6852c94d1bb29eb077ee46e295",
       "value": " 1500/1500 [00:00&lt;00:00, 2513.30 examples/s]"
      }
     },
     "129cb1babd2f44e4898e329dbae3f889": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5504ff1beee74fb9ae1ad41bb15cd8c5",
       "max": 2508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6003e391b59b4258b9f79d74167fa5da",
       "value": 2508.0
      }
     },
     "12d509f5056c49d8abff5b20e026b14c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_193f91811088469fa6f3ee45bce3c4a3",
        "IPY_MODEL_f810b33055914323ae146244a6de9464",
        "IPY_MODEL_abb158df7dd7451188c00edd634cfce6"
       ],
       "layout": "IPY_MODEL_2c6424348ce44cad85d3a1aadf1b84d3"
      }
     },
     "14a368dc0f8244aebc94439e27daded2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "151f91670bc04e6f937381737143aa9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15d7fd41f1004892a9f1e8f0c7f0b271": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "161035aaeb1f47aead0df593108e8db3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0802d3d4650c4f7584fa90e60694cb9f",
       "max": 646739.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1ad6efbf681d4c5db70372264c94efce",
       "value": 646739.0
      }
     },
     "178451be1b0c46c88d3ff0a5d3db0e54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_07b1d0941a2a4a2ebaad0a05a1f7d5cb",
        "IPY_MODEL_fbdaf6a3c138497092236856dfd10854",
        "IPY_MODEL_8cee3f24eee34706b12b9a8383f34122"
       ],
       "layout": "IPY_MODEL_db3c2355641d44c4b937a11e2c15c244"
      }
     },
     "193f91811088469fa6f3ee45bce3c4a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6df6d249949c42bba8302f25cde443bf",
       "placeholder": "​",
       "style": "IPY_MODEL_a10a1c4c9047492a85ca95987cd03341",
       "value": "special_tokens_map.json: 100%"
      }
     },
     "1ad6efbf681d4c5db70372264c94efce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1bfa73eca42e4966bdb2b5690943c7a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8d351d4aa2794bbea122c0d233292322",
       "placeholder": "​",
       "style": "IPY_MODEL_eff6f440693a4121961f4eb757fa544f",
       "value": "tokenizer.json: 100%"
      }
     },
     "1c308b31f5924572b5e7f478eaf4bfdc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1c55761533aa4133a32f6b1e563024e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1cda2a0c84fe4b248169b817151d1766": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1ce024a307d0450cbb1b37866c7b2ac8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1d000e46423e436e9ab88aa330932483": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "23a2e3b0ba924d51a848a8ada5679a40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "25eb19f21d2c430f97879a1d8dc61fff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2650f099409245219f618d2f8b3861f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2c6424348ce44cad85d3a1aadf1b84d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c89187a091a4149b37c81e2e75cee03": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ce56917b5324bceb0c2145784c741c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2df8a11592424a368d537a4db05483d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2ee1cff632d84296ac135ea38eaf3468": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0ae9114f38d84ee1a0364ac521c0edce",
       "max": 349.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fea50d5f4b654c32b632f3cc541dabdb",
       "value": 349.0
      }
     },
     "2f7967aa913447b589d8ffc375863356": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_01d13a7281d14705b673e51a56781025",
       "placeholder": "​",
       "style": "IPY_MODEL_1d000e46423e436e9ab88aa330932483",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "33fbe06e1f6b47bbb5313be89c97d1ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "34ffba8fde6f4cf7bbdd241b1787a23b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "397c27f3360241bb8bb69ffe6030a8ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b873e3f0a9f0432985bb5d52cd6162d3",
       "max": 94551.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5dad3e970b4047dbaf84f6955444db65",
       "value": 94551.0
      }
     },
     "3b2aaaf2840847ddbe02c322aa1a346d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3b3817f13f3e4937989d64b59fc1b41a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3b9fd9a1b667414d97b57b22f6225889": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c7df46f1faa4574bb7475b111227268": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3e491a3da3ac41859871bcdaf4167646",
       "placeholder": "​",
       "style": "IPY_MODEL_9e36b1351afc4fbc841c1fb33f964310",
       "value": " 366/366 [00:00&lt;00:00, 25.1kB/s]"
      }
     },
     "3dd515c280a14daa9b2aa78fc4ff06ec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3e491a3da3ac41859871bcdaf4167646": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3e6c45c1008847ee9081a6f8b8cbcad7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_33fbe06e1f6b47bbb5313be89c97d1ff",
       "max": 52.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2df8a11592424a368d537a4db05483d4",
       "value": 52.0
      }
     },
     "436bd61a13a6465daecbe58ef8c6d194": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "458ec8dbba8b4b3f8a846a52167c0470": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "459cb160bb4543b6b04d966398110a10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "45a5515191f249ada5d3e73dd2c86070": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d91d54a678204f0fba06b81f56334983",
        "IPY_MODEL_9194037ae1b440fda017a057ef4cf5a2",
        "IPY_MODEL_11e1a9235fac4573b5e8bb8474734276"
       ],
       "layout": "IPY_MODEL_70034040c4704348a6e580174975cce4"
      }
     },
     "4953e11a38d6425db24bafba2a8b683c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49c804e728cf41cfa9c33ed03f06f6a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_151f91670bc04e6f937381737143aa9b",
       "placeholder": "​",
       "style": "IPY_MODEL_5f399158e83c4baeaebce7b43ebe9575",
       "value": " 94.6k/94.6k [00:00&lt;00:00, 3.18MB/s]"
      }
     },
     "4d7e4bcf311d451a90aab177a3ef2fce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3dd515c280a14daa9b2aa78fc4ff06ec",
       "placeholder": "​",
       "style": "IPY_MODEL_d04abe29489f459cb033769509a7a3e5",
       "value": " 711k/711k [00:00&lt;00:00, 25.1MB/s]"
      }
     },
     "5293eb65d8ff49118cf595bc1a7fecbe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "52a83f67da1548a9a40a5600aeb489e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_62cebbb7149c4944b5c06b4c1cd770b7",
        "IPY_MODEL_161035aaeb1f47aead0df593108e8db3",
        "IPY_MODEL_b9fee520c3594da0a968e87c3d833ddb"
       ],
       "layout": "IPY_MODEL_458ec8dbba8b4b3f8a846a52167c0470"
      }
     },
     "5504ff1beee74fb9ae1ad41bb15cd8c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "556164c8c0d943e89a1178b94716dbe2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a783a375b6e44b3b94b15d364d004930",
        "IPY_MODEL_2ee1cff632d84296ac135ea38eaf3468",
        "IPY_MODEL_fad4a54b9e9a4764b7c5129f1ac3ee67"
       ],
       "layout": "IPY_MODEL_073b333c338a4fa8affd3984ee26041c"
      }
     },
     "565691cf85db4b99861ebb4f83aa97e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "56fdca9a8ae64d14a38c7b12feb64631": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5921a32edeb0408b85e20b1eb89009cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "59d96c01399a4d6cb0c62cfe50c9d42a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5cce72bbb372491bab89cc0c33f70065": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fbd6d9706cf941baaeb61dd5e91e425b",
       "placeholder": "​",
       "style": "IPY_MODEL_955d6b7953464423808a154b834dd7c3",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "5dad3e970b4047dbaf84f6955444db65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5defab559ff5432cb3ce1f5639a7cf51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5f21e729eed6499190b194ac1ce26616": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f8686be209d9429086444f6aed34d780",
       "max": 190.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_842540330b9545a29ece02aebc2ee907",
       "value": 190.0
      }
     },
     "5f399158e83c4baeaebce7b43ebe9575": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6003e391b59b4258b9f79d74167fa5da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6072a9d0107942f7ad769f7846c8afbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "62cebbb7149c4944b5c06b4c1cd770b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3b3817f13f3e4937989d64b59fc1b41a",
       "placeholder": "​",
       "style": "IPY_MODEL_e435669d24534a1c9b76a9513ffa65f6",
       "value": "Downloading data: 100%"
      }
     },
     "634e89b4705541e5a75d26a23c2f8e7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c33916ecd4294913be13e4cc4eb9d03c",
       "placeholder": "​",
       "style": "IPY_MODEL_9384fb6543e0445a9bc9aab53ebc8cd3",
       "value": " 52.0/52.0 [00:00&lt;00:00, 4.67kB/s]"
      }
     },
     "666ccd46ae824d0d82326c11b236d49f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_117fb054d61e496ea50bfbcb14a401c2",
        "IPY_MODEL_fc5f3d2ba2fe496895a585c61a860b1b",
        "IPY_MODEL_91868e56046d4dcfb3f0444b7a51c56d"
       ],
       "layout": "IPY_MODEL_820a4a2021a34a22bb0b03f9fef9046c"
      }
     },
     "678dca113ac044babaaf82757470aac2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6c593182a4f44b4db870925fd950ec95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6df6d249949c42bba8302f25cde443bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e9db73416d04b4ca3fd0427fd2dc9ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6ee989fe959f440797faed467a27a39b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c1421797d2894b2c9fec5ae37f3f29d3",
        "IPY_MODEL_ea28cb6e47bf42568c15fe987b7ba62e",
        "IPY_MODEL_e900516626d943c98acb634e5c3e1ddd"
       ],
       "layout": "IPY_MODEL_1c55761533aa4133a32f6b1e563024e9"
      }
     },
     "6f77dd87da5b4b3981d09b05053fdf62": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "70034040c4704348a6e580174975cce4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "736edfac2b4d40d4bcc4918d44c26b84": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "73fdfaa1323f4bfca4bc5ac4a26d7198": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "758ebbd906044b2285c1f700d291365b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c88450fff96f4ad78dab81f78f474462",
       "placeholder": "​",
       "style": "IPY_MODEL_ad10d40a718d4389ae2c8999126f956d",
       "value": "vocab.txt: 100%"
      }
     },
     "75dec569dc2c438fa403c62b1659203b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "767942f961034492bf4955fb008a420c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7cfd83a977314eb5bbebceba61baa012": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7e7de33dfe04420f8bbf2a8c0437081b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7e81be2bd7e746928ee43678b8e35a3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7f114b0ab6b04999a50789b7635d1d82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f3cee676ccc49169b9a89199761024c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f6560dd66394fcc9181f7e700d9047c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f8ffbd4aea14a5ab43ee74b1c7d93a0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "813f93915e7b4fa79b20a7cbf3ef5e47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "820a4a2021a34a22bb0b03f9fef9046c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "842540330b9545a29ece02aebc2ee907": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "85ff8d89e63e4e22902d9dc559a5a808": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "863f55e78d9b49f1b49920cfed2513f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dc24a88c1fbb46f3815e5185b37d6a04",
       "placeholder": "​",
       "style": "IPY_MODEL_a96029839c8343e6af22c33179e7a08b",
       "value": " 190/190 [00:00&lt;00:00, 16.2kB/s]"
      }
     },
     "88fd91123e094d09b63d314d59069292": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9e4e8666b6a949de8a0801277143e531",
       "placeholder": "​",
       "style": "IPY_MODEL_c89c240926514b0dae53c693129fcb97",
       "value": " 2508/2508 [00:00&lt;00:00, 94293.73 examples/s]"
      }
     },
     "8cee3f24eee34706b12b9a8383f34122": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_73fdfaa1323f4bfca4bc5ac4a26d7198",
       "placeholder": "​",
       "style": "IPY_MODEL_c867a3d6322b4e4f8e27312fd48f3863",
       "value": " 1/1 [00:00&lt;00:00, 126.49it/s]"
      }
     },
     "8d351d4aa2794bbea122c0d233292322": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "909b3e6852c94d1bb29eb077ee46e295": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "90abc7fb420e4e0ab38e6b2fe24c030f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_34ffba8fde6f4cf7bbdd241b1787a23b",
       "placeholder": "​",
       "style": "IPY_MODEL_5293eb65d8ff49118cf595bc1a7fecbe",
       "value": "README.md: 100%"
      }
     },
     "90f117cae82e49619acd021cbe952bd9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "91868e56046d4dcfb3f0444b7a51c56d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_14a368dc0f8244aebc94439e27daded2",
       "placeholder": "​",
       "style": "IPY_MODEL_5921a32edeb0408b85e20b1eb89009cd",
       "value": " 777/777 [00:00&lt;00:00, 52.4kB/s]"
      }
     },
     "9194037ae1b440fda017a057ef4cf5a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6f77dd87da5b4b3981d09b05053fdf62",
       "max": 1500.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9ebfff127953418ebd01915b20a8af21",
       "value": 1500.0
      }
     },
     "9384fb6543e0445a9bc9aab53ebc8cd3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "955d6b7953464423808a154b834dd7c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9b576373fb2747718add42f8e104c139": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9cf1b4559c404cbd95a060afa03e14f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_90abc7fb420e4e0ab38e6b2fe24c030f",
        "IPY_MODEL_397c27f3360241bb8bb69ffe6030a8ef",
        "IPY_MODEL_49c804e728cf41cfa9c33ed03f06f6a9"
       ],
       "layout": "IPY_MODEL_3b9fd9a1b667414d97b57b22f6225889"
      }
     },
     "9e36b1351afc4fbc841c1fb33f964310": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9e4e8666b6a949de8a0801277143e531": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ebfff127953418ebd01915b20a8af21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a10a1c4c9047492a85ca95987cd03341": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a247a1bc123d4c1ab59ad5a8146759d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a25eadcc46a741a49c98a9fa322f7b87": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a31d1cc6b00249b192ac191e87c4cd51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_097b0398789a470ea9b81416f7154f95",
       "placeholder": "​",
       "style": "IPY_MODEL_0189edca8da549fe82c9590e57e668c8",
       "value": " 2508/2508 [00:00&lt;00:00, 11877.79 examples/s]"
      }
     },
     "a32fbeae81584ef6a6974c734abbcd41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2f7967aa913447b589d8ffc375863356",
        "IPY_MODEL_e7b1b791af47482883a8a233c19db3dd",
        "IPY_MODEL_d5ad3931194249239190c7fb64cfdf97"
       ],
       "layout": "IPY_MODEL_15d7fd41f1004892a9f1e8f0c7f0b271"
      }
     },
     "a5b75e8382ec49178d141896345e51aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a651fdc09e7d4e269e0cddf24f47942f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a68f381a845b46809a7eb29452524817": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_115a96597536472b8a3d4a08c331102b",
       "placeholder": "​",
       "style": "IPY_MODEL_1c308b31f5924572b5e7f478eaf4bfdc",
       "value": " 5.55k/5.55k [00:00&lt;00:00, 435kB/s]"
      }
     },
     "a783a375b6e44b3b94b15d364d004930": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6e9db73416d04b4ca3fd0427fd2dc9ef",
       "placeholder": "​",
       "style": "IPY_MODEL_d20f54b7a9d3412186644582b4fb947e",
       "value": "modules.json: 100%"
      }
     },
     "a8793b0d547d4f91b5325c2e39737984": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a96029839c8343e6af22c33179e7a08b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "abb158df7dd7451188c00edd634cfce6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7f114b0ab6b04999a50789b7635d1d82",
       "placeholder": "​",
       "style": "IPY_MODEL_565691cf85db4b99861ebb4f83aa97e2",
       "value": " 125/125 [00:00&lt;00:00, 9.87kB/s]"
      }
     },
     "ad10d40a718d4389ae2c8999126f956d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "aeac173c0e884f49998a8c1ee82e759d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cf42ffd1551d4f0499d3f25eac0cacef",
       "max": 5554.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2650f099409245219f618d2f8b3861f2",
       "value": 5554.0
      }
     },
     "af57c9475234492ba660072530bdeaa0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b0344e01a8dc420983e29e9465fa524e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b0a80371e2f742828c275119aa9f185f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b3bc25650fb54aa08fe0effba8e32eaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1bfa73eca42e4966bdb2b5690943c7a3",
        "IPY_MODEL_048d1cfe161e438f87b83b317b201017",
        "IPY_MODEL_4d7e4bcf311d451a90aab177a3ef2fce"
       ],
       "layout": "IPY_MODEL_c964d5818fa242b39ec7ab4f35e2e9d5"
      }
     },
     "b49938e2fcd045f9a165a2f51b4fb802": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ceecd320cb3b43cbae0a552963031cb1",
        "IPY_MODEL_129cb1babd2f44e4898e329dbae3f889",
        "IPY_MODEL_a31d1cc6b00249b192ac191e87c4cd51"
       ],
       "layout": "IPY_MODEL_6c593182a4f44b4db870925fd950ec95"
      }
     },
     "b7c1124e1f8c4db2874ce41dab3ee4f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b873e3f0a9f0432985bb5d52cd6162d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8a2ba196ab44e6a9c04ff94a91c8db1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_436bd61a13a6465daecbe58ef8c6d194",
       "placeholder": "​",
       "style": "IPY_MODEL_6072a9d0107942f7ad769f7846c8afbf",
       "value": "config_sentence_transformers.json: 100%"
      }
     },
     "b9fee520c3594da0a968e87c3d833ddb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ee67be8f023d4d668c484b8c414bd8a0",
       "placeholder": "​",
       "style": "IPY_MODEL_e5afc69a607a4310a5e063c34c3c0d1c",
       "value": " 647k/647k [00:00&lt;00:00, 6.95MB/s]"
      }
     },
     "bd072a674064462592318a21fd97fbff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7f6560dd66394fcc9181f7e700d9047c",
       "placeholder": "​",
       "style": "IPY_MODEL_2ce56917b5324bceb0c2145784c741c5",
       "value": "sentence_bert_config.json: 100%"
      }
     },
     "bd7f42bd6e7f4bc097894dbfb2a79c66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bd8ad3f62607433ea6865841f02a8629": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_da27ec2312af4210a09393e0d5e91765",
        "IPY_MODEL_5f21e729eed6499190b194ac1ce26616",
        "IPY_MODEL_863f55e78d9b49f1b49920cfed2513f9"
       ],
       "layout": "IPY_MODEL_85ff8d89e63e4e22902d9dc559a5a808"
      }
     },
     "c0eb2b6708034ef3aa53940bafa03fb2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b8a2ba196ab44e6a9c04ff94a91c8db1",
        "IPY_MODEL_062dae1f53524ff381473550b221d9c0",
        "IPY_MODEL_da99071c7e6d486a9c1b7054b35315b7"
       ],
       "layout": "IPY_MODEL_7cfd83a977314eb5bbebceba61baa012"
      }
     },
     "c1421797d2894b2c9fec5ae37f3f29d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7e7de33dfe04420f8bbf2a8c0437081b",
       "placeholder": "​",
       "style": "IPY_MODEL_f2e7fb61b065472e86fb63d0c8c11057",
       "value": "model.safetensors: 100%"
      }
     },
     "c2df244a41cb4dcbada02d091b491e7f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c33916ecd4294913be13e4cc4eb9d03c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c3b7af467af84cff99925172158ff07b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f1e585f56971432699238140068aea7a",
       "max": 2508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f08e49c3e5c248789ad79fef36b39bca",
       "value": 2508.0
      }
     },
     "c71fa82e300d485891e8227a92d9ecb2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7f3cee676ccc49169b9a89199761024c",
       "max": 231508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a247a1bc123d4c1ab59ad5a8146759d6",
       "value": 231508.0
      }
     },
     "c867a3d6322b4e4f8e27312fd48f3863": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c88450fff96f4ad78dab81f78f474462": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c89c240926514b0dae53c693129fcb97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c964d5818fa242b39ec7ab4f35e2e9d5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb8d43930dcd40fdbcd86a1478c3dd29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cd223be05bfa4496901457a3f7cf6575": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cdaa2a9bde1746d2aa5188d42124aa8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_edf498252eb1431e9f646ea254cac945",
        "IPY_MODEL_aeac173c0e884f49998a8c1ee82e759d",
        "IPY_MODEL_a68f381a845b46809a7eb29452524817"
       ],
       "layout": "IPY_MODEL_af57c9475234492ba660072530bdeaa0"
      }
     },
     "ceecd320cb3b43cbae0a552963031cb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_736edfac2b4d40d4bcc4918d44c26b84",
       "placeholder": "​",
       "style": "IPY_MODEL_bd7f42bd6e7f4bc097894dbfb2a79c66",
       "value": "Map: 100%"
      }
     },
     "cf42ffd1551d4f0499d3f25eac0cacef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d04abe29489f459cb033769509a7a3e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d128e9e16d5f4e6b9a38b57454e2d258": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5cce72bbb372491bab89cc0c33f70065",
        "IPY_MODEL_fa9e0ebbd5cb4db29cb3271cd64986ab",
        "IPY_MODEL_3c7df46f1faa4574bb7475b111227268"
       ],
       "layout": "IPY_MODEL_b0a80371e2f742828c275119aa9f185f"
      }
     },
     "d20f54b7a9d3412186644582b4fb947e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d401aa87da5d4caabdf36e49ef27efc5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d5ad3931194249239190c7fb64cfdf97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_75dec569dc2c438fa403c62b1659203b",
       "placeholder": "​",
       "style": "IPY_MODEL_f7b0564b6175454b8c1441ad6cdbd2a1",
       "value": " 4/4 [01:55&lt;00:00, 26.19s/it]"
      }
     },
     "d6db8e90b4c541399e4efb50837c165c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d91d54a678204f0fba06b81f56334983": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_90f117cae82e49619acd021cbe952bd9",
       "placeholder": "​",
       "style": "IPY_MODEL_f0381aa11b59415b9854a9a93696e7c7",
       "value": "Map: 100%"
      }
     },
     "da27ec2312af4210a09393e0d5e91765": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7f8ffbd4aea14a5ab43ee74b1c7d93a0",
       "placeholder": "​",
       "style": "IPY_MODEL_d401aa87da5d4caabdf36e49ef27efc5",
       "value": "1_Pooling/config.json: 100%"
      }
     },
     "da99071c7e6d486a9c1b7054b35315b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_59d96c01399a4d6cb0c62cfe50c9d42a",
       "placeholder": "​",
       "style": "IPY_MODEL_9b576373fb2747718add42f8e104c139",
       "value": " 124/124 [00:00&lt;00:00, 9.57kB/s]"
      }
     },
     "db3c2355641d44c4b937a11e2c15c244": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc24a88c1fbb46f3815e5185b37d6a04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e124278b7ce44c2f9068d44b605a6c37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e435669d24534a1c9b76a9513ffa65f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e5afc69a607a4310a5e063c34c3c0d1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e6308ca023674a5ba1ec6b2513b2fb8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e7322542d50b461195b866c85ad31eff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e7b1b791af47482883a8a233c19db3dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2c89187a091a4149b37c81e2e75cee03",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1ce024a307d0450cbb1b37866c7b2ac8",
       "value": 4.0
      }
     },
     "e7fed60578dc4951bba6c50d8d6765c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e900516626d943c98acb634e5c3e1ddd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c2df244a41cb4dcbada02d091b491e7f",
       "placeholder": "​",
       "style": "IPY_MODEL_23a2e3b0ba924d51a848a8ada5679a40",
       "value": " 438M/438M [00:02&lt;00:00, 211MB/s]"
      }
     },
     "ea28cb6e47bf42568c15fe987b7ba62e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_029db36ec8db436eb31cad703d3801eb",
       "max": 437955512.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_459cb160bb4543b6b04d966398110a10",
       "value": 437955512.0
      }
     },
     "eaf6e1dea68d48238e1916f688b3698a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bd072a674064462592318a21fd97fbff",
        "IPY_MODEL_3e6c45c1008847ee9081a6f8b8cbcad7",
        "IPY_MODEL_634e89b4705541e5a75d26a23c2f8e7a"
       ],
       "layout": "IPY_MODEL_a8793b0d547d4f91b5325c2e39737984"
      }
     },
     "edf498252eb1431e9f646ea254cac945": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e7322542d50b461195b866c85ad31eff",
       "placeholder": "​",
       "style": "IPY_MODEL_1cda2a0c84fe4b248169b817151d1766",
       "value": "Downloading readme: 100%"
      }
     },
     "ee67be8f023d4d668c484b8c414bd8a0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eef48bc106ad4ccead20d5d9111fafcd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a25eadcc46a741a49c98a9fa322f7b87",
       "placeholder": "​",
       "style": "IPY_MODEL_cb8d43930dcd40fdbcd86a1478c3dd29",
       "value": "Generating train split: 100%"
      }
     },
     "ef2e58a58019402a8986f18d8df02b3a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef453c0e28e24c2786084918952b430a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eff6f440693a4121961f4eb757fa544f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f0381aa11b59415b9854a9a93696e7c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f08e49c3e5c248789ad79fef36b39bca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f1e585f56971432699238140068aea7a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f2e7fb61b065472e86fb63d0c8c11057": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f6a25d7dda3549f5bf4f4c47e6ce3957": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f7b0564b6175454b8c1441ad6cdbd2a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f810b33055914323ae146244a6de9464": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_767942f961034492bf4955fb008a420c",
       "max": 125.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3b2aaaf2840847ddbe02c322aa1a346d",
       "value": 125.0
      }
     },
     "f8686be209d9429086444f6aed34d780": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa9e0ebbd5cb4db29cb3271cd64986ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_25eb19f21d2c430f97879a1d8dc61fff",
       "max": 366.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f6a25d7dda3549f5bf4f4c47e6ce3957",
       "value": 366.0
      }
     },
     "fad4a54b9e9a4764b7c5129f1ac3ee67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ef2e58a58019402a8986f18d8df02b3a",
       "placeholder": "​",
       "style": "IPY_MODEL_e7fed60578dc4951bba6c50d8d6765c5",
       "value": " 349/349 [00:00&lt;00:00, 27.0kB/s]"
      }
     },
     "fbd6d9706cf941baaeb61dd5e91e425b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fbdaf6a3c138497092236856dfd10854": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e124278b7ce44c2f9068d44b605a6c37",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e6308ca023674a5ba1ec6b2513b2fb8d",
       "value": 1.0
      }
     },
     "fc5f3d2ba2fe496895a585c61a860b1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4953e11a38d6425db24bafba2a8b683c",
       "max": 777.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7e81be2bd7e746928ee43678b8e35a3a",
       "value": 777.0
      }
     },
     "fea50d5f4b654c32b632f3cc541dabdb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
