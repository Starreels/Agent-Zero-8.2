This car crazy because the agent, even though it ran into error, was able to fix it itself. This is an interview with Jan Tomaszek, the founder of Agent 0, which is a brand new approach to AI agents. Instead of having to define tasks, agents, and do all of this setup, you simply give the agent a prompt, and it does everything for you. You'll see how revolutionary this is. And fun fact, Jan is also the second highest contributor in the side of our AI community, which is where he also developed and released Agent 0. This is the David Andre podcast. Enjoy. Thank you David for the introduction. Maybe I would start by where to find this and try it for yourself. Everything is open source, so just go and have fun. This is the GitHub repository. Now let's jump right into it. 

Everything will be linked below the video. In terms of UI, it is more like a chatbot. I can start by just greeting him to show you the message format. You may have noticed it was quite quick, but the message was streamed, token by token. This is how Agent 0 communicates. He writes a JSON object and he starts with his thoughts. And so this allows the agent to think things thoroughly before he does something before he calls a tool. There are only like five generic tools built into the framework. One of them is this response tool where the agent writes his text and this message is then sent to me as the user. The first impression that anyone should get is that this doesn't require any knowledge of the framework. You don't have to know any syntax or how it was built. You can just start using it right in your terminal. Yeah, maybe I should mention that you don't need to open those Python files or you don't need to create new Python files. So you just need to run the application. You don't need to program it. Yeah, just to get it from the GitHub. One nice example I like to do that illustrates the capabilities of this framework is current time in Berlin and C.L. This is what I did in one of the demonstration videos. And you can see the agent writes his message. He writes some code. Something happens. Now the agent is going to get an error. I will show you why he's going to fix that error. He's going to execute the code again and he will write the response for me. Okay, I think we have to break this down because a lot happened in this example. So can you scroll up? Yeah. So yeah, I wanted to let it finish and go step by step. Yeah, this kind of crazy because the agent even though it ran into error, it was able to fix itself and then installed the necessary libraries to actually get the date and time because obviously the LLM, which in this case, it's GPT4O mini write. Right. Yeah, the LLM itself doesn't have the knowledge of the time, especially not in different locations. Just walk us through all the steps that happen here because this is fascinating. By the way, if you want to build something with agent zero and you need more help, then make sure to join our community. Of course, you can message Jan. You can interact with me directly. And in the next five days, we're launching the long awaited Make Money with AI training, which is going to teach you step by step how to make your first thousand dollars with AI.

 This offer doesn't last forever because once that training releases, the price is going to double. 

So, let's just join in the next five days to take advantage of this offer. If you wanted to use a standalone LLM, it would have no idea of time because it's just neural network. And if you want to use a generic framework like QAI, you have to create a tool that will take the time zone as an input and the time as the output. And you have to interact your agent on how to use the tool. But agent zero has a generic tool called code execution tool. And this is really the superpower of this framework because the agent can use this tool to write any Python code JavaScript code or terminal commands. And LLMs are very good at writing code. And another thing LLMs are very good at is debugging code like analyzing errors and fixing code. So why not like put these together, let them write their own code, execute it for them and give them the output so they can fix it and run it again. So in this case, I told him get current time in Berlin and Seattle. He had some thoughts like user requested the current time. I will need to use library to get the current time in different time zones. That's why the Python time zone library is mentioned here. So he writes Python code. He wants to the Python code is better readable here where we are notified that the agent actually uses code execution tool. So he uses Python runtime. He wants to use these two libraries, but this library is not pre installed in the Python environment. So he writes the code to get the time here. A doctor container is started in the background. And he gets an error that the Python time zone library is not installed. And he knows exactly what this error means. So he knows that the PYTC library is not installed. I need to install the library. I will use pip and he runs a terminal command using the same code execution tool, but this time in terminal runtime. PIP install PYTC.

 And what this does is that it runs this command in the doctor container in a Linux environment. It installs the library into the Python environment. So here is the output of the installation. The agent can always see the output of the code. So now he knows that the package was successfully installed. And he continues the library has been successfully installed. I can now proceed and he writes the same code again. He gets the time in different times, also here and the last line here he prints out the result. So this is the result in the terminal. These are the two variables, the agent printed. And now he knows I have successfully achieved the current time. I will now prepare the final user and he uses a response tool to send me the response. So now I know the current time in Berlin is 1409 and in Seattle is 509. Yeah, really fascinating. Like so much happened in such a simple demo. And I don't think like other agents frameworks. Like as you said, in Korea, you have to build a custom tool yourself, right? And a lot of people don't have programming skills. They don't know Python. That is intimidating. Here you can just chat with the agent and installs the libraries and builds the tools it needs to achieve that task. Yeah, I really like this example because it's so easy. Everyone can understand this, but it is something you cannot do basically anywhere else. Yeah, people don't realize, like even in chat GPT, the LLM itself isn't doing these things right? OpenA has made many of these tools that the LLM can use to answer these questions. So if you're using, you know, if you want to build agents, you're only going to call the API for the LLM itself. It doesn't call like the API call doesn't come with people tools in it of itself. So stuff like this to get current time or other stuff that you need APIs for. You need to build the tools. And if you don't know how to do that, then you know, you either have to learn it or your screwed. So I think this is like a revolutionary idea is that I just have the agent do that. You know, why should the user build everything? Yes, exactly. And like 90% of these operations, the agent is doing our very trivial in Linux or in Python, right? It's like open a file, a rename a file, zip something or write something. And if you want to use like custom function for everything or even API call for everything, it gets like very time consuming to develop such thing. Yeah, let's talk about a bit about the model because GPT4O Mini is came out, I think last week. It's a very new model. And I would say it's perfect for building agents because it's so cheap and it's also really solid. Yeah, I love the model. I was using GPT3.fl after both before GPT4O Mini because it was the best like price of quality ratio before GPT4O Mini. And I was hoping for a long time that such a model would come out like faster and cheaper. Maybe it's not faster. It's probably about the same speed. But it's they say it's 60% cheaper and more capable. Yeah, it's very good. You know, before like a lot of people said building agents expensive, now I think that excuses taken away with this model. Yes, I also experiment with the Gemini flash. And there is also a good model and it has that one million token contact window, which it really good because you can store a very long conversation and like a very long code output. So if you want to do something complex, it can maintain like a long history of conversation. Yeah, and you've actually good in this network, this framework, agnostic to any of the LLM providers. Later we can show how you've built that. But you know, if people want to take a new slot, they can use Gemini or open source models as well. You know, that's like we don't know what's going to come out right next week. Cloth for my drop or open AI, my GPT5 like we don't know and building stuff for just one model. I mean, that's not really a good strategy. So you've definitely taken the right approach here. Exactly, this was exactly my thoughts, right? I don't know what model is going to be the best tomorrow, right? And I want this to be compatible with all the models and a lot of people want to use this offline, right? Because they want to work with their personal stuff. So yeah, this is compatible with basically any model capable of generating text. It can be a chat model or instruct model. And this Jason output, I don't use any Jason mode because again, that would break the compatibility because only some models allow structured output. But you can instruct any model to provide you some and most of them will understand unless it's some like fine tuned model for just text or just conversation. So you can use this with Olamah, Hanging Face, you can use it with Grog for free. If you want, you can use it with Lamah 370B or 3.172B on Grog for free. Yeah, it opens a lot of doors. So I guess let's go into the question like what is required to run agent zero because you already mentioned a darker. So obviously most people are probably not familiar. I made a video on it. So I'll link that below as well. But those who are not familiar can explain the structure of agent zero. Yes, I will exit this so we can start it again. So this is the project folder of agent zero in Visual Studio Code. And it is actually surprisingly simple framework. There is really not much code inside. And I can show you, for example, the main file, how easy it is to configure the agent zero here. We start by selecting chat language model utility language model and embedding language model. I might be confusing, but I think it is just a matter of efficiency. I use the chat LLM for the general chat with agent zero and the utility LLM for utility functions such as summarizing messages to say space or some like quick things in between the framework needs to do. So you can use cheaper model for utility and something quality focused for the main LLM.

 And embedding LLM is used just for the memory feature because there is a vector database integrated into the framework. I use the same model for both the chat LLM and the utility LLM because right now with the GPT-40 mini there's really there's really not many reasons to to switch to cheaper models. And for a full day of testing it usually costs me about 30 cents maybe with GPT-40 mini. And I also use the embedding from OpenAI.

 This is even cheaper. This costs like a fraction of a cent per day. And this is how agent zero is configured. There is one configuration object with a few settings. All of them are predefined so you don't actually need to change them unless you want to. And we create the agent and we start a chat function. And here in the main file there is all the UI you can see when I run the agent here in the domain. There are these prompt for the user responses from the agent. This is what the main.py file is about. So you don't find any of the framework logic here. This is just for the user to be able to communicate with the framework. And all of the agent logic is in the agent file. And I guess even this file for more context. Most of the stuff is visible for debugging and knowing what's happening. So if you go back to the terminal there isn't the stuff that the user actually needs to pay attention to. It's really like the green response at the bottom right. Yeah. The rest of the stuff is just helping you see what the agent is doing. What it's thinking. Yeah, I always pay attention to what the agent is thinking because sometimes he can head in the wrong direction and you actually have a chance to stop him. Just like this. If I tell him like a right me a poem about money. And he starts writing something. I can press any key on my keyboard to stop him. And this user intervention. Pop up shows. And I can tell him story. Not money. Monkey. Right. So even if I make a mistake, I can stop him right away. I don't have to wait for the full output. And the agent will react to the user has corrected their request to a poem about monkeys instead of money. So this is. This is something I knew I need to implement into the framework because if you play with other AI frameworks, you know how frustrating it is to like watch the agent headed in the wrong direction and there's nothing you can do. Because if you like terminate the program you lost all the progress. And the more complex of a task to hire the chance that the agent will do something you don't want to do. Actually one interesting thing right now I can see is that this is not a valid Jason. So even GPT 40 mini can make mistakes and can produce in a valid Jason. But I created a Jason parser specifically for this project that can like parse even incomplete or invalid Jason objects. Some models like the cloud they like to use triple quotes and multi line these string contents, which is legal in Jason. But when I saw they do it, I said like why not allow them right so I edited the parser so they can actually do some more magic and even if they produce like these double brackets, which are incorrect. I can fix this for them so it still produces a valid output. So you can use it even with these smaller models that like to make errors sometimes they forget to use quotes sometimes they forget to do comas or something. So this parser should be able to recover from all of these errors by the LLM.

 Yeah, that's really like I think that's probably essential because you know the more LLM's there are every one of them has tendency to format things in a different way. Yeah, and the problem with large language models is that once they make an error it stays in the conversation history. So they see their previous output being formatted. You know this way with these double brackets and now he's probably going to answer with double brackets forever. Yeah, that's like forcing. Yeah, that's the problem because they see their history quite like the examples right. If you provide examples for your LLM it's basically the same as message history. So once they see something in the message history they can like quickly like poison their whole like knowledge or attitude on how to call that. Yeah, I'm kind of surprised like the ability to interrupt agents isn't everywhere right. Because it just seems like a such a essential thing like given agents are obviously not perfect. The human needs to play the role of a manager or CEO that oversees the projects and makes like the decisions you know where to go. So it's kind of crazy that not every framework has it. Yeah, it seems like a simple feature, but it's actually quite complex to implement because everywhere you do any I don't know loop or anywhere you progress to the next step of the conversation loop. So you have to check whether the user preface the key or not and you have to like stop you have to be able to stop any function at any point basically. And that might be a problem because your code might expect a function to finish completely return output. And now you have to edit all of your functions to be able to like skip the rest and return. But I think even from like a philosophical perspective right because right now LLMs are have some like obvious downsides right in terms of they're not creative. They cannot invent new stuff. I think in the like near future there is going to be the best thing is going to be just a combination of human and AI right where human can do the things that it can do best and LLMs can do the things that it can do best like for example there is no way human can compete on a context window like you know 1 million 2 million going through 1000 page book that Gemini can do like instantly right. So I think you know maybe in the future like when you know we have a G I S I let's not talk about that I'm talking about like the next five years where the most practical thing is going to be the human has an idea of what to execute and can direct the agents and the agents are just do the like small almost like a manual labor right each task and the human is overseeing like managing the team of agents I think that's like going to be really the way we work in the next five years. Yeah exactly I think the ultimate augmentation would be an agent that can read your mind and can do something like a rag for you right you do something or you think about something and it can feed you with relevant information on the topic. Yeah you do calculations in your head and you get the responses from your agent. Don't massively increase the beat that we can work at. What's faster. Yeah this might this might be the first baby step towards that direction right this is more of a personal assistant rather than like fine tuned framework for a specific task running in production during one thing over and over. This is something that should like make your life easier or speed up your development or whatever you need it for I can tell him something like prepare a development environment for me like install a server like download some libraries run it. Prepare the project structure for me and I will continue from there and it is capable to do it in I don't know a minute or two maybe and I would spend like an hour maybe setting up the Linux machine installing all the necessary stuff and finding out what's what. So not not too waste much time. There is not a lot of code as you can see there are 300 lines of code in the agent file so. It is not a big framework there is a there's some other code in the path and directly where I have the tools and some of the helper functions but this is basically the conversation group of the agent so the agent runs in a loop until the task is finished and then he reports back to the superior. And I see superior because right now we have seen a very basic example where I talk to agent one but the reason it is called sorry agent zero but the reason it is called agent zero is because there can be more agents and they can have numbers I can say something like right five more points. Use one agent for each. They each in a text file. And right now we will see that the agent zero uses a tool called call subordinate and he sends him a message. Please write a poem about monkeys. Save it in a file named monkey poem one dot TXT and here we can see that agent one is starting a message. The user has requested a poem about monkeys but this time it is not actually the user. It is actually the agent zero. The agent zero is now superior agent to the agent one and if agent one needs to break down his task further. He can spawn agent to an agent three et cetera. And actually you said the agent agents don't know whether the previous agent is a human or another agent. Yes and they don't care they are instructed that there is a superior agent that gives them instructions. I think I call him the user that's why he talks about the user but agent one has no idea that his user is actually another agent and he doesn't need to know. And so agent one was doing something then he responded to agent zero agent zero then called another instance of agent one. He didn't call agent to he called agent one again but he made a reset. So agent one lost all his memories and started over and this way I don't need to create like large networks of agent if the agent zero needs to like just split his task into sub tasks and delegate them to different agents. They can reuse one agent over and over and always reset him and just give him another instruction set. And we don't like fill up the memory. The reason why this is important is that all of these large language models they have limited context window. So only spoke many messages can fit into the memory of the agent. So if you want something very complex from agent zero he will probably in the middle of the execution forget some of these older messages and he might start like steering away from the original goal. So this way the agent zero can just break down the task into sub tasks delegate the sub task to subordinate agents and subordinate agents can do the same. Sometimes you can see chains like ten agent long if the task is too complex to be handled even at layer eight or nine they can break down further and delegate further. And so each of these agents they have their own like clean context window unproduited by their subordinate agents or superior agents and I think the execution could be done right now. So I completely the track of writing and saving five poems about monkeys I can see the work directory of the agent and yeah there are some text files. Continue something. So if this was just a standard change the LLM you know you you couldn't it can't obviously say files on the computer so you still have to copy paste the outputs and do the manual stuff which you know why do that when an agent can do that easily. Exactly and as we talked about the doctor container and saving files on my computer the way this works is that the agent starts his own doctor container I had prepared an image for this and it knows the name of the image so you don't need to configure anything in doctor you just need to have the doctor installed on your machine the easiest way is to download the doctor that's called the kitchen for those are Mac on Linux you probably already had a doctor. And the image and the container will be created automatically and when I exit when I exit the process of agent zero it will be removed automatically so it always starts with press container. If you want to change this behavior you can in the framework and I can explain why it's a good idea to use the doctor because I know in the past you have some interesting stories with agents doing you know weird behaviors. Yeah like at first I didn't use a doctor container because I was lazy and I wanted to get some proof of concept running so the agent was executing stuff on my computer directly and at some point your files are at risk right it installs a lot of packages so you can run out of space it can uninstall packages so it might actually make your computer or other project. If you tell him like delete my disk it will probably be able to delete your disk so you would have to be very careful this way it is running in a separated isolated environment so it has a Linux machine running in doctor with python pre installed and Node.js pre installed and some other tool for communication so it is like a sandbox it can play there safely and the way it is able to create files on my computer is. Because in the project directory there is a work directory folder and this is mapped to the root folder of the Linux container so whatever the agent does in the container is created here in my directory on my computer but the agent has no way to break out of this folder and do something else on my computer but only this folder is shared so. If it is polluted I can delete it but if he breaks something he breaks his own stuff in the work directory and the benefit of this is that when the agent creates something right right now with these problems or I just did some flowers before you can just grab the files and work with them from here you don't need to somehow connect to the container and use something like ftp to transfer those files you just have those files at the reach of your hand. I guess this is a good spot to showcase the only folders and files that the user actually needs to interact with inside of agent zero because most of them are you know for the framework. Yes, yes. So what you can change is for example the models file and I have prepared functions for all the various models so. You actually use these models like this you don't need to import more libraries from language for each individual model provider you can use my model library and for example get open a chat and specify the temperature and for example the model name here. So this is one thing you might want to update or edit if you want to use something specific but it is already prepared for all am I hugging face so. You may be don't need to change this file at all even in the future. Now the work directory is the shared directory with the execution environment so this is where the agent actually works everything downloaded created will be stored here in this folder. And you can even feed this folder yourself with files for the agent so if you want your agent to do something on folder full of files you can just copy or move the folder into this directory and tell the agent I gave you a folder find it and do something with it. 

Now. One thing you probably will want to touch is this prompts folder and this prompts folder is like 75% of the framework behavior everything is defined here and basically nothing is set in the code the code only controls the communication loop between the agent and those tools and between the agent and the user. And so we can use the agent and subordinate agents but everything about the framework is in these prompts for example this is the agent system mark on file and this is the main system prompt for every agent so every agent gets this system prompt and everything the agent needs to know is defined here we have some role description you are autonomous Jason AI task solving agent. Some instructions on how to communicate he has an example of the Jason output he should produce. Here are some step by step instructions to problem solving so outlying the plan check the memory because maybe he did something similar in the past and he has some knowledge of tools he can reuse. The task into sub task and delegate complete the task report back to the user and here are some tips and tricks and general operation manual and other instructions right. And here we have agent dot tools mark on file and here I describe those four or five basic tools the agent has so one of these tools is the response and I show him how to use the response tool. For example if the user greets the agent he will generate some thoughts like the user has greeted me I will blah blah blah and he will send a response high etc or here is how to use the code subordinate agent right. So for example here is an example how to re-instruct the subordinate agent on how to fix something like the agent didn't do properly the first time well done now edit or something like that. The agent has knowledge tool I didn't show this one yet but knowledge tool combines online search perplexity search and memory search into a single tool so if the agent needs to do something he doesn't know how to do he can search for libraries tutorials whatever using this single tool so he doesn't need like three or five tools one for Google one for perplexity one from one for something else. He can have one knowledge tool which will do all of these searches at the same time and return combined output let's show a simple example of this. Sure. So find a random like the video about rag. And he uses the knowledge tool find a random YouTube video with retrieval augmented generation and he gets a response from online sources from one of them is perplexity one of them is dug down go so this seems like perplexity this is dug down go and the last is memory and he has no memories yet about finding random YouTube videos. And so he got the result and he tells me that there is a video in here on this link and he can use this tool to find libraries find tutorials on how to use this libraries find code snippets and anything else and because it is combined with the memory feature if the agent memorize something in the past for example successful use of the library. And use of some like a new little tool you can store that in the memory and later it will be automatically recalled when he uses the knowledge tool along with the online results. For example this could be also useful when using some specific documentation or something that you know likely doesn't have a lot of reference in the training data that you want to make sure the agent is using the latest in text. Yeah, and you can also do something like memorize my API for open AI is by five for something like this you will store that in the memory and the next time he wants to use open AI API for some reason and he uses the knowledge tool the API key for open AI will pop up from his memory. And this mess up the agents in speed losing to be for many. Where is that like set the main API key. No, it is just stored in the vector database and memory I just told him to know why something right. It's not going to use it for anything right now. Yeah, make sense. Normally in the project all the API keys would be in the dot be in the file just like anywhere else. So you only need to put the ones that you plan on using so obviously you don't need to fill out all the different moral providers. Yes, yes, I only use the open AI API key right now and perplexity if you don't have perplexity API key you don't have to put it in the dot in the file and it will just not use perplexity. But because perplexity has like $5 a month pre-credits for API for paid users it's like a good supplementary product for agent 02. Yeah, it's such a good deal. Okay, so because almost nothing is hard coded into the framework and basically everything is here in the system from for example. If I were just to like remove this from the mark on file the agent would stop delegating subtask to subordinates because you wouldn't know that there is a tool called subordinate. Maybe there is a mention in the system about delegating subordinates but if you remove like these mentions you will have no knowledge that you can do such thing and so he will not. So if you want to like change the behavior of the framework if you want to change the way the agent communicates the way he calls tools the way he works with memory you can all do it in the prompt you don't have to touch the code. So this is quite an important for all the no coders which is probably a majority of of AI users right with it. Most of people are just like a beginning with Python just because of AI and actually me included I started doing Python just few months ago and just for the sake of AI because I was given no other choice. And so this can be really helpful to all the users that just want to play with this framework and experiment and want to be able to like alter the behavior dramatically. They can reach it by editing this text which is human friendly. And I would like to show you one more thing that I tried just this morning I created a career example because the agent zero interface is so simple you just have a message on the input and a message on the output right you you give your agent an input like memorize my API key and you get an output which is this final green response. So the function is actually equal simple it. It looks like this right you get a message and you get the result so I thought why not creating a crew AI tool called agent zero so that your crew in crew AI would have the power of agent zero but like without the side effects right without having to like chat with him and like. We're keeping all the benefits of crew AI but also having the like superpower of writing and executing his own code. So I created this very simple example I just start the agent zero and I create a tool for crew AI called agent zero there is a tool description in here and inside we just call the message function of region zero. I created just one agent just the assistant and I created just one task get files of the user read contents of grant or directory so and that fit so for demonstration when I run this file. We should be able to see the crew AI output first the phenof agents right talking task I need to read the content he is using the action call agent zero and now you can see agent zero does his thing this is very easy for him that's just one Linux command he returns the output. And the crew AI and the rest it gets the output and it can provide the output as the file answer so you don't have to choose your framework right you can use a combination and you can actually implement agent zero into basically any application you need it is it is just a simple just a simple function with one input and one output so if you have. If you have any like process or flow you would like to integrate agents you are into it is very simple can we go through like step by step because we'll give people the GitHub link can we go for step by step what is required now we're using VS code so a lot of people don't even have that installed so can you go to the GitHub repo and show like how would you set it up if you had a completely new computer. If you are serious about AI and you don't want to miss the AI revolution then make sure to generate community this is the place that was the breeding route for agent zero this is where you got the original idea and where people gave him feedback and you know helped him write the prompts and stuff like that plus there is 500 other people at the cutting edge of AI you get direct access to me in the form of weekly calls and one one calls at month to and you get all of the trainings and workshops how to build agents and in the next five days how to make it. So I'm going to show you a one with AI and on top of that if you don't like it there is a money bank guarantee so give it a shot the link is in the description there is a. There is a setup here so users can go through this but I will show you I will show you here you don't actually need VS code at all right only if you want to like edit the code or if you want to debug the code I included a VS code configuration folder into the code. So you can use the code to the project which which has debugger options enabled and type taking enabled so you can use visual studio code it will make your life easier if you want to code if you don't want to code you don't have to but you will still have to use the terminal so what you have to do is download the code from GitHub and you can either do that by cloning the repository if you know how if you don't know how you can download the zip file of all the code. Just like this and you can you can then extract that folder and what you need to do is install the necessary requirements and it is mentioned in the in the guide here how to install them you just run like this. This is the agent you just run pip install our requirements dot txt and what this will do is that it will check the requirements dot txt file the folder and it will install all the required dependencies so everything required is included in the project right now it is not going to install anything it will just check that everything is installed because I really have the project running. But on the first run this would download and install all the requirements and I've just did it on both Mac and Windows so it is Windows compatible and the other thing you need is the docker and as I said the easiest way is to get docker desktop application you can install this in a few quick steps it has graphic installation interface you just you just tick all the recommended settings you're going to take. You can change anything and it works on both macOS and windows and only next to you probably already have docker so basically only I can buy from a doctor. Yeah Python and docker but you don't even need to use Python environments a lot of people are very confused about Python environments you don't need to use them I would recommend learning about Python environments and using them because it will keep your installations more organized but it's not required. Yeah because everything is running in the docker container. Yeah yeah right now as we can see no container is running but when I when I start agent zero until him to do something in code like get the current time again we can start the doc we can see that the docker container is starting and it is running. Okay so that's simple enough can we maybe show one more example of agent zero in action that's a bit more complex than the ones we've used. Yeah of course I also like the example of downloading and curvading videos for example so I can tell him like on a YouTube video about rag then download it and I know he is probably going to fail the first time. Because he always uses the wrong the wrong library the first time so I can even hear him in the right direction right away. Okay so he tries to use code execution tool to use a library to download this this YouTube video but it's not installed so he installs and right here we can see that there what dialogue in the process. And the agent is actually even capable of responding to like interactive programs right this is also one feature that was quite difficult to implement but once it's working it saves so many scenarios from failure so the agent sends the Y key to confirm the dialogue into the terminal the installation happens right now he is installing the YouTube download library or something like that. And this library is not going to work it produces errors right so I can again stop my agent because I see he's heading in the wrong direction so I press any key on the keyboard and tell him use why he the out he. And he says the user suggested using white to the P he. He probably put the wrong. To man inside. Oh no okay sorry so this is still the output of the previous program that is unfortunate I will probably have to restart agent zero this time sometimes when the agent runs a program in the terminal that just. Doesn't want to stop something like starting a web server or some code that runs in a loop the agent will not be able to recover from that because once he cannot send any more input into the terminal he cannot kill the process I will deal with this from the future versions I will allow the agent to like start in session entire but now let's do it again download. I think this is actually a good that it happened because it also answers the question like when should people restart engine engine zero right I guess at once a day or every project or every task. Would you recommend. Yeah actually the easiest way is to just exit the agent zero because this will also remove the darker container so when the darker container starts fresh even if there wasn't error even if the operating system is broken or if there is like a frozen process it will be restarted like the full virtual computer will be restarted so these ways actually to exit the agent and start him again. Your files will not disappear because the work directory is still like on your computer and map and as you can see it was able to download something but then it got some errors so I'm going to remove these files for now. And I will tell my agent use by the VIP library with you are. And first he checks whether this library installed is installed it is not so he installs the library it's a small library so it should be quick. And he proceeds with downloading and I told him a random video so he is actually doing something like a random pick. But this is not what I meant so let there him in the right direction one more. Can you explain a bit more about how you made this framework work even though it runs into errors because most frameworks one error can just stop the whole thing but this one can actually push through and solve the errors. Yeah, I think there are two levels to this one is that when the when the terminal produces errors it doesn't matter to the framework itself because the framework is calling the terminal in the Docker container remotely so any errors produced in the terminal are just error messages return to the framework. So I just take those error messages and be done back to the agent and the agent handles those errors right so he can say something like okay this error means this and I can fix it in this way. And another thing is that there can be an error in the framework itself some of the built in tools can produce errors it didn't happen to me in a long time because those tools are very simple they are just calling like us and remote terminals or they are. Just manipulating text but if there is an error for example if the Jason was completely broken and no information could be retrieved from it there I try to catch all the exceptions from those errors and feed the text back to the agent so when there is an actual error in the framework. The agent is responded with one of these messages something like you have misformatted your message follow the system prompt right there are some of these messages utility messages to steer the agent back contract. So basically this is like using the good prompt engineering principles to remind the LLM of what it should do right because like this is one of the basic principles if there is something really important let's say you're writing a system prompt that should be there at least two or three times right but the longer the context window is if there's like hundreds of thousands of tokens the hard to chance that the agents are going to ignore something and these kind of reminder messages should help with that a lot. Yeah exactly I can actually throw you one trick that I do I can lower the maybe you have noticed that there is a time out on messages from the agent I can show you why that is I will lower that time out to five seconds and when I start the agent zero and just tell him higher when the agent responds to the user there is always a time out on the message and if I don't respond in time. The agent will get a message like this user is not responding if you have a task in progress continue on your own if you don't have a task at hand use the task done to with text argument and this tool is actually not mentioned in the tools list because I didn't want him to use this tool likely I really only wanted him to use it when he wants to avoid that time out so if you have some like long running task something you want your agent to do I don't know overnight maybe you want your agent to train. Another agent you want your agent to iterate given different prompts then award point or something store the results somewhere and you want him to do this for several hours you don't want like a single message to the user to stop the framework. So when the agent uses the response tool there is always a time out if I respond in time or if I use the W to wait he will get my response if I don't you will get this example on like how to end his work if he doesn't have any more work to do and so he does right now because I just greeted him he said I have no more work he still knew what you need and now okay he used to response instead of task done okay so. That is a failure that is actually the first time I've seen fail on using the task done maybe maybe I didn't write this with the GPT 4 role but actually this was very simple to follow with GPT 3.5. Okay so yeah I sometimes instruct the agent only after he does something he is using response I don't know why that is now. But by default the time out of 60 right. Yeah the time out was 60 and you can change it to whatever you want I just did it because when I'm not in the computer and I want him to continue he just will continue sometimes and that depends on the prompt but sometimes the agent likes to like report back his success even in the like middle of the task or sometimes he likes to ask full of questions sometimes you tell him like go and download something or get some information and he uses a library that requires. A P I keys and he will go and ask you for an API key so if you are not at your computer or you don't have the API key and you don't respond then this would be a game over right if he stopped so if you don't respond it will tell him like user is not responding you have to manage on your own so he will probably try some different library. Okay I wanted to show you the download video so download YouTube video about rag. Use white you D.R.P. for that let's make it simple for him so I noticed this is one of the core ideas for principles is to keep the agents running at all costs right you made sure that the agent can answer yes or no questions in the terminal that it can work through errors that it does not need you know user response like. I guess explain like why this seems such obvious and important thing to you. Well I don't actually know why it seems obvious but actually once you try to develop something like this and you get a few failures on your agent hanging on something simple you will start to mitigate those situations so one of the mitigations is exactly this and right now you can see the agent made a mistake I told him use white you D.R.P. to download video and he used url with video ID playsholder right and he got an error so he used the knowledge tool the knowledge tool gave him a link about some YouTube video about rag so you don't know that so we should actually now see a YouTube video downloaded about rack yeah rack from scratch. Okay seems legit and now now let's say convert it to MP3 using FMP eG if I know the library that works I can tell him this will save some time so he checks a FMP eG version it is. It is installed but now we have a probably problem with the name of that file and that is something that Linux does with file names when you use the Alice command is that it does some unicode is keeping on the file name and sometimes the agent is even able to decode this into the correct character and then use it let's see if he is now okay it seems he was. It seems he was because it seems like the conversion happened the video has been successfully converted to MP3 format let's see. Yeah we have the MP3 here and okay so I can tell him now remove the original video so you can clean up the video and then I can tell him. Also clean up the libraries used and he will uninstall the library. This is not necessary because one the agent is finished and I turn him off the whole Docker container will shut down with all of the libraries being removed so but if you want to use it for example on a persistent system you can it can even clean up after itself. And I think we have the MP3 file here. This is lands from chain. I hope you could hear it I'm not sure about the I could clean sharing feature. Yeah this is nice. Sometimes you go ahead. Sometimes you have to fix these errors for your agent sometimes the agent will run into a dead end and is not able to recover because he is trying one library after another and none of them work. Sometimes you can help him by preparing something for him like renaming files in the directory or whatever or instructing him what library to use. So you can really cooperate with your agent you don't have to fully rely on his judgment sometimes he will need your help like this will probably be less and less with the next generation of models but they can always run into a dead end. Yeah that's what I meant like I think the killer combo is a human plus agent because it really right now at least you know in the foreseeable future each have different advantages like completely different like architecture of the brain then how the alarm works. Yeah and it doesn't even have to be a user as I showed the Kraya example it can be a Kraya agent because it's just a tool where the Kraya agent sent a message and received a message. So if the agent zero response with something I wasn't able to find appropriate library for this I wasn't able to finish the task the Kraya agent can actually answer him using the tool again telling him like use the YGDRP library or whatever so it doesn't have to be a human help it can be another agent's help or another tools help. So what kind of prompted you to build this like what was the original idea behind agent zero. Yeah I didn't experiment with Kraya I called it a recruit and I what I did was that I created a Kraya I created a Kraya just like this by creating some agent task and some some crew and what I did is I just like. I just like wrapped it all in a function so I did something like create create. And then I made this function a tool just like this and I gave the tool just like this to the crew itself and so the crew was able to create another crew and there was something there was something like I don't know that. And so the crew running or the agents inside the first crew were able to use this tool to spawn a copy of itself and give it a task and I instructed them here in their goals and backstories or task descriptions or whatever like when your task is big break it down into smaller sub task and use the create function to handle the task. And because the crew had to be like generic I didn't create any like the roles specific for some task but I created something like a search agent something like a writer agent right like generic roles different roles but still like very generic yeah without without any like specific tasks. So the first crew was able to break it down into few other crews and then it continued and because it was so generic I also needed some generic tool because I didn't know whether they will want to like search the web or write code or whatever so I created a first function writing or like running python code. So it was a very simple function just like this except this wouldn't be a task but a python code and inside it would call like executive Python and it would return the result so it wasn't it wasn't much stable it could crash the whole program etc but it really gave the crew like real superpowers and I saw the potential because LLM's are really good at writing code and debugging code and this is where I saw the potential how they can recover from errors. They can fix their code and move on and just with a single crew AI tool you are able to do so many things so there I decided to build a full framework around this. And I wanted something that was like a little less black box than crew AI because in create I also uses a lot of these small prompts like this right instructing the agent for example like when the agent repeats the same message you have a message like this in create as well right yeah but these messages are hidden from you in create so I wanted something to be more open and more customizable. And then I like come up with the idea of combining multiple tools into one so for example the knowledge to combines perplexity Google memory search etc so from them I was just like iterating on thoughts and making making things rather simple and easier for the agent I didn't want the agent to hallucinate on his tools because that's a problem with every framework if you give it like 10 to 20 tools. And the agent has to choose whether whether it wants to do Google search or Dr. Go search or perplexity search it will get confused but if you combine them into one tool and call it search then there is no room for error and the user doesn't like like you know as long as it finds the information. Yeah exactly. So I guess you know how how were you able to do this I can tell us a bit more about your background on like what were your previous experiences. Yeah I had very little to non-experience with Python actually what I do for living is very proprietors of to our development we don't even use visual video code we don't use GitHub we don't use like Azure or AWS everything I do is very proprietary very in house so yeah this was like very eye opening for me and I had to learn about Python and I had to learn how to do it. I had to work with Git properly and I had to learn how to deploy my applications into the cloud and then I did a few presentations on this so I could teach more people about this but yeah actually the good thing about coding is that once you're a programmer your programmer if you have the right mindset and if you had the good habits you can learn like any programming language function call iteration and condition. This is with in every programming language and there's nothing to change about this so maybe the syntax is a bit different maybe maybe some brackets change maybe use columns or some icons somewhere maybe use different keywords but it's basically all the same so once you learn one programming language you can learn any programming language so I would highly recommend anyone wanting to experiment with agents just start by learning Python. It's quite simple. I don't actually like that language too much but I understand that it is simple enough for beginners so there are some radios. And it has the most like AI libraries by far. Yes yes. But yeah I mean learning I always recommend like do the first you know 20 30 hours like people always think like when I say learn programming they imagine like becoming expert like you right like thousands of hours but even in the first 20 hours taking some basic Python course or working with chat GPT to learn the basics and write some few programs that alone will unlock so many limiting beliefs and as you said like you only need to understand the direction of the project right like variables if statements functions and the syntax you know just leave that to the LLMS like the LMS can write that perfectly. Not only the syntax but actually those built-in tools and those built-in libraries like as you said I maybe have thousands of hours of programming but I don't remember how to read a file in Python or how to write a file in Python right. And those extra hours of programming they would just give you those like good habits right so you will become better at documenting your code your code will be more readable your code will be more customizable in the future. That is a bit benefit right that you don't write crappy code so you don't have to fix it in the future and it is easier to maintain so this is what the thousands of hours of programming will actually teach you but not how to like do the function call itself. I still use chat GPT with my custom GPT for coding for things like this. I don't remember how to create a crew AI tool but I can ask for complexity and to show me the code and I can copy paste it right. As I said I don't remember how to read and write a file I don't remember how to communicate with the terminal I always have to search for these things and now with AI it's like 10 times easier because you can just ask the question and you don't have to click any links it will just give you the answer. You don't have to go through various forums and stick over so this is the best time to learn programming it is still not obsolete and you have the best tools to do it. Yeah and there is like no shame using the AI to help you out. Like some people have the notion that you know they don't want to do it and it's kind of crazy because even in AI communities not people don't use the AI tools enough right. You have so many years of habit either going to Google or asking other people when you get stuck or when you don't know something but these tools are like a lot more powerful than people realize. Yeah I believe that even the best programmers should use AI for coding because AI can also have ideas and those are not AI ideas right. Those are copied ideas from Stack Overflow from other programmers and it can write a function like much better optimized than you would like even if it does the same thing can be much faster or it can be much less code. So I think everyone should use AI for coding and only like edit the code or sometimes it's hard to explain what you want right sometimes explaining your function might take like multiple times more time than writing the function itself but I think that's the best way to do it. But and especially with something like regular expressions right regular expressions are notoriously hard to write and I don't know what the program. Yeah that can do that from the top of his every everyone just searches for them and AI is very good at writing those so definitely at least for this every program should use AI program. So what is your ultimate goal with agent zero. Okay so I think the most important thing is to have an open source alternative to closed source features like for example the code interpreter on open AI side because if you use code interpreter in chat GPT you know it can also run code for example I use it with my custom GPT I tell him write me a function that I say tested and it will run that function through the code interpreter. But there are limitations it's a flying it cannot communicate it cannot read or write files it cannot install new packages etc but this limitation is for users right this limitations probably doesn't apply to internal open AI tools so closed source companies like open AI.

 So in contrast to their name they already have those tools right a lot of companies and a lot of people already have tools like agent zero and you know with this potential you can do a lot of hard you can like to instruct your agent to go and scan people online if you use something like a dolphin model uncensored you can do stuff like this so I believe there needs to be a balance and that the open source community needs to have tools like this to be able to some countermeasures so the ultimate goal is I think this would be ultimately not developed just by me but a large number of developers from the open source world and it would become something actually useful. Right now I see it as a foundation right it's not a product yet but I think it's a good foundation because it has been built with extensibility in mind you can build your own tools you can change how this works and you can add a lot of features into it. So I think it's a good foundation for the open source community now to jump in and to really like push this into something that can actually be used. Awesome so you know everyone make sure to go to the GitHub again and start the project and see if you can contribute. I think one of the things you said you wanted to work on the system problems right? Yeah exactly those system problems are they are just bad you know to go with my life. These prompts have been all written by me and I don't think I edited them much ever since I think I just maybe edit a few instructions when I found some errors so maybe I added something like always be very descriptive but I didn't actually try to change this completely right and maybe just by giving these instructions in a different order or maybe just by putting some of them it would put more focus on the others. I don't know and probably nobody knows until you try so in the future yeah I would definitely like more people to try more prompt and I would also like the agent zero to try more from itself right like I said to be able to for example train agent one so in the future version I would like to create more of these prompts holders so you could have for your these messages and prompts separated and they could be edited by agent zero and. You would maybe create a copy of his folder edit something call agent one you how it works change something do it again and then maybe you will come up with entirely different prompt and then even maybe copy it for himself and include himself right everything is possible if you give the agent access to the files and tell him what to do. So what I like the one to two features that you think you are looking to add in the near time future that you think would help this framework the most. Definitely memory because right now the agent is probably using like 5% of the potential of the memory feature and also the memory feature is very quickly implemented it is just a simple vector search using similarity scores so there is. Not even any other like summarizing the messages or filtering them or or re ranking by relevance right so this will be improved a lot and I would also like to add some separate memory like areas so one memory would be the important one where you tell your agent like store this API key or something and another memory area can be automatic like all the messages from the conversation with the agent would be stored automatically. And would be also loaded automatically based on the context of the conversation and they can be injected into the system prompt of the agent so when you talk to your agent about downloading a YouTube video he would automatically have memories about downloading YouTube videos pop up for example at the end of his system prompt. Imagine that's going to be kind of difficult to add because like for example change the memory feature right now and through my experience it's like does more harm than good. Yeah and also thank you for bringing this up. I would also like this memory or the agent itself to behave more like a human because when I observe for example how my children learn it's a very interesting process. And if you try to implement something like this in code it could be very difficult for example imagine you tell your agent my name is Bob and the next week you tell him my name is Steve right if it was a human you would ask you something like wait last week you said your name was Bob right. But how do you implement this in the code like most most memory function for frameworks would just store both of these information and the next time do the search. And for example the name Bob would get 2% better relative core because the name is closer to some vector and so it would tell you like your name is Bob right and like these conflicts and. And like importance is course of information these are very hard to implement like. It seems surprisingly or it seems very simple for us humans right like some memories are more important the others. But if you want to implement this in code it gets very hard so I thought about starting a separate project on a GitHub just for the memory framework and then just like importing the memory framework as a library into agent zero. Yeah that would be interesting because even in the problems right like for us it's instinct let's say there is like 10 different lines of problems in a system prompt for us it's kind of obvious which are more important and which are not but you know the LLM doesn't know. Actually I think the LLM just picks just like our brain but but the logic behind it is just hidden to us right because LLM is a black box so we probably do not know where is he going to focus. Like we can use like a exclamation mark or something like a cavity never or something like I do. Yeah or repeating the thing because then we have a higher chance but yeah we don't know how it works and we can just try and observe and that's why these prompts are so important and that's why I wanted. Most of the behavior of the framework to the imprompt because then we can easily adjust to new generation of modern right for example prompt that worked with open AI may fail horribly with LLM because it has been playing on very different set of data and also open ups you know the project to people who don't know how to code but can write prompts. Yeah one more thing I wanted to mention and one thing that is given for free by letting your agent write code we can do for example something like this. Take the file, plower one dot SVG and do HTML and coding then save it as a new file. If you wanted to do this with a framework for example like I don't know who I are and you didn't want to have specific tool for encoding and you only had tools for reading and writing files. What the agent would have to do is read the whole file into the context window and then produce the output and then write the file so yeah both on the input and on the output all of the contents of the file would have to go through the model and you would have to pay for the token and also if the file was a few gigabytes in size or even megabytes it would probably not fit into the context window of the model right so you wouldn't be able to do it. But now if you look at this the agent just writes code and he executes the code and all of the content manipulation happens in the code on my computer in a local container so I don't pay for any of the tokens inside that file and that file can be hundreds of gigabytes large and it will still it will still be processed and we probably now have plower encoded. Yeah, it seems okay. I mean this is actually a very important idea because not only as you said not only is it cheaper because you don't have to pay for tokens it also is faster because you know if it's like hundreds of thousands of words even tens of thousands will take some time right and then it's also more reliable because if you are just using a library or just Python to convert something for a different file type that is going to be like that's the chances of something going wrong. There are essentially zero as opposed to the agent like rewriting everything from scratch and messing up somewhere. Yes, exactly, especially with long files and of course this is at least possible with big files right. Yeah, if you have a file big enough you just don't fit it into the context window and your whole message will fail. And either way like you just don't want to put random stuff into the context window even if it's short right like it just. Makes the agent more distracted and. It fills up the context window easier and faster and you have to pay for the more tokens. Yeah, and it can be probably information etc etc so just by writing the code you can like skip a lot of communication and a lot of token generation. So I guess like the big idea here is that what can be done with code probably should be done with code and like not try to fit everything into a AI.

 I always say this because neural networks they are horribly inefficient right. They are very capable and they are very versatile but they are horribly inefficient if you for example train a neural network for something like multiplication or addition. It will do the work ultimately with some precision but it will do it like maybe a thousand times more power consumed than a code. So if the LLM can write the code instead of processing all that data is extremely more efficient. Well, I guess on that note we can wrap it up unless you have anything else you want to show it. I don't know if anyone wants another demo just let me know and I can do another YouTube video. I will probably do it with the original demo as well. You made the video and we will do it below. Thank you. I will also make another video about setting up the project properly so people can follow the tutorial and get running. Yeah, that's going to be popular for sure. I guess on that note thank you for showing us agent zero. I mean, for me this is fascinating because it's completely different approach than all the other frameworks and I think this one has the most promise out of all the agent frameworks. So I'm just glad we can show it and I'm glad you actually built it into something people can use because I know it has been like in a beta testing for the last few weeks. So it's exciting that it's finally version one. It is actually version zero point four is still in beta. It's more or less stable at least available to the public. Yeah, thank you very much David. Thank you for this opportunity.